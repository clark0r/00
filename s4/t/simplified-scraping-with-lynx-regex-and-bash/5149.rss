<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Simplified Scraping with Lynx, Regex, and Bash</title>
    <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149</link>
    <description>## LYNX
I have been into web scraping for a long time, since the first time I realized people will pay for large neatly organized data. I came across something interesting and wanted to pass some knowledge onto others. [Lynx is a command line based browser](http://lynx.invisible-island.net/). I first discovered it when I had my first Linux install complete only to realize I needed a desktop and couldn’t quite figure out how to get it going (KDE or Gnome; back when you could get free Linux cd’s from computer shops).

Our script using Lynx and it’s dump option. The dump option pretty much “dumps” the text of the webpage (the stuff you see).

## REGULAR EXPRESSIONS
[Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression) have been around a very long time, since the 1950’s. Many different variants of the “language” have come about. In working your way through tons of data looking for more specific data, “regex” (regular expressions) is the way to go. It’s not hard to learn regular expressions but it helps to know that the regex you use in PHP isn’t necessarily the regex you will use with grep on the command line.

## BASH SCRIPTING
All you need is a little bit of bash scripting knowledge. You can find some nice bash tutorials over at [Ryan’s bash tutorials website](http://ryanstutorials.net/bash-scripting-tutorial/). The samair.ru website has a list of free proxies, not sure if they scan it themselves or rip them from somewhere else but we are gonna rip it from them (with our script at the end) with the help from bash.

We use a simple while loop that increments from 1 to 11. During the loop we will use the counter variable in our URL that we are **dumping** from [Lynx](http://lynx.invisible-island.net/). We also use a simple linux command to “bash” our file the proxy sites contents dump into, truncate. The _truncate -s 0_ command will empty our file called plist.

At the end of the script we simply cat out the plist file to our screen and grep the IP’s using our regular expression. There are many ways to go about this and as I sit here and write about it I am thinking of modifying it. It was a simple script and doesn’t need more attention, it does it’s job and the job is done. You can use this script to get the proxies from [samair.ru](http://samair.ru/proxy/) from it’s 11 free pages it provides. Possibly good to use with [proxychains](http://proxychains.sourceforge.net).

## THE SCRIPT

```sh
#!/bin/bash
truncate -s 0 plist

counter=1
while [ $counter -le 11 ]
do
  lynx -dump http://samair.ru/list/ip-port/$counter.htm &gt;&gt; plist
  ((counter++))
done
cat plist |grep -Eo ‘[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\:[0-9]{1,5}’
```</description>
    
    <lastBuildDate>Sun, 25 Feb 2018 22:12:36 +0000</lastBuildDate>
    <category>Linux</category>
    <atom:link href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[system]]></dc:creator>
        <description><![CDATA[
            <p>This topic was automatically closed after 30 days. New replies are no longer allowed.</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/14">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/14</link>
        <pubDate>Tue, 27 Feb 2018 19:45:05 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-14</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[oaktree]]></dc:creator>
        <description><![CDATA[
            <p>JavaScript as <code>anti-scrape</code> is fairly easy to thwart once you look for the in-page json.</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/13">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/13</link>
        <pubDate>Sun, 25 Feb 2018 22:12:36 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-13</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[AHMED]]></dc:creator>
        <description><![CDATA[
            <p>hello,</p>
<p>thank you very much can you please add more bash scripting how-to ?</p>
<p>best regards,</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/12">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/12</link>
        <pubDate>Sat, 24 Feb 2018 18:33:42 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-12</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fxbg]]></dc:creator>
        <description><![CDATA[
            <p>youre just missing the part where it bashes and saves to a file, plus I think your regex is broken. I just tested this script and it does still work.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f.png" data-download-href="/uploads/short-url/n0fTmhTYmZUP1l3oHt4lAGuVuQ7.png?dl=1" title="" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f_2_690x319.png" alt="" data-base62-sha1="n0fTmhTYmZUP1l3oHt4lAGuVuQ7" width="690" height="319" srcset="https://0x00sec.s3.amazonaws.com/optimized/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f_2_690x319.png, https://0x00sec.s3.amazonaws.com/optimized/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f_2_1035x478.png 1.5x, https://0x00sec.s3.amazonaws.com/original/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/2X/a/a1396b5343ffc1d39fb78e4a69899394571f216f_2_10x10.png"></a></div><p></p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/11">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/11</link>
        <pubDate>Sat, 24 Feb 2018 01:02:00 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-11</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[grymoire]]></dc:creator>
        <description><![CDATA[
            <p>This no longer works. The web site now uses JavaScript to defeat scrapers.</p>
<p>p.s. this could have been done in one line:</p>
<p>lynx -dump <a href="http://samair.ru/list/ip-port/%7B1,2,3,4,5,6,7,8,9,10,11%7D.htm" rel="nofollow noopener">http://samair.ru/list/ip-port/{1,2,3,4,5,6,7,8,9,10,11}.htm</a> |grep -Eo ‘[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}:[0-9]{1,5}’</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/10">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/10</link>
        <pubDate>Fri, 23 Feb 2018 13:07:31 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-10</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fxbg]]></dc:creator>
        <description><![CDATA[
            <p>I normally just regex my way across the pages when scraping, with no libraries like beautifulsoup, I just figured this was more lightweight and hacky <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/9">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/9</link>
        <pubDate>Tue, 30 Jan 2018 00:19:50 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-9</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[Techno_Forg]]></dc:creator>
        <description><![CDATA[
            <p>WWW::Mechanize library is what I use in Perl. Basically WWW::Mechanize is kind of like a browser in a script. (<a class="mention" href="https://d.clarkee.co.uk/u/nugget">@nugget</a> please correct me if I’m wrong).</p>
<p>Documentation:<br>
</p><aside class="onebox whitelistedgeneric">
  <header class="source">
      <img src="https://metacpan.org/static/icons/favicon.ico" class="site-icon" width="48" height="48">
      <a href="https://metacpan.org/pod/release/OALDERS/WWW-Mechanize-1.86/lib/WWW/Mechanize.pm" target="_blank" rel="nofollow noopener">metacpan.org</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://metacpan.org/pod/release/OALDERS/WWW-Mechanize-1.86/lib/WWW/Mechanize.pm" target="_blank" rel="nofollow noopener">WWW::Mechanize - Handy web browsing in a Perl object - metacpan.org</a></h3>

<p>Handy web browsing in a Perl object</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>
<p></p>
<p>This is quick and dirty as <a class="mention" href="https://d.clarkee.co.uk/u/pry0cc">@pry0cc</a> stated, but I would think you could do more if you use Perl and WWW::Mechanize. For example, give the option of grabbing all the links in the page with Perl. Of course there are other ways of doing this like Python and ruby, but this is just my preference and my two cents.</p>
<p>Although, this is a really great post. Good Job! Kudos to you.</p>
<p>–Techno Forg–</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/8">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/8</link>
        <pubDate>Mon, 29 Jan 2018 17:43:55 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-8</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fraq]]></dc:creator>
        <description><![CDATA[
            <p>I mean, BS4 is a big install and nokogiri takes more CPU/mem to compile than a DO droplet or an RPi typically has available. I can see why someone might want to use a pure bash solution.</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/7">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/7</link>
        <pubDate>Mon, 29 Jan 2018 16:12:23 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-7</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[pry0cc]]></dc:creator>
        <description><![CDATA[
            <p>Nice post. But why would you do this, when you could parse HTML with nokogiri in ruby? Or beautifulsoup in python? This is indeed quick n dirty, and gets the job done, but if you haven’t checked out either of those, I strongly recommend you to check them.</p>
<p>Scraping is one of my favourite pass-times. I think ruby does it better <img src="https://0x00sec.org/images/emoji/twitter/stuck_out_tongue.png?v=9" title=":stuck_out_tongue:" class="emoji" alt=":stuck_out_tongue:"> <a class="mention" href="https://d.clarkee.co.uk/u/joe_schmoe">@Joe_Schmoe</a> <a class="mention" href="https://d.clarkee.co.uk/u/oaktree">@oaktree</a></p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/6">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/6</link>
        <pubDate>Mon, 29 Jan 2018 15:42:14 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-6</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fxbg]]></dc:creator>
        <description><![CDATA[
            <p>Excellent, thank you</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/5">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/5</link>
        <pubDate>Sun, 28 Jan 2018 20:11:24 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-5</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[oaktree]]></dc:creator>
        <description><![CDATA[
            <p>There is… If you see the edit I made you can see how to do it from now on.</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/4">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/4</link>
        <pubDate>Sun, 28 Jan 2018 20:09:24 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-4</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fxbg]]></dc:creator>
        <description><![CDATA[
            <p>It’s my first post, wasn’t quite sure if the formatting would be okay so I linked it. I added the code to the post now. Is there some kind of syntax highlighting I am missing in the little toolbar?</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/3">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/3</link>
        <pubDate>Sun, 28 Jan 2018 20:06:53 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-3</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[oaktree]]></dc:creator>
        <description><![CDATA[
            <p>Hiya there! Please paste in snippets in addition to (or instead of) just linking a pastebin.</p>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/2">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/2</link>
        <pubDate>Sun, 28 Jan 2018 19:48:39 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-2</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
      <item>
        <title>Simplified Scraping with Lynx, Regex, and Bash</title>
        <dc:creator><![CDATA[fxbg]]></dc:creator>
        <description><![CDATA[
            <h2>LYNX</h2>
<p>I have been into web scraping for a long time, since the first time I realized people will pay for large neatly organized data. I came across something interesting and wanted to pass some knowledge onto others. <a href="http://lynx.invisible-island.net/" rel="nofollow noopener">Lynx is a command line based browser</a>. I first discovered it when I had my first Linux install complete only to realize I needed a desktop and couldn’t quite figure out how to get it going (KDE or Gnome; back when you could get free Linux cd’s from computer shops).</p>
<p>Our script using Lynx and it’s dump option. The dump option pretty much “dumps” the text of the webpage (the stuff you see).</p>
<h2>REGULAR EXPRESSIONS</h2>
<p><a href="https://en.wikipedia.org/wiki/Regular_expression" rel="nofollow noopener">Regular Expressions</a> have been around a very long time, since the 1950’s. Many different variants of the “language” have come about. In working your way through tons of data looking for more specific data, “regex” (regular expressions) is the way to go. It’s not hard to learn regular expressions but it helps to know that the regex you use in PHP isn’t necessarily the regex you will use with grep on the command line.</p>
<h2>BASH SCRIPTING</h2>
<p>All you need is a little bit of bash scripting knowledge. You can find some nice bash tutorials over at <a href="http://ryanstutorials.net/bash-scripting-tutorial/" rel="nofollow noopener">Ryan’s bash tutorials website</a>. The <a href="http://samair.ru" rel="nofollow noopener">samair.ru</a> website has a list of free proxies, not sure if they scan it themselves or rip them from somewhere else but we are gonna rip it from them (with our script at the end) with the help from bash.</p>
<p>We use a simple while loop that increments from 1 to 11. During the loop we will use the counter variable in our URL that we are <strong>dumping</strong> from <a href="http://lynx.invisible-island.net/" rel="nofollow noopener">Lynx</a>. We also use a simple linux command to “bash” our file the proxy sites contents dump into, truncate. The <em>truncate -s 0</em> command will empty our file called plist.</p>
<p>At the end of the script we simply cat out the plist file to our screen and grep the IP’s using our regular expression. There are many ways to go about this and as I sit here and write about it I am thinking of modifying it. It was a simple script and doesn’t need more attention, it does it’s job and the job is done. You can use this script to get the proxies from <a href="http://samair.ru/proxy/" rel="nofollow noopener">samair.ru</a> from it’s 11 free pages it provides. Possibly good to use with <a href="http://proxychains.sourceforge.net" rel="nofollow noopener">proxychains</a>.</p>
<h2>THE SCRIPT</h2>
<pre><code class="lang-auto">#!/bin/bash
truncate -s 0 plist

counter=1
while [ $counter -le 11 ]
do
  lynx -dump http://samair.ru/list/ip-port/$counter.htm &gt;&gt; plist
  ((counter++))
done
cat plist |grep -Eo ‘[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\:[0-9]{1,5}’
</code></pre>
          <p><a href="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/1">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149/1</link>
        <pubDate>Sun, 28 Jan 2018 19:44:46 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-5149-1</guid>
        <source url="https://d.clarkee.co.uk/t/simplified-scraping-with-lynx-regex-and-bash/5149.rss">Simplified Scraping with Lynx, Regex, and Bash</source>
      </item>
  </channel>
</rss>
