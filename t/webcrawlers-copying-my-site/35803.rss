<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Webcrawlers copying my site</title>
    <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803</link>
    <description>I recently created a site that would serve as a personal blog. I noticed that if I google my site&#39;s name, I get an exact copy of it, hosted by someone else.

I&#39;m guessing this is the action of a bot that does this on a large scale for phishing purposes.

That leads to the question: since this bot is copying any files I host on my site and hosting them themselves, does that introduce any vulnerabilities on their end? How would I go about looking for such vulnerabilities?

What is a good way to defend against these sort of bots? Is setting up a honeypot and ip banning an effective strategy?</description>
    
    <lastBuildDate>Fri, 20 Oct 2023 21:11:34 +0000</lastBuildDate>
    <category>Web Hacking</category>
    <atom:link href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[system]]></dc:creator>
        <description><![CDATA[
            <p>This topic was automatically closed after 121 days. New replies are no longer allowed.</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/13">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/13</link>
        <pubDate>Sun, 29 Oct 2023 19:56:17 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-13</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[c0z]]></dc:creator>
        <description><![CDATA[
            <p>Here‚Äôs some iptables rules if you want as well. I‚Äôm making log parser scripts just slowly lol.</p><aside class="onebox allowlistedgeneric" data-onebox-src="https://github.com/Ghost53574/iptables-rules">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">

      <a href="https://github.com/Ghost53574/iptables-rules" target="_blank" rel="noopener nofollow ugc">GitHub</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/345;"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/5/c/5cad24e7d4a472a1636021dafc46a8967277ff38_2_690x345.png" class="thumbnail" width="690" height="345" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/5/c/5cad24e7d4a472a1636021dafc46a8967277ff38_2_690x345.png, https://0x00sec.s3.amazonaws.com/optimized/3X/5/c/5cad24e7d4a472a1636021dafc46a8967277ff38_2_1035x517.png 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/5/c/5cad24e7d4a472a1636021dafc46a8967277ff38.png 2x" data-dominant-color="E6E8E4"></div>

<h3><a href="https://github.com/Ghost53574/iptables-rules" target="_blank" rel="noopener nofollow ugc">GitHub - Ghost53574/iptables-rules: A bash script created for automating the...</a></h3>

  <p>A bash script created for automating the creation of iptables rules and backup of rules I use - GitHub - Ghost53574/iptables-rules: A bash script created for automating the creation of iptables rul...</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/11">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/11</link>
        <pubDate>Wed, 05 Jul 2023 12:52:37 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-11</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[disponat]]></dc:creator>
        <description><![CDATA[
            <p>I installed the ultimate bad bot blocker. I still get see sketchy requests in the logs, but fewer than before I think. Looks like installing fail2ban and setting some rules would help, I‚Äôll spend some time learning that next.</p>
<p>I like the garlic idea of encoding all the content and decoding it after the <code>DOMContentLoaded</code> event fires. I won‚Äôt use it for now, but I‚Äôll keep it in mind.</p>
<p>Thanks for the tips!</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/10">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/10</link>
        <pubDate>Wed, 05 Jul 2023 03:06:30 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-10</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[hoek]]></dc:creator>
        <description><![CDATA[
            <p>Oh just seen this post and wanted to suggest ultimate bad blocker but I see you found it. I am using it in many projects with Nginx and it works great. In <code>blacklist-ips.conf</code> you can add IP clone server and in <code>custom-bad-referrers.conf</code> a domain. It works pretty well.</p>
<p>You can also block image hotlinking in website conf, for example:</p>
<pre><code class="lang-auto">location ~ .(gif|png|jpe?g)$ {
   valid_referers none blocked website.com *.website.com;
   if ($invalid_referer) {
      return 403;
   }
}
</code></pre>
<p>sometimes it broke clone site (I had one situation like this)</p>
<p>but ultimate bad bot blocker is amazing and should be enough.</p>
<p>Analyze you web server logs and check if this is some kind of custom bot with custom user agent, then if custom you can also add it to <code>blacklist-user-agents.conf</code>.</p>
<p>And from time to time search for clones and add them to blacklist.</p>
<p>Let us know if you manage it.</p>
<p>Default configuration protects pretty well from script kiddies, standard tools and well known bots.</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/9">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/9</link>
        <pubDate>Sun, 02 Jul 2023 17:48:46 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-9</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[messede]]></dc:creator>
        <description><![CDATA[
            <aside class="onebox allowlistedgeneric" data-onebox-src="https://github.com/velocitatem/garlic">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">

      <a href="https://github.com/velocitatem/garlic" target="_blank" rel="noopener nofollow ugc">GitHub</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/345;"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/4/2/425404128d128255148e5331454d735b0bcf921b_2_690x345.png" class="thumbnail" width="690" height="345" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/4/2/425404128d128255148e5331454d735b0bcf921b_2_690x345.png, https://0x00sec.s3.amazonaws.com/optimized/3X/4/2/425404128d128255148e5331454d735b0bcf921b_2_1035x517.png 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/4/2/425404128d128255148e5331454d735b0bcf921b.png 2x" data-dominant-color="F6F4F0"></div>

<h3><a href="https://github.com/velocitatem/garlic" target="_blank" rel="noopener nofollow ugc">GitHub - velocitatem/garlic: üßÑüßõ  protect your website from being scraped by...</a></h3>

  <p>üßÑüßõ  protect your website from being scraped by bots. - GitHub - velocitatem/garlic: üßÑüßõ  protect your website from being scraped by bots.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/8">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/8</link>
        <pubDate>Sun, 02 Jul 2023 11:34:11 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-8</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[c0z]]></dc:creator>
        <description><![CDATA[
            <p>You could just add password to the site with the prompt ‚ÄúThe password is: _________‚Äù.</p>
<pre data-code-wrap="js"><code class="lang-plaintext">#https://stackoverflow.com/a/44698584/2901077
function run(){
  var password = prompt("Password is fuckbots");
  if(password != 'fuckbots'){
    document.body.innerHTML = '';
    document.body.innerHTML = 'Password Failed! Reload to Renter Password';
  }else{
    alert('Success');
  }
}
run();
</code></pre>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/7">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/7</link>
        <pubDate>Sun, 02 Jul 2023 09:18:47 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-7</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[disponat]]></dc:creator>
        <description><![CDATA[
            <p>I will leave CAPTCHA as a last resort.</p>
<p>I‚Äôve looked at the access logs and there‚Äôs quite a few requests on there. I‚Äôm certain they are all bots, it‚Äôs a new site, and I don‚Äôt expect any real visitors.<br>
Some examples of requests these requests are:</p>
<ul>
<li>GET /ab2g</li>
<li>‚Äú\x0Bm\xAC\x86{\xD8\xF4\xE7\x19\xA5\xA1n‚Äù  ‚Üí What is this even?</li>
<li>GET /.env</li>
<li>"GET /admin/phpinfo.php</li>
</ul>
<p>I‚Äôve added a little javascript snippet at the top of the site that checks if the domain matches expected and brings up a message if not. The bots copied it as-is. This is what their site looks like now: <a href="https://live.bayeq.xtuplecloud.com/" rel="noopener nofollow ugc">https://live.bayeq.xtuplecloud.com/</a></p>
<p>I don‚Äôt want to disable right clicking, and I‚Äôm not sure it will deter the bots, it‚Äôs likely their method of copying does not depend on right clicking.</p>
<p>I will set up Mitchell Krozga‚Äôs ‚Äúultimate bot blocker‚Äù, and see if that helps.</p><aside class="onebox allowlistedgeneric" data-onebox-src="https://github.com/mitchellkrogza/nginx-ultimate-bad-bot-blocker">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">

      <a href="https://github.com/mitchellkrogza/nginx-ultimate-bad-bot-blocker" target="_blank" rel="noopener nofollow ugc">GitHub</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/345;"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/8/1/81765dfc421359f51cce5b6850afb79953d608cd_2_690x345.png" class="thumbnail" width="690" height="345" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/8/1/81765dfc421359f51cce5b6850afb79953d608cd_2_690x345.png, https://0x00sec.s3.amazonaws.com/optimized/3X/8/1/81765dfc421359f51cce5b6850afb79953d608cd_2_1035x517.png 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/8/1/81765dfc421359f51cce5b6850afb79953d608cd.png 2x" data-dominant-color="E5E8E3"></div>

<h3><a href="https://github.com/mitchellkrogza/nginx-ultimate-bad-bot-blocker" target="_blank" rel="noopener nofollow ugc">GitHub - mitchellkrogza/nginx-ultimate-bad-bot-blocker: Nginx Block Bad Bots,...</a></h3>

  <p>Nginx Block Bad Bots, Spam Referrer Blocker, Vulnerability Scanners, User-Agents, Malware, Adware, Ransomware, Malicious Sites, with anti-DDOS, Wordpress Theme Detector Blocking and Fail2Ban Jail f...</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

<p>The main thing I‚Äôm curious about is if this approach of blindly copying all the files opens them up for attack. For example, if they copy a keylogging application and somehow are exploited to run it. I can‚Äôt think of any way of executing such an attack, but I‚Äôm curious if anyone else has any ideas.</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/5">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/5</link>
        <pubDate>Sat, 01 Jul 2023 19:25:18 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-5</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[disponat]]></dc:creator>
        <description><![CDATA[
            <p>I  set up a robots.txt to look like this:<br>
User-agent: *<br>
Disallow: /about</p>
<p>I don‚Äôt mind search engines crawling my site to index it, I just don‚Äôt want it to be copied. Is there a way robots.txt can achieve that?</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/4">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/4</link>
        <pubDate>Sat, 01 Jul 2023 18:45:38 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-4</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[tiz45]]></dc:creator>
        <description><![CDATA[
            <p>robots.txt ? antibots ?</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/2">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/2</link>
        <pubDate>Fri, 30 Jun 2023 23:56:42 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-2</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
      <item>
        <title>Webcrawlers copying my site</title>
        <dc:creator><![CDATA[disponat]]></dc:creator>
        <description><![CDATA[
            <p>I recently created a site that would serve as a personal blog. I noticed that if I google my site‚Äôs name, I get an exact copy of it, hosted by someone else.</p>
<p>I‚Äôm guessing this is the action of a bot that does this on a large scale for phishing purposes.</p>
<p>That leads to the question: since this bot is copying any files I host on my site and hosting them themselves, does that introduce any vulnerabilities on their end? How would I go about looking for such vulnerabilities?</p>
<p>What is a good way to defend against these sort of bots? Is setting up a honeypot and ip banning an effective strategy?</p>
          <p><a href="https://0x00sec.org/t/webcrawlers-copying-my-site/35803/1">Read full topic</a></p>
        ]]></description>
        <link>https://0x00sec.org/t/webcrawlers-copying-my-site/35803/1</link>
        <pubDate>Fri, 30 Jun 2023 03:55:20 +0000</pubDate>
        <guid isPermaLink="false">0x00sec.org-post-35803-1</guid>
        <source url="https://0x00sec.org/t/webcrawlers-copying-my-site/35803.rss">Webcrawlers copying my site</source>
      </item>
  </channel>
</rss>
