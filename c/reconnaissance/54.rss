<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:discourse="http://www.discourse.org/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Reconnaissance - 0x00sec - The Home of the Hacker</title>
    <link>https://0x00sec.org/c/reconnaissance/54</link>
    <description>Topics in the &#39;Reconnaissance&#39; category </description>
    
      <lastBuildDate>Fri, 17 Nov 2023 08:50:08 +0000</lastBuildDate>
      <atom:link href="https://0x00sec.org/c/reconnaissance/54.rss" rel="self" type="application/rss+xml" />
        <item>
          <title>Nmap --proxies not working</title>
          <dc:creator><![CDATA[ADORE]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>I  try to scan ports over tor using nmap<br>
It’s scaning the target.</p>
<p>nmap --proxies socks4://127.0.0.1:9050<br>
<a href="http://www.example.com" class="onebox" target="_blank" rel="noopener nofollow ugc">www.example.com</a></p>
<p>But when i stop tor service and then try to scan with same command its still working no error showing.</p>
<pre><code>   nmap --proxies socks4://127.0.0.1:9050 www.example.com
</code></pre>
<p>Why???<br>
Why???<br>
Whyyyyyyyyyyyyy???/??//?/???/??/???/???</p>
            <p><small>7 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/nmap-proxies-not-working/37942">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/nmap-proxies-not-working/37942</link>
          <pubDate>Fri, 17 Nov 2023 08:50:08 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-37942</guid>
          <source url="https://0x00sec.org/t/nmap-proxies-not-working/37942.rss">Nmap --proxies not working</source>
        </item>
        <item>
          <title>Info gathering - Steam / Discord</title>
          <dc:creator><![CDATA[33three33]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello all,</p>
<p>Looking for some basic/summary advice about how to identify accounts from various sources (steam forums/discord users etc).<br>
I’m basically trying to highlight some bad actors on steam who are managing to mass-ban honest users by using multiple sock puppet accounts to report and ban others</p>
<p>I’m not sure how to go about this so looking for basic advice on what I should start to learn to put together an info-pack / build up information.</p>
<p>I have some very basic knowledge from some online courses on ethical hacking/security but getting a little lost in how I would approach this task.</p>
<p>Before posting it says this is a similar topic to gathering sensitive info/doxxing. Whilst I am not interested in any financial gain or highlighting in public any bad actors, my aim is to gather info and provide this direct to the companies themselves to enable them to take action on the bad actors.  Simple reporting is not enough in this case.</p>
<p>Any help would be appreciated - thanks in advance</p>
            <p><small>8 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/info-gathering-steam-discord/36213">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/info-gathering-steam-discord/36213</link>
          <pubDate>Mon, 31 Jul 2023 07:48:28 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-36213</guid>
          <source url="https://0x00sec.org/t/info-gathering-steam-discord/36213.rss">Info gathering - Steam / Discord</source>
        </item>
        <item>
          <title>How we can scan port manually?</title>
          <dc:creator><![CDATA[ADORE]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello Guys,</p>
<p>i started learning hacking.<br>
I want to know how we can scan TCP and UDP ports  Manually. i am not saying any kind of tool like nmap or any scanning tool.</p>
<p>If anyone have this kind knowledge please help me out.</p>
            <p><small>7 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/how-we-can-scan-port-manually/33572">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/how-we-can-scan-port-manually/33572</link>
          <pubDate>Wed, 22 Feb 2023 04:24:13 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-33572</guid>
          <source url="https://0x00sec.org/t/how-we-can-scan-port-manually/33572.rss">How we can scan port manually?</source>
        </item>
        <item>
          <title>The Dilemma of Attacking Okta, Red Team Operations</title>
          <dc:creator><![CDATA[camel]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <h1>
<a name="introduction-1" class="anchor" href="https://0x00sec.org#introduction-1"></a>Introduction</h1>
<p><img src="https://0x00sec.s3.amazonaws.com/original/3X/a/8/a8dae437780636a0e50643872b79bb4266f7eabf.png" alt="Intro-Login" data-base62-sha1="o5LbE5UQIzXXNxNvYM0irOxeYI7" width="383" height="321"></p>
<p>An ominous login page, mysterious isn’t it? This page is seen by hundreds of employees/customers of companies like Discord, Microsoft, Paypal, GoDaddy, Roblox, etc. This is an Okta login page, successfully authenticating yourself with one of these will usually redirect you to a companies internal services, such as: Jira, Confluence, Metrics systems, the whole shebang!</p>
<h1>
<a name="okta-2" class="anchor" href="https://0x00sec.org#okta-2"></a>Okta?</h1>
<p>Okta is “an American identity and access management company” that allows companies to easily manage and control access to different parts of their infrastructure. Okta is usually used to authorize and manage access to <em>internal services</em>. As a hacker this information is very valuable; so many attack vectors include Okta access as a prerequisite, or even an end goal.</p>
<h2>
<a name="the-authentication-dilemma-3" class="anchor" href="https://0x00sec.org#the-authentication-dilemma-3"></a>The Authentication Dilemma</h2>
<p>Given all thats on the table for Okta, and the companies that are involved, Okta has their work cut out for them in terms of keeping employee accounts safe.</p>
<p>Okta offers many authorization methods, some examples include:</p>
<ul>
<li>
<p>Basic <code>username:password</code> Pairing</p>
</li>
<li>
<p>Common 2FA: Google Authenticator, Email, SMS, etc.</p>
</li>
<li>
<p>MFA (biometrics, location information, YubiCo’s YubiKey)</p>
</li>
<li>
<p>3rd Party Auth Services: <a href="https://developer.okta.com/docs/api/resources/oidc" rel="noopener nofollow ugc">Oauth</a>, <a href="https://developer.okta.com/docs/api/resources/oidc" rel="noopener nofollow ugc">OpenID</a>, <a href="https://www.okta.com/integrate/documentation/saml/" rel="noopener nofollow ugc">SAML</a> and <a href="https://www.okta.com/security-blog/2019/01/understanding-fido-standards-your-go-to-guide/" rel="noopener nofollow ugc">FIDO</a>.</p>
</li>
<li>
<p>Customized API/HTTP Auth</p>
</li>
</ul>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/6/8/68f66a57359283862fb4711052a8fa14368f4a7e.jpeg" data-download-href="/uploads/short-url/eYxBamUNOjOGktn9sms1o9lQTPU.jpeg?dl=1" title="Auth-Methods, 75%" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/6/8/68f66a57359283862fb4711052a8fa14368f4a7e_2_690x164.jpeg" alt="Auth-Methods, 75%" data-base62-sha1="eYxBamUNOjOGktn9sms1o9lQTPU" width="690" height="164" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/6/8/68f66a57359283862fb4711052a8fa14368f4a7e_2_690x164.jpeg, https://0x00sec.s3.amazonaws.com/optimized/3X/6/8/68f66a57359283862fb4711052a8fa14368f4a7e_2_1035x246.jpeg 1.5x, https://0x00sec.s3.amazonaws.com/optimized/3X/6/8/68f66a57359283862fb4711052a8fa14368f4a7e_2_1380x328.jpeg 2x" data-dominant-color="F4F8F9"></a></div><br>
This is perfect for companies that try their best to be as secure as possible, but for attackers this is yet another hoop that you have to jump through in order to achieve that initial access you are depending on.<p></p>
<h1>
<a name="attacking-okta-authentication-4" class="anchor" href="https://0x00sec.org#attacking-okta-authentication-4"></a>Attacking Okta Authentication</h1>
<p>Trying to gain unauthorized access to ANY okta account may seem like trying to infiltrate Fort Knox. But like all things let’s try to break this big problem down into smaller problems:</p>
<ul>
<li>
<p>Accessing Employee Information (usernames, corporate emails, phone numbers)</p>
</li>
<li>
<p>Accessing Employee Credentials (passwords)</p>
</li>
<li>
<p>Accessing Needed MFA Vessels (2FA Codes, Physical Tokens, Biometrics)</p>
</li>
</ul>
<p>Now once again the first two aren’t that hard. Some mass phishing or remote access would do the trick. The main issue is companies that use fairly secure authorization methods, a perfect example of this of YubiCo’s YubiKey.</p>
<p>They are the “un-phishible” hardware authorization solutions. <strong>Google, Amazon, Microsoft, Twitter, and Facebook</strong> all use YubiKey to add an extra  layer of security to both employee and end user accounts, but we will talk about them later.</p>
<h1>
<a name="the-actually-secure-companies-5" class="anchor" href="https://0x00sec.org#the-actually-secure-companies-5"></a>The Actually Secure Companies</h1>
<p>Some companies only use common <code>username:password</code> login systems, maybe 2FA using Google Authenticator/SMS. Most adversaries can easily get past this using an Adversary in The Middle <a href="https://www.hypr.com/security-encyclopedia/adversary-in-the-middle" rel="noopener nofollow ugc">(AiTM)</a> attack with a service like <a href="https://github.com/kgretzky/evilginx2" rel="noopener nofollow ugc">Evilginx2</a>.</p>
<p>Actually secure companies use hardware/biometric solutions. These are by far some of the most secure authorization solutions on the market. it seems as hardware based solutions are the best of the two, due to the simple fact biometrics can be easily stolen/reproduced (<a href="https://getsmarteye.com/stolen-fingerprints-data-can-sabotage-your-biometric-security/" rel="noopener nofollow ugc">article on the topic</a>).</p>
<p>Back to hardware solutions, why are they so secure? This is something that only the employee has access to this solution. There is also a “single origin verification protocol” that makes phishing these keys even harder.</p>
<h2>
<a name="yubikey-rage-6" class="anchor" href="https://0x00sec.org#yubikey-rage-6"></a>YubiKey <img src="https://0x00sec.org/images/emoji/twitter/rage.png?v=12" title=":rage:" class="emoji" alt=":rage:" loading="lazy" width="20" height="20">
</h2>
<p>YubiKeys use a protocol known as “origin binding”, in lay-mans terms: when a key is registered is in binded to a certain domain, so if you try logging in on another domain, your key wont allow it.</p>
<p>What happens is the browser signs the request to the security token with the website URL. The security token’s response based on the secret includes this as a result. So if you try to login to <code>d0main.com</code> instead of <code>domain.com</code> and get a U2F 2nd factor auth, the browser will generate a request based on <code>d0main.com</code>. Even if the malicious site, <code>d0main.com</code>, copied/repeated the public key info for the second factor auth request from <code>domain.com</code>, the browser would hash and sign the request as coming from <code>d0main.com</code> as a result. The resulting login token would not match up with what <code>domain.com</code> expected. The login would fail. - <a href="https://news.ycombinator.com/item?id=32417755" rel="noopener nofollow ugc">YCombinator thread</a></p>
<p>This simple check pretty much stops attackers from phishing YubiKeys. Of course that statement is only true in a perfect world, there could always be a vulnerability in the keys firmware, or in the browser itself (which is the intermediary between the login page and the key itself). An article on Chrome’s WebUSB is linked below:</p>
<aside class="onebox allowlistedgeneric" data-onebox-src="https://www.wired.com/story/chrome-yubikey-phishing-webusb/">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/3X/c/4/c49bc509162c703076794befafd04c2e4c3a534a.png" class="site-icon" width="16" height="16">

      <a href="https://www.wired.com/story/chrome-yubikey-phishing-webusb/" target="_blank" rel="noopener nofollow ugc" title="04:54PM - 01 March 2018">WIRED – 1 Mar 18</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/361;"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/e/d/ed09db3f1b885165b23c3c55bd25ef9b8436bc4c_2_690x361.jpeg" class="thumbnail" width="690" height="361" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/e/d/ed09db3f1b885165b23c3c55bd25ef9b8436bc4c_2_690x361.jpeg, https://0x00sec.s3.amazonaws.com/optimized/3X/e/d/ed09db3f1b885165b23c3c55bd25ef9b8436bc4c_2_1035x541.jpeg 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/e/d/ed09db3f1b885165b23c3c55bd25ef9b8436bc4c.jpeg 2x" data-dominant-color="05663C"></div>

<h3><a href="https://www.wired.com/story/chrome-yubikey-phishing-webusb/" target="_blank" rel="noopener nofollow ugc">Chrome Lets Hackers Phish Even 'Unphishable' Yubikey Users</a></h3>

  <p>While still the best protection against phishing attacks, some Yubikey models are vulnerable after a recent update to Google Chrome.</p>


  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

<h1>
<a name="an-un-patchable-vulnerability-7" class="anchor" href="https://0x00sec.org#an-un-patchable-vulnerability-7"></a>An Un-patchable Vulnerability</h1>
<p>With the concurrent growth of both employee security and the value of internal access, it is no longer uncommon to phish employees. But why take the time of your day to phish employees with a low success rate. when you can take a variate amount of time to extort/blackmail employees with a much higher success rate.</p>
<p>There are plenty of things certain people have to hide from their employers, but this is up to you, as a red teamer, to find.</p>
<h1>
<a name="fin-8" class="anchor" href="https://0x00sec.org#fin-8"></a>Fin</h1>
<p>What do you all think about Okta as an authentication service? Let everyone know!</p>
            <p><small>5 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/the-dilemma-of-attacking-okta-red-team-operations/32393">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/the-dilemma-of-attacking-okta-red-team-operations/32393</link>
          <pubDate>Tue, 06 Dec 2022 00:23:05 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-32393</guid>
          <source url="https://0x00sec.org/t/the-dilemma-of-attacking-okta-red-team-operations/32393.rss">The Dilemma of Attacking Okta, Red Team Operations</source>
        </item>
        <item>
          <title>Advanced Axiom Usage - axiom-scan</title>
          <dc:creator><![CDATA[pry0cc]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hey 0x00ers!</p>
<p>You may have heard of the tool I’ve been working on for the past 6 months called axiom, incase you haven’t, I’ll provide you with a quick overview.</p>
<p><a href="https://github.com/pry0cc/axiom">https://github.com/pry0cc/axiom</a></p>
<blockquote>
<p>The dynamic infrastructure framework for anybody! Distribute the workload of many different tools with ease, including nmap, ffuf, masscan, nuclei and many more!</p>
</blockquote>
<p>Axiom is a larger infrastructure framework that allows you to quickly spin up and down different hackbox hosts packed with tools for you to perform testing. Axiom instances have tools preinstalled including nmap, ffuf, masscan, nuclei, subfinder, httpx, dnsx and shuffledns (and many more!). You can also spin up lots of hosts at one time by using axiom-fleet.</p>
<p>Once you have a fleet, you can perform distributed scanning! It’s really up to you how you want to use it.</p>
<p>If you’re new to axiom, I recommend reading the wiki in its entirety - and remember - it’s still in Beta, we’re still really just prototyping <img src="https://0x00sec.org/images/emoji/twitter/stuck_out_tongue.png?v=9" title=":stuck_out_tongue:" class="emoji" alt=":stuck_out_tongue:"> If you find any issues, please open an issue, it’s probable that we can fix it!</p>
<p><a href="https://github.com/pry0cc/axiom/wiki">https://github.com/pry0cc/axiom/wiki</a></p>
<p>This article is intended for existing users, I will not explain the code too much but provide a basic example of how you can use it. I’d like for current users of axiom to try these out and follow along.</p>
<hr>
<h1>Just axiom-scan</h1>
<p>Spin up a fleet with more than 2 instances, you can find out how to do this here: <a href="https://github.com/pry0cc/axiom/wiki/Fleets">https://github.com/pry0cc/axiom/wiki/Fleets</a>. I’ll let the code speak for the rest of a demo for axiom-scan, feel free to follow on with this demo:</p>
<h3>Step 1 - Download Chaos Subdomains</h3>
<p>Download subs from here: <a href="https://chaos.projectdiscovery.io/#/">https://chaos.projectdiscovery.io/</a></p>
<p>We need to get some data to test with!</p>
<pre><code class="lang-bash"># Pull random 50 root levels from chaos - pretty one liner
for domain in $(curl -s https://raw.githubusercontent.com/projectdiscovery/public-bugbounty-programs/master/chaos-bugbounty-list.json | jq -r '.programs[].domains[]' | shuf | head -n 50); do echo "Pulling $domain"; chaos -silent -key $token -d $domain &gt;&gt; subs.txt; done

wc -l subs.txt
</code></pre>
<h3>Step 2 - Merge Subdomains together</h3>
<pre><code class="lang-bash">cd ~/Downloads

mkdir demo
mv chaos* demo
cd demo

# Unzip
unzip chaos*

# Show files
ls

find . -name '*.txt' -exec cat {} \; &gt; allsubs.txt
</code></pre>
<h3>Step 3 - Spin up a fleet (may already be prepared)</h3>
<pre><code class="lang-bash">axiom-fleet fire -i=15
axiom-select 'fire*'
axiom-ls
</code></pre>
<h3>Step 4 - Resolve Subdomains</h3>
<p>We can resolve subdomains at mass using <code>dnsx</code></p>
<pre><code class="lang-bash">Code - Bash

axiom-scan allsubs.txt -m dnsx -resp -o resolvedfqdns.txt # simple

add resolvers
</code></pre>
<h3>Step 5  - Nmap IP’s</h3>
<p>We can do some portscanning with nmap in a distributed axiom-scan.</p>
<h3>Ports</h3>
<p><code>80,81,443,591,2082,2087,2095,2096,3000,8000,8001,8008,8080,8083,8443,8834,8888</code></p>
<blockquote>
<p>Note <img src="https://0x00sec.org/images/emoji/twitter/firecracker.png?v=9" title=":firecracker:" class="emoji" alt=":firecracker:"> nmapx doesn’t work with old versions of interlace</p>
</blockquote>
<pre><code class="lang-bash"># Experimental
axiom-scan ips.txt -m nmapx -p80,81,443,591,2082,2087,2095,2096,3000,8000,8001,8008,8080,8083,8443,8834,8888 -oX chaos-scan.xml
axiom-scan ips.txt -m nmapx --top-ports 5 -sV -oX chaos-scan.xml

# Tried and true (the old way, slower)
axiom-scan ips.txt -m nmap -p80,81,443,591,2082,2087,2095,2096,3000,8000,8001,8008,8080,8083,8443,8834,8888 -oX chaos-scan.xml
</code></pre>
<h3>Step 6 - Extracting hosts &amp; IP’s from Nmap XML output</h3>
<p>Essentially convert nmap.xml → host:ip notation.</p>
<pre><code class="lang-bash">&gt; ports.txt
wget https://gist.githubusercontent.com/pry0cc/dd2e7955d0a0222eb6c09cb283a6d614/raw/3c7bd4c20bb7649a944a36507073d9c9ab4100d8/ports.py
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python2 get-pip.py
python2 -m pip install python-libnmap
python2 ports.py chaos-scan.xml &gt; ports.txt

head -n 100 ports.txt
wc -l ports.txt
</code></pre>
<blockquote>
<p>READ THE HTML OUTPUT! It looks totally cool… <img src="https://0x00sec.org/images/emoji/twitter/fire.png?v=9" title=":fire:" class="emoji" alt=":fire:"></p>
</blockquote>
<p>Axiom-scan xml nmap scans auto generate html output too!</p>
<p>(You must have xsltproc installed :))</p>
<pre><code class="lang-bash">xdg-open chaos-scan.xml.html
</code></pre>
<h3>Step 7 - Scanning port combos with httpx</h3>
<p>Using the file we created earlier.</p>
<pre><code class="lang-bash">axiom-scan ports.txt -m httpx -o http.txt
</code></pre>
<h3>Step 8 - Gowitness</h3>
<blockquote>
<p>Use a shortened sample for gowitness just because it takes foreverrrr otherwise!</p>
</blockquote>
<pre><code class="lang-bash">cat http.txt | shuf | head -n 150
cat http.txt | shuf | head -n 150 &gt; sample-http.txt

axiom-scan sample-http.txt -m gowitness -o screenshots
</code></pre>
<h3>Step 9 - Run httpx on subs</h3>
<p>Convert ip:port notation into <a href="http://ip:port/" rel="noopener nofollow ugc">http://ip:port/</a> notation for using our other tools.</p>
<pre><code class="lang-bash">cat allsubs.txt | shuf | head -n 500 
cat allsubs.txt | shuf | head -n 500 &gt; subs.txt

axiom-scan subs.txt -m httpx -o http.txt -title -follow-redirects -ip -content-length -cname -content-type -status-code -vhost
</code></pre>
<h1>Axiom-proxy</h1>
<p>Start a proxy round-robin listener against all our nodes in our fleet.</p>
<pre><code class="lang-bash">axiom-proxy 'fire*' --single
</code></pre>
<blockquote>
<p>Run curl over and over again  to show it’s different ips</p>
</blockquote>
<blockquote>
<p>This proxy can be used in burp <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
</blockquote>
<pre><code class="lang-bash">curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq
curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq -c
curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq -c
curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq -c
curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq -c
curl --socks5-hostname 127.0.0.1:1337 https://ipinfo.io | jq -c
</code></pre>
<h1>Axiom-exec</h1>
<blockquote>
<p>Get a list of all the hosts</p>
</blockquote>
<pre><code class="lang-bash">axiom-exec 'curl -s ifconfig.me' 'fire*'
</code></pre>
<h1>Axiom-rm</h1>
<p>Finally, we can delete our fleet so it doesn’t cost us any $$$. Easy as that!</p>
<pre><code class="lang-bash">axiom-rm 'fire*' -f
</code></pre>
<h1>Conclusion</h1>
<p>Today we’ve demonstrated a few ways of executing distributed scans using axiom-scan, I hope this was informative! I hope you enjoy axiom! &lt;3 Enjoy 0x00ers!</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/advanced-axiom-usage-axiom-scan/24600">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/advanced-axiom-usage-axiom-scan/24600</link>
          <pubDate>Sat, 16 Jan 2021 17:17:20 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-24600</guid>
          <source url="https://0x00sec.org/t/advanced-axiom-usage-axiom-scan/24600.rss">Advanced Axiom Usage - axiom-scan</source>
        </item>
        <item>
          <title>OSINT - Lamprey</title>
          <dc:creator><![CDATA[hostile.node]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello everyone.</p>
<p>I was doing some volunteer work recently and there was a situation which involved performing a rather large number of Google searches for cross-referencing purposes and potential leak identification. The concept of performing &gt;20k queries manually didn’t appeal.</p>
<p>I’ve created a small tool (<a href="https://www.pedro-nunes.net/?p=562" rel="nofollow noopener">Lamprey</a>) to do the heavy lifting for me. Takes in N lists of queries, performs a combinatorial expansion and outputs a summary and the top 10 results for any matching hits. The outputs are in .csv so it can be analysed further in other programs.</p>
<p><span alt="image" data-base62-sha1="xFFgTs1k4IixEuv0nI8dAPCxZEb" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>However, one thing I wanted to point out the community towards is that Google offers US$300 in credit with their platform. I’ve written a document on how to set up a <a href="https://gitlab.com/hostile.node/lamprey/-/wikis/Custom-Search-Engine-setup" rel="nofollow noopener">Custom Search Engine in the project’s wiki</a>, which you can leverage for other projects. It’s just a JSON API, so once it is set up it is quite straightforward to use.</p>
<p>GPL as usual, source’s here: <a href="https://gitlab.com/hostile.node/lamprey" rel="nofollow noopener">https://gitlab.com/hostile.node/lamprey</a></p>
<p>Hopefully of use to someone.</p>
<p><em>- hostile.node</em></p>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/osint-lamprey/19477">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-lamprey/19477</link>
          <pubDate>Tue, 25 Feb 2020 11:12:54 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-19477</guid>
          <source url="https://0x00sec.org/t/osint-lamprey/19477.rss">OSINT - Lamprey</source>
        </item>
        <item>
          <title>Rabbit Hole - simple node graph creator</title>
          <dc:creator><![CDATA[hostile.node]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello all.</p>
<p>I’m a fairly visual person when handling information - I get a great deal out of visualising it and it helps me keep track of routes which have not been fully explored. I’ve been using Maltego (Community Edition) to map some of the Hack The Box machines but I’ve both run into issues with the mandatory logging in and with the limitation of having processors return a maximum of 12 nodes.</p>
<p>I’ve decided to create something which provided me with the functionality I needed and that I could expand as required.</p>
<p><span alt="68747470733a2f2f692e6779617a6f2e636f6d2f65383763303463666534383539356233666636346138653662376538646566322e706e67" data-base62-sha1="3JPyUGEkr9ls5KvuGJqpv5uwduA" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>I thought I’d share it with you in case it is of use to other people. It works both for Windows and Linux, and can be downloaded from here: <a href="https://gitlab.com/hostile.node/rabbithole" rel="nofollow noopener">https://gitlab.com/hostile.node/rabbithole</a></p>
<p>Windows prebuilt binaries are available here: <a href="https://pedro-nunes.net/downloads/Rabbit_Hole_0.1.zip" rel="nofollow noopener">https://pedro-nunes.net/downloads/Rabbit_Hole_0.1.zip</a></p>
<p>I’m planning on allowing users to create new custom nodes, as well as extend it so scripts (Python, likely) can create new nodes on the fly, such as e.g. nmapping an address.</p>
<p>Let me know if you find it handy or if you have any thoughts <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
<p>Cheers<br>
– hostile.node</p>
            <p><small>4 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/rabbit-hole-simple-node-graph-creator/17066">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/rabbit-hole-simple-node-graph-creator/17066</link>
          <pubDate>Sun, 20 Oct 2019 21:26:32 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-17066</guid>
          <source url="https://0x00sec.org/t/rabbit-hole-simple-node-graph-creator/17066.rss">Rabbit Hole - simple node graph creator</source>
        </item>
        <item>
          <title>OSINT / OPSec: First Lessons (My Way)</title>
          <dc:creator><![CDATA[Zentreax]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hi there, and welcome to a little introduction into OSINT and OPSec. First off, how would we define the two?</p>
<p>OSINT is</p>
<p><strong>O</strong> pen <strong>S</strong> ource <strong>INT</strong> elligence</p>
<p>and OPSec is</p>
<p><strong>Op</strong> erational <strong>S</strong> ecurity</p>
<p>Pretty easy so far, right? (Btw, this is my first ever blog post like this, please give me some feedback!) However, they’re very important to you, your privacy, and your rights. Why you may ask, well that’s a damn good question! Let me tell you why. To begin, OSINT is used by military and government, cyber security enthusiasts, professionals, and even amateurs alike. There are many tools out there that allow people to use the public information provided by yourself on the internet to compile the data together and use it for what they will, albeit legal, or illegal purposes. One of these great tools (or terrible depending on perspective), would be the <a href="https://osintframework.com/" rel="nofollow noopener">OSINT Framework.</a> You see, something like this is both free, and available to the public. With the right mindset, and know how, and you could compromise someone’s data. This affects anyone, and everyone using the internet. So how do you protect yourself? Yet another great question! There are several ways to protect yourself.</p>
<ul>
<li>Start with not putting the information there to begin with.</li>
</ul>
<p>Don’t list every possible detail on your Facebook, Instagram and <a href="https://0x00sec.org">Twitter</a> account. All of this altogether should be disposed of, as they collect and abuse your personal data anyhow.</p>
<ul>
<li>
<strong>Don’t</strong> click dodgy links.</li>
</ul>
<p>This one should be a no-brainer but I often have to remind, even the most educated members of the internet to NOT click an obvious ip logger, even for shits and giggles, because you’re taking the obvious bait on the hook. Don’t be a sitting fish!</p>
<ul>
<li>Do what many call an “Anti-Dox”</li>
</ul>
<p>Try to dox yourself, and find your personal information, request to remove it, and fix your accounts. Set them to private and DELETE THE EVIDENCE. It’s also good to check the <a href="https://web.archive.org/" rel="nofollow noopener">Wayback Machine, an internet archive.</a></p>
<ul>
<li>Finally, common sense goes a long way. That will protect you better than most options. If you think of the information you’re putting online, and really consider the consequences, you will at least be making an informed decision. Which is better than a hasty, or impulse decision.</li>
</ul>
<p>Next lesson will be more in detail about opsec. Be sure to check out other threads and feel free to ask questions down below!</p>
            <p><small>4 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/osint-opsec-first-lessons-my-way/16633">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-opsec-first-lessons-my-way/16633</link>
          <pubDate>Tue, 01 Oct 2019 21:46:00 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-16633</guid>
          <source url="https://0x00sec.org/t/osint-opsec-first-lessons-my-way/16633.rss">OSINT / OPSec: First Lessons (My Way)</source>
        </item>
        <item>
          <title>My Personal OSINT Techniques, Part 1 of 2: Key &amp; Layer, Contingency Seeding</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>We live in a world that is hyper communicative, with much of this  communication occurring on the Internet.</p>
<p>On the Internet, companies/products want to communicate their value to customers and people want to communicate with other people.</p>
<p>Open Source Intelligence (OSINT) is a byproduct of these online communications, and as the quantity of these communication continue to increase, the resources that yield OSINT will also increase.</p>
<p>In hacking (a term that I include Red Teaming and Penetration Testing in), we weaponize information through the application of our experience, intelligence, strategy, creativity and  tooling.</p>
<p>This capacity is a major distinction that separates an experienced hacker from most other users on the Internet.</p>
<p>For example: if a normal user accesses log files on a misconfigured web server and an experienced hacker accesses those same logs on that same host, what is the difference between the two users in this crude example?</p>
<p>The hacker has the capacity to convert the data on those log files into a resource that could allow them to access the web server and/or other hosts on the network (or beyond it).</p>
<p>OSINT is the real world equivalent of these metaphorical log files mentioned above, except it seems like every user and company on the Internet is writing their own log files…</p>
<p>And they seem to leave these log files they write for themselves all over the Internet.</p>
<p>OSINT is usually gathered for the purpose of analysis/reporting and is refined through any number of well defined processes. This yields intelligence that can be applied toward answering a specific question or deciding/reinforcing an appropriate response or path of action.</p>
<p>Below: The image provides an examples of a processes used to gather, analyze and refine OSINT.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/2/2de71eb7326ccbab8eeeb097f1b6fd23b29dd6e7.png" alt="050916_2237_TheArtofSea1" data-base62-sha1="6y4EP51eLIZG8u0aMI2R7Y7l6OH" width="580" height="367"></p>
<p>OSINT as a hacking/Red Team/penetration testing resource can yield a great number of resources that can be leveraged for enumeration and exploitation during an operation/engagement.</p>
<p>This data is usually much more information dense then the output provided by tooling such as a portscan or vulnerability scanner.</p>
<p>However, this data also tends to require more time to process effectively…it generally cannot be put into direct action as quickly as other data types due to the extra analysis/critical thinking needed to process it.</p>
<p>This is because OSINT often consists of what I call “layers”; sometimes these layers consist  of data that targets contribute themselves.</p>
<p>Examples of the layers that targets can contribute to OSINT include things like metadata, overt/underlying conditions conveyed by the the wording of a target’s expression(s) and opportunities to better identify/quantify a target’s relationships (and the condition/nature of those relationships).</p>
<p>This is the real trick of making OSINT work during offensive operations/engagements: extracting the most relevant advantages possible from the layers of data provided without the time periods or logistical resources that most conventional processes for working with OSINT assume.</p>
<p>For an added bonus, OSINT tends to be an excellent resource for providing us with contingencies, which are infinitely useful when making decisions on things like target acquisition.</p>
<p>These contingencies can be a real boon for recouping time/energy lost in pursuing rabbit holes and/or running into dead ends, all of which happen to the best of us from time to time.</p>
<p>Two of the personal strategies I utilize most when working with OSINT during engagements include “Key and Layer” and “Contingency Seeding”.</p>
<p>I will demonstrate both processes (as well as some other methodologies, resources and tactics I use when working with OSINT) by detailing a real world example from an engagement I ran against a corporate client.</p>
<p><strong>Key and Layer, Contingency Seeding: Maximizing OSINT for Hacking/Red Team/Penetration Testing</strong></p>
<p>During an engagement I utilized Google Dorking to discover the archives of an internal mailing list that belonged to the target company; it was publicly accessible on the Internet.</p>
<p>This was an ongoing archive that contained well over a decades worth of internal emails, some of which were employee to employee communications and others that were employee to client/customer communications.</p>
<p>This archive contained thousands of emails, the earliest of which dated back to 2001 with the most current dating just days before the engagement began.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/16bae24277e8f1d73a1e45c713687f48a1ae8a18.png" alt="osint1" data-base62-sha1="3f4TRPQoNzcym1RZZWWhwGzuDB6" width="685" height="500"></p>
<p>By accident or on purpose, the majority of companies I’ve engaged keep some manner of OSINT rich archives sitting somewhere on the Internet, publicly available.</p>
<p>I found the archive in the image above after reading online user manuals for a network solution the target developed. I knew from reading blogs on the target’s sites that they used this solution in most of their own networks besides selling it as a managed and unmanaged solution to their customers/clients.</p>
<p>One of the manuals for this solution stated that it used default/hardcoded credentials with a username that I had never seen before; a fair approximation of this username would be <strong>XYZuser</strong>.</p>
<p>Searching the Internet for material that contained the default/hardcoded password used alongside the username, I used manual Google Dorking against the string <strong>intext:xyzuser</strong>.</p>
<p>Below: Manual Google Dorking against the string intext:xyzuser uncovered an indexed entry that led to the e-mail archive. This entry also displayed the username I searched for plus its matching password (redacted in red).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/5/5d1c1171721e02bb1c991f7b141fdf5ba5b19f8d.png" alt="osint2A1" data-base62-sha1="dhGxvwptIT7TrF7lbKi0PyrrVdH" width="690" height="166"></p>
<p>The archive included a “Search this archive” function, which I used to search the archive for keywords like “password”, “credentials” and “Administrator”.</p>
<p>A search using the word “password” located hundreds of archived emails like the one pictured below   (many of which contained credentials).</p>
<p>We will use the “Key and Layers” process against one of the archived emails I found (shown below) to demonstrate the capacity of the technique to help extract many of the advantages/resources an instance of OSINT can provide.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/3/3275f42fa534a87a86764b54abf78e01c9b372c5.png" alt="osintemail1a" data-base62-sha1="7coAu8qfuXmgNrIA0LieFmrLtU9" width="503" height="500"><br>
<img src="https://0x00sec.s3.amazonaws.com/original/2X/7/7a54304177b1b8bc84d2d38d100f3900984ef131.png" alt="osintemail4a" data-base62-sha1="hsaCIheaS7XtMVv4uOwLj7dnMsN" width="534" height="475"><br>
<img src="https://0x00sec.s3.amazonaws.com/original/2X/2/242e1b75185d8de734ca8ce1d370fe5a4ae4fa03.png" alt="osintemail6" data-base62-sha1="5a3YlgMZpoQVyr8mV4MWEk1l58n" width="629" height="500"></p>
<p>The first step of this process is to evaluate this instance of OSINT for the primary, most visible advantage/resource it provides (the “Key” advantage).</p>
<p><strong>NOTE:</strong> I had already established a Key value for the archive as a whole at this point, based on the set of credentials I found via the Google search indexed entry above: the Key value of the archive was that it contained emails containing credentials.</p>
<p><strong>The Key value is important for many reasons, a few of which include:</strong></p>
<p><em>1) If it is your first time reviewing a single instance of OSINT and you can’t find a strong Key value that leaps out at you, it may be time to move onto another instance (or perhaps another source all together) for the time being (and perhaps come back to this one later).</em></p>
<p><strong>PLEASE NOTE:</strong> <em>Where the Key and Layer technique is concerned, an example of an OSINT instance would be any of the individual emails stored by this archive.</em></p>
<p><em>An example of an OSINT source would be the entire archive of emails itself and all the functionality the archive entails.</em></p>
<p><em>2) This Key advantage helps to insure our investment of time in investigating an instance or source of OSINT; offensive engagements/operations are dynamic challenges where time is ultimately the enemy</em>.</p>
<p>*Should an event outside of our control force us to suddenly abandon an OSINT source/instance after establishing a Key value, at least we have yielded some tangible value from that source/instance.</p>
<p>Over time, this strategy will pay dividends: we are ensuring that we are gaining advantages/resources from the material we choose to invest our time/attention in, while more quickly putting aside the material with layers that are not yielding these advantages/resources.*</p>
<p><em>This is especially important when working post exploitation in LAN, where your investment of attention elsewhere could (essentially) leave an active session out in the open. If we’re going to put a session (and the implant/infrastructure that maintains it) in a position where there is an increased probability of it being detected or disrupted (perhaps accidentally by an unsuspecting user), then we should be ensuring we maximize the reward to balance the added risk.</em></p>
<p><em>3) I’ve found that the Key value concept helps me gain better value from the materials I do set aside; it helps me move through a greater quantity of OSINT content more quickly, while also helping me maintain/define a sense of the value these resources could provide.</em></p>
<p><em>This is because defining the reasons an OSINT instance/source does not have a Key value also helps me defines the resources it does have.</em></p>
<p><em>This process helps me create a store of resources that can be drawn from at any point during an engagement. This allows me to understand how these resources could be used to connect the dots, even if the data doesn’t represent a dot itself.</em></p>
<p>Reading through the archived e-mail below, I establish the Key value: the email possesses another set of hardcoded/default credentials (redacted in red, a different set of credentials from those redacted above) for the same network solution, with information in the body of the email quantifying the relative effectiveness of it.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/3/3275f42fa534a87a86764b54abf78e01c9b372c5.png" alt="osintemail1a" data-base62-sha1="7coAu8qfuXmgNrIA0LieFmrLtU9" width="503" height="500"></p>
<p>As is common with instances of OSINT, there are many more layers of advantages/resources present.</p>
<p>However, we also have Contingency Seeding occurring: given the context of this e-mail, the credentials it contains seems like a good path to investigate/follow.</p>
<p>Should this set of credentials lead us to a dead end or toward a disadvantageous situation, or should we learn from other recon that these credentials do not have the value we think they do, we have a second set of credentials to utilize (the credentials found in the Google Dorking search entry).</p>
<p>With the Key value already established (the credentials redacted in red), let’s work through the archived email layer by layer; when using “Key and Layer”, I work from the top of the source down to the bottom.</p>
<p>A layer constitutes every section of a source where resources/advantages are present.</p>
<p>Starting from the top of the e-mail (below), we have the full name of the target’s employee and their e-mail address; though the archive has tried to sanitize the e-mail address, it still hints at the naming convention the target’s internal/corporate e-mail addresses use (first.last@).<br>
<img src="https://0x00sec.s3.amazonaws.com/original/2X/0/089adbe80522feecb33b6888f44e544a98ce71e0.png" alt="osintemail3" data-base62-sha1="1e7Bqtb1c0Jc6iLpHgRReIUNx3G" width="625" height="143"><br>
The date/time in the email was close to the date range when this engagement was occurring.</p>
<p>This helped quantify the relevance of a couple of things: it helped to ensure the effectiveness of the credentials that were included in the email and the situation surrounding them (the technical difficulty associated with changes to those credentials) which was addressed in the e-mail.</p>
<p>Also, given the thousands of emails present in the archive, we could search all of the emails this employee sent/responded to and quantify all of the days/times associated with those e-mails.</p>
<p>This would leave us with a statistical range as to when the employee may or may not have been active on their corporate email/corporate host.</p>
<p>As this archive would not contain all the employee’s emails, this statistical range would not be perfect.</p>
<p>However, should we ever gain access to this employee’s credentials/corporate host, this range could:</p>
<p>Help us lower the probability of being detected when accessing the employee’s email account or corporate host to utilize it as a resource (read the emails their account contains, launch social engineering attacks at other employees from it, utilize/search the employee’s host for resources with a Meterpreter session, etc.).</p>
<p>Also, if we wanted conduct attacks like taking screenshots of this employee’s online sessions, this statistical range could help us activate implants on their host during days/times the employee was most likely to be active.</p>
<p>Finally, if the archives show statistical norms when this employee e-mails other employees, this could help launch us social engineering attacks at those times/on those days against those employees, which can help with adding an extra layer of feigned authenticity to the attacks.</p>
<p>Now, we move on to another layer of resources: the body of the e-mail itself, a layer added by the target’s employee…as is often the case with OSINT, this is the most valuable intelligence we can find.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/3/3478280402386f9c41a8c84e53c8fbceef01ff7c.png" alt="osintemail2" data-base62-sha1="7uagfN6J3XRd3vwMbhpxVVAKnUw" width="545" height="372"></p>
<p>This is where the Key resource is located, provided by the words of the target’s own employee: active (at the time at least), hardcoded/default credentials in an e-mail that is destined to be stored on the public Internet within hours or days.</p>
<p>The employee continues adding valuable layers to this OSINT by explaining why his fellow employees should not change these default credentials, furthering the statement by saying it is unlikely the target or it’s clients/customers (both of whom make heavy use of the target’s products) will go through the trouble of doing so.</p>
<p>The body of this e-mail has helped solidify the value of the credentials it provides, ensuring that there is a high likely hood that any hosts enumerated hosts that are this product will be accessible via these credentials.</p>
<p>Logging into a host always  carries the danger of being detected, but logging into a host after multiple failed attempts is generally much worse.</p>
<p>The body of this e-mail could aid in crafting social engineering attacks that appear to mimic this  employee’s writing style, word choices, demeanor and formatting; impression of these elements could likely be improved through studying any number of emails in the archive that belong to this employee.</p>
<p>This study could include noting historic differences/similarities in how this employee interacts with certain employees/clients over many emails, with targets of social engineering attacks that impersonate this employee targeting employees/clients that display a dynamic we feel can be leveraged.</p>
<p>For social engineering attacks against this employee, we know Alexander likes to go by Alex. For social engineering attacks that pose as them, we know the name the name they go by and how he prefers to sign off on his correspondence (using “Best,”, which we can be verify by studying other emails that belong to this employee in the archive).</p>
<p>We could use this email and others in the archive that belong to this employee to build custom wordlists with Cewl to bruteforce any resources attributed to them.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/7a54304177b1b8bc84d2d38d100f3900984ef131.png" alt="osintemail4a" data-base62-sha1="hsaCIheaS7XtMVv4uOwLj7dnMsN" width="534" height="475"></p>
<p>Moving on to the layer shown above, the archived emails that belonged to the target’s employees seemed to always include the internal corporate email signature of each participant (this varied where the target’s clients/customers are concerned).</p>
<p>These signatures pretty much mangled the scant security measures that were taken to obscure information like internal corporate emails.</p>
<p>Here, we have data that helped us quantify the viability/quality of this instance of OSINT: since this employee is a System Architect, there is the highest reasonable probability that the data is factual, given the employee’s position in the company.</p>
<p>We also have other data helpful in attempting other attacks (especially social engineering attacks) such as an address, phone number, fax and this employee’s division.</p>
<p>This layer also adds extra value to other data found earlier: having discovered the facility this employee works at, we could take an established statistical range of the days/times this employee worked using the headers of their archived e-mails and use that to make a safe assumption what days/times the majority of that facility’s employees work.</p>
<p>This data could be used to to improve the probability of successfully launching  any number of attacks against the facility’s network infrastructure or the employees themselves.</p>
<p>The archives attempts to hide the employee’s email addresses are a failure due to the presence of the employee’s email signatures:</p>
<ol>
<li>
<p>We already have the naming convention of this employee’s email address taken from headers.</p>
</li>
<li>
<p>The obscured e-mail address is repeated here above the target company’s domain name.</p>
</li>
<li>
<p>The number of Xs used to hide the remainder of the employee’s email address equals the same number of characters used to spell the company’s/target’s domain name in the website address field after the www (the company’s emails could also be found using <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> and this method recreates the employee’s email address exactly).</p>
</li>
</ol>
<p>We also have the layout/appearance of the target company’s internal e-mail signature and their confidentiality agreement; both of these could aid in producing convincing phishing/spearphishing emails that appear to originate from within the company.</p>
<p>We have the employee’s phone number; we could attempt to gain access to this employee’s voicemail box, possibly leveraging data from this and other emails in the archive to do so.</p>
<p>For examples: employee ID numbers are often the default code used to secure an employee’s voicemail; we could search archived emails belonging to this employee to see if the ID numbers were ever an included value in the email headers/signature or mentioned by this employee or other employees/clients/customers.</p>
<p>Since there is no cellphone field in the signature, this could be a deskphone within the target company’s facility; if a BlackHat could gain access to the employees voicemail box, PBX type exploitation for profit could be a possible.</p>
<p>The BlackHat PBX attack scenario adds value to the idea of quantifying times/dates listed in the header of this/other archived emails belonging to this employee to help establish a statistical range of normal working days on/days off and hours on/hours off, as well as the likely norms worked by other company employees at that facility.</p>
<p>PBX exploitation for profit often involves a BlackHat exploiting PBX employee voicemail message forwarding functionality, causing company phonelines to call pay by minute (1-900) numbers belonging to the BlackHat, charging the company for the time elapsed via repeated calls; some BlackHats have earned hundreds of thousands of dollars over a weekend by doing this…it helps to utilize this attack when company employees are off and not near their desk phones.</p>
<p>Due to the presence of the fax machine number, we now know a fax machine is likely present at the target facility, which is an added, viable attack vector.</p>
<p>This adds a third contingency via Contingency Seeding: our first contingencies should utilize the credentials that have been found. Should these credentials not work, another set of contingencies could involve trying to locate fax machines on the target’s perimeter to attack; or, if we already have a foothold in this facility’s LAN, we could try to locate the fax and utilize it for post exploitation activities.</p>
<p>Since there is no deskphone field in the email signature, this employee may only use a cellphone or softphone for work, which could create an avenue for other attacks against them.</p>
<p>For instance, if we somehow discover that the employee uses a cellphone instead of a deskphone, we could attempt possibly attempt SMS based social engineering attacks them.</p>
<p>Or, if we learn that the employee uses a softphone, we could attempt to enumerate the software used and attempt to leverage any vulnerabilities that the software possesses at some point of this engagement/operation.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/2/242e1b75185d8de734ca8ce1d370fe5a4ae4fa03.png" alt="osintemail6" data-base62-sha1="5a3YlgMZpoQVyr8mV4MWEk1l58n" width="629" height="500"></p>
<p>Above: The final layer of data for this instance of OSINT is the “Other related posts” field.</p>
<p>The messages in this thread could allow us to discover departments, networks and facilities where we can best utilize the credentials we have found to access hosts in the target’s network.</p>
<p>For instance, if messages in this section contains emails where company employees state having the network solution in play, we could enumerate what department/location they work at through data contained in their email signature (and possibly the email itself or other emails in the archive).</p>
<p>The same strategy could also apply to any customers/clients involved in this dialogue. If their email signatures didn’t leak identifying information in any of this section’s threads, we could also attempt to search emails in the archive for the necessary information.</p>
<p>Then it becomes a matter of enumeration to find the hosts that data in an email or emails points at.</p>
<p>Perhaps an employee in one of emails listed in this section states they constantly have to work around the problem these credentials present (confirming the network hosts are present in their network); this employee’s e-mail signature states they work in the target’s Engineering Department in another facility.</p>
<p>We could enumerate the target’s domains/subdomains with tools like Amass, Aquatone, Fierce or Sublis3r and/or sites like DNSDumpster, searching for domains/subdomains that seem likely to be part of the Engineering department (looking for naming conventions containing words like “dev” or “staging” are a good start).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/74008b8e8d1cb97a95b1420c8ea6d465bff2889e.png" alt="amassosint1A" data-base62-sha1="gycynDOQtrezblXvGkWYb693LuC" width="460" height="500"><br>
<em><strong>Image above:</strong> OWASP Amass DNS Enumeration output enumerates a target IP range using words in the naming convention indicative of Engineering/Developer department subdomains.</em></p>
<p>After locating the necessary target domains/subdomains, we could then search these IP in Shodan to see if the necessary network solution is present pending other enumeration, such as portscans of the target’s full IP ranges.</p>
<p>As DNS and other enumeration commences, we could also utilize Shodan search filters to expedite the process of finding these hosts (we could use the archive to isolate attributes that allow us to do so).</p>
<p>This is especially helpful, as Shodan search filters allow us to search by a huge number of parameters, examples of which include state, country, port, type of software and network IP range.</p>
<p><strong>NOTE:</strong> Daniel Miessler’s overview of Shodan search filters can be found here <a href="https://danielmiessler.com/study/shodan/" rel="noopener nofollow ugc">https://danielmiessler.com/study/shodan/</a></p>
<p>We could also use the e-mails that make up this thread to further isolate the best targets: what are the employees/customers/clients saying about the credentials and the situation surrounding them?</p>
<p>Are they working on fixing their dependence on these credentials regardless of the difficulties?</p>
<p>Are employees from any of the target’s departments/locations stating that they are just fine with the credentials or do they state they’ve resigned themselves to the situation?</p>
<p><strong>This type of data is excellent for Contingency Seeding; let’s say we read the emails linked in this section and established some contingencies based off them.</strong></p>
<p><strong>Contingency Seeding often includes establishing different levels of viable targets…we will state this example from a BlackHat’s perspective, where all of the company and it’s clients/customers are fair game):</strong></p>
<p><strong>Target 1 - The second, confirmed set of credentials vs. hosts/networks where employees/customers/clients have stated/hinted the credentials are used and they have no plans of fixing their dependence on them…search for these networks using the data contained in employee email signatures and any clues that may be included in emails contained in this thread.</strong></p>
<p><strong>Contingency Target 1 - The second, confirmed set of credentials vs. hosts/networks where employees/clients/customers have stated/hinted the credentials are used and they plan on remediating the issue, but they have not begun this process…search for these networks using the data contained in client/customer email signatures and any clues that may be included in emails contained in this thread.</strong></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/5/5d1c1171721e02bb1c991f7b141fdf5ba5b19f8d.png" alt="osint2A1" data-base62-sha1="dhGxvwptIT7TrF7lbKi0PyrrVdH" width="690" height="166"></p>
<p><strong>Contingency Target 2 -  First set of credentials found in Google search engine entry (above, redacted in red) vs. hosts/networks where employees/clients/customers have stated/hinted credentials are used and they have no plans of fixing their dependence on them…use these credentials against hosts where the other confirmed credentials have failed (these may have been networks identified using the data contained in employee email signatures and any other clues that may have been included in emails contained in this thread).</strong></p>
<p><strong>Contingency Target 3 - First set of credentials found in Google search engine entry (above, redacted in red) vs. hosts/networks where employees/clients/customers have stated/hinted credentials are used and they plan on remediating the issue, but they have not begun this process…use these credentials against hosts where the other confirmed credentials have failed (these may have been networks identified using the data contained in employee email signatures and any other clues that may have been included in emails contained in this thread).</strong></p>
<p><strong>Other resources/advantages present in the layers of “Other related posts”:</strong></p>
<p>Reading all of the emails in this thread may present opportunities to improve the probability of successful social engineering attacks.</p>
<p>For instance, if messages became heated between two participants  in this thread, we could fashion a social engineering attack leveraging sentiments like “you were right, I found this document (really a malicious attachment). I apologize…” or “I looked into it for you and I think I found a solution, which I attached (really a malicious attachment)”.</p>
<p>An attack of this type could be made especially potent given our access to both the thread and archived e-mails.</p>
<p>The archive is likely to include a wealth of materials that could help us impersonate the target company’s employees (or even it’s clients/customers) through studying (and then mimicking) idiosyncrasies like: individual word choices, the layout of their writing, habitual spelling mistakes, favored expressions, the aesthetics conveyed by individual email signatures, changes of demeanor between interactions with different employees (or different clients/customers for that matter) and quotes used in their e-mails, all garnished by details like the company privacy disclosure.</p>
<p>While the archived emails likely lack some of the aesthetic qualities of the company’s emails, these can be learned/mimicked by searching the web for images of company emails, signing up for company resources via temporary email (with Guerilla Mail perhaps) that are available to anyone (such as promotional materials or employment opportunities).</p>
<p>At the time of this engagement, the email addresses contained in this thread were only dated days/weeks before the beginning of the engagement.</p>
<p>This gave me the opportunity to use tooling like Spiderfoot or Pwned (which queries Have I been Pwned?) to locate any of the emails in the thread that had been included in a credentials dump recent to the start of the engagement.</p>
<p>If Spiderfoot stated that any of the emails in the thread were associated with or used to create external accounts on other sites, it may be worth seeing if any of those sites had recent dumps associated with them as well.</p>
<p>If any of the target’s employees/customers/clients had credentials in these dumps, there is always the chance they are reusing passwords between accounts…this could translate to taking creds from a recent dump and using those credentials to access an employee’s/client’s/customer’s corporate email account.</p>
<p>It’s always possible that by using dumped credentials to access other accounts belonging to an employee/customer/client  that we could eventually gain access to a internal corporate account .</p>
<p>Perhaps the account is linked to or contains intelligence/data that grants us access to an internal  corporate account  (for instance, I have found corporate email credentials saved in the “Drafts” folder of other external email accounts).</p>
            <p><small>4 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/my-personal-osint-techniques-part-1-of-2-key-layer-contingency-seeding/13033">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/my-personal-osint-techniques-part-1-of-2-key-layer-contingency-seeding/13033</link>
          <pubDate>Tue, 16 Apr 2019 16:20:50 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-13033</guid>
          <source url="https://0x00sec.org/t/my-personal-osint-techniques-part-1-of-2-key-layer-contingency-seeding/13033.rss">My Personal OSINT Techniques, Part 1 of 2: Key &amp; Layer, Contingency Seeding</source>
        </item>
        <item>
          <title>OSINT vs Fraudster</title>
          <dc:creator><![CDATA[Cry0l1t3]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hey, guys</p>
<p>how are you doing?</p>
<p>Last year there was a situation where a guy tried to get my money by stealing my credentials for a payment service by using a phishing mail and after he noticed it didn’t work he tried to social engineer me.</p>
<h4>With this topic, I want to show you guys how important and dangerous OSINT can be in real-life situations.</h4>
<h1>Phishing mail</h1>
<p>At that time I was selling my car. All of a sudden I got a (great configured) email to a fake PayPal that I almost used. I stopped because the design of it was a little bit too pixelated. So I deleted this email and was waiting for a real sell.</p>
<p>Sorry that I don’t have a screenshot of the content of it.</p>
<h1>Social Engineering</h1>
<p>A day later the same email address contacted me again.</p>
<blockquote>
<p>Mario peer <a href="https://0x00sec.org">***************@gmail.com</a></p>
</blockquote>
<blockquote>
<p>I just received an email from PayPal that Legal action will be taken on you at any moment from now, why did you fail to make the transfer of information to the shipping agency and your inability to convey this money means that you will have a problem with them and they know how you are going to track you down.<br>
I want you to understand that all your money has been deducted from my account and waiting to be transferred and activated on your account, but you must first send the fee and return shipping agency in responding to the PayPal confirmation email from them with the GT you have received obtained by money gram, after you must have sent the charge carrier. I hope you understand better now and I hope you can go ahead and make the transfer if you do not want Problem. Here PayPal is the information of the information carrier, once again, where you are going to send the shipping fee below. check your spam email and junk for the confirmation from PayPal.</p>
<p>Name: Wale Joseph<br>
State: Oyo<br>
City: Ibadan<br>
Zip: 23402<br>
Country: Nigeria</p>
<p>Here is the information you will need to send to me as soon as you get it done.<br>
Receiver’s Name<br>
Money Gram, Receipt<br>
Reference<br>
Amount Sent.<br>
Await your response<br>
I will be waiting to read from you regarding the transaction.</p>
<p>Nice doing business with you</p>
</blockquote>
<p>The things I didn’t like in this email:</p>
<ol>
<li>Location</li>
<li>Name</li>
<li>Already paid???</li>
<li>“if you do not want problem” - really?</li>
</ol>
<p>Okay man. So here I wanted to show this fraud who really does have a problem now.</p>
<h1>The Counter</h1>
<p>So I followed the PayPal link. It redirected me to his domain. I also took a look at his Gmail-Account. There I found interesting information which I used to do some OSINT.</p>
<p>At some point, I found how this guy looks like. Here is our guy:</p>
<p>&lt; his picture &gt;</p>
<p>After searching a little more I was really surprised…<br>
This dude already has his own house!</p>
<p>&lt; picture of his house &gt;</p>
<p>I found almost everything about him. Here is the small list of the things I found after 4 hours of OSINT:</p>
<p>Name: 		Galih *********<br>
Birthday:	*****************<br>
Location:	J*******, Indonesia (West-******** (Provinz))<br>
Home:		*************** V no.******* J*******, *******************.<br>
Pictures:</p>
<ul>
<li>&lt;link1&gt;</li>
<li>&lt;link2&gt;</li>
<li>&lt;link3&gt;</li>
<li>&lt;link4&gt;</li>
<li>&lt;link5&gt;</li>
</ul>
<p>Accounts:	<br>
Gmail:		**************************************<br>
Twitter:	**************************************<br>
LinkedIn:	**************************************	(since March 201*)<br>
Instagram:	**************************************<br>
YouTube:	**************************************<br>
Facebook:	**************************************<br>
Twiblue:	**************************************<br>
Soundcloud:	**************************************	<br>
Userscripts-mirror:	**************************************<br>
Blog:		**************************************<br>
Site:		**************************************</p>
<p>Shop:			**************************************<br>
Location:	***************** II No. **** Duren Sawit  *********************.</p>
<p>Phone:</p>
<ul>
<li>(021) 8*** ****</li>
<li>(021) 8*** ****</li>
</ul>
<p>Whatsapp:</p>
<ul>
<li>0812 **** ****</li>
<li>0812 **** ****</li>
</ul>
<p>Jobs:		<br>
20** - now:	Computering and networking technical by *********************	(SEO Specialist)<br>
20**–20**:	******************<br>
20**–20**:	******************************<br>
20**–20**:	*****************<br>
20**–20**:	**********************</p>
<p>Group:			*********** ************* User Group<br>
since DD.MM.YYYY<br>
&lt;link&gt;</p>
<p>Activities:		*********** Festival as DJ &lt;date&gt;<br>
&lt;link&gt;</p>
<p>…</p>
<p>So at this moment, I knew who he is. I answered him to his email. And here is how the conversation ends:</p>
<h3>Cry0l1t3:</h3>
<blockquote>
<p>Dear Mario Peer (Galih *******),</p>
<p>sorry that I didn’t complete the transfer. I have to work a lot. So I want to apologize and tell you that you have a nice Shop (www.lo********.com) in *************** II No. 62 Duren Sawit - *********. I am very interested in the articles that you sell. I also like DJ stuff and the Pioneer DDJ-RZX mixing desk. I paid roundabout 3.000€ for it too. Not to forget the number 57 is my lucky number. I also have 4 trees in my garden. What are the odds! You’re a really likeable guy. But I am desperately disappointed by you. You should be answerable for this kind act with really good liberally bounty to me. My Mixing desk is broken and I want to buy a new one.</p>
<p>I hope you are happy with my answer.</p>
<p>Have a nice day</p>
<p>Sincerely</p>
</blockquote>
<h3>Galih:</h3>
<blockquote>
<p>The payment has been made and the money has been deducted from my account and it’s on its way into your account but the money would be pending until you have sent the sum of 400 Eur through Money Gram to the address of the shipper giving to you so that they can come for the pickup and then send the necessary money gram information to pay pal for Verification. . You should understand what I mean so kindly bear with me. Once the money gram information is received from you, the sum of 4,930 Eur would be released into your account. Get to mail me back soon.</p>
<p>Thanks</p>
</blockquote>
<h3>Cry0l1t3:</h3>
<blockquote>
<p>Sorry, I forgot to congratulate to your passed birthday at ************<br>
How old did you become? 20?<br>
Its a nice job position at ************* as SEO.</p>
<p>Good luck</p>
</blockquote>
<h3>Galih:</h3>
<blockquote>
<p>???</p>
</blockquote>
<h3>Cry0l1t3:</h3>
<blockquote>
<p>Your pictures:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your girlfriend:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your Shop:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your friends:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your family:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your Accounts:<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
&lt;link&gt;<br>
Your Career:<br>
…</p>
</blockquote>
<p>And so on. Unfortunately, I never heard anything from him anymore.</p>
<p>Please, make sure you know what you’re sharing.<br>
Keep calm, guys.</p>
            <p><small>21 posts - 11 participants</small></p>
            <p><a href="https://0x00sec.org/t/osint-vs-fraudster/11563">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-vs-fraudster/11563</link>
          <pubDate>Wed, 13 Feb 2019 15:32:55 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-11563</guid>
          <source url="https://0x00sec.org/t/osint-vs-fraudster/11563.rss">OSINT vs Fraudster</source>
        </item>
        <item>
          <title>OSINT - Shodan API Key</title>
          <dc:creator><![CDATA[Cry0l1t3]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hey guys!</p>
<p>This is a quick tutorial how to get your Shodan API Key to use the Shodan NSE Script.<br>
Already <a class="mention" href="https://0x00sec.org/u/pry0cc">@pry0cc</a> created a <a href="https://0x00sec.org/t/osint-passive-recon-and-discovery-of-assets/6715/13">topic</a> which shows you the usage of this script.</p>
<p>First things first, you have to create a shodan account for this.<br>
Just visit the registration site of shodan and create a account.<br>
Link: <a href="https://account.shodan.io/register" rel="nofollow noopener">https://account.shodan.io/register</a></p>
<p>After entering your parameters you have to activate your account by clicking on the link from the received email.</p>
<p>The next step is to login and you will see your API key on the main page.</p>
<p>That’s all.</p>
<p>Have fun. Enumeration is the key!</p>
<p>Regards,<br>
Cry0l1t3</p>
            <p><small>6 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/osint-shodan-api-key/8249">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-shodan-api-key/8249</link>
          <pubDate>Fri, 24 Aug 2018 12:33:28 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-8249</guid>
          <source url="https://0x00sec.org/t/osint-shodan-api-key/8249.rss">OSINT - Shodan API Key</source>
        </item>
        <item>
          <title>OSINT 0x02 - LinkedIn is not just for jobs</title>
          <dc:creator><![CDATA[pry0cc]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <h1>OSINT 0x02 - LinkedIn is not just for jobs</h1>
<p>Sup 0x00’ers, that’s right, I am back with another banger of an article, ready?</p>
<p>If you read my last article on OSINT, you’ll know a little bit on how to find dirt on companies, their assets, and how to do all of that passively. Well now I am going to show you a little bit about researching individuals, and specifically those who work at a specific company.</p>
<p>If you read the title, which I am sure you have, you’ll know that we’re going to utilize LinkedIn for this. LinkedIn really is a very very very useful tool for enumerating users, and their emails.</p>
<h1>‘Generating’ email addresses</h1>
<p>From my last article, I mentioned a tool called <a href="http://hunter.io">hunter.io</a>, you can use it to search for company email addresses, and it even gives you a break down on what it thinks the current email structure is for a company.</p>
<h2>Stage 1 - Figure out the naming conventions</h2>
<p>Lets make up a fake company, say even <a href="http://google.com">google.com</a>.</p>
<p>Now lets assume we found a few emails with the format of <a href="mailto:hsimpson@google.com">hsimpson@google.com</a>, and then we see another email, <a href="mailto:jsmith@gmail.com">jsmith@gmail.com</a>. We can soon start to get a feel for the kind of structure they’re using for emails, typically, <code>{first initial}{lastname}@{companyname}.com</code>, this could vary from organisation to organisation, but we can quickly come up with the naming convention, and then we can move onto stage 2.</p>
<p>You can do this with <a href="http://hunter.io">hunter.io</a>. Notice the ‘most common pattern’ section?</p>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<h2>Stage 2 - Get the employees and Generate the Emails</h2>
<p>This is where LinkedIn plays nicely with us. If we can get a list of first and last names of everybody working at a company, we can then take that infomation and feed it into a python script, and generate email addresses from the convention.</p>
<p>We can easily obtain these names through google dorking. Try my new tool <a href="https://github.com/pry0cc/GoogLinked">GoogLinked</a>, when coupled with <a href="https://github.com/pry0cc/ProxyDock">ProxyDock</a> (another shameless plug), you can scrape google all day with inpunity.<br>
<span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>One thing you’ll want to do before you run this is modify the script, at the moment it contains Microsoft and <a href="http://microsoft.com">microsoft.com</a> as the arguments, you’ll want to modify it to be “company name”, (as shown on linkedin), and the company email domain name. In the above example, I piped all results into a file, otherwise it will just dump them onto the standard output.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/7c6be95b95d5acaf3d3f72cd3de5d4b521f9b892.png" alt="enter image description here" width="" height=""><br>
Wow, that’s a lot of email addresses, lets take a look and see what it came back with.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/bdb0290dd2d5415b6f2abb1c99d7180e5c12c14e.png" alt="enter image description here" width="" height=""></p>
<p>So as you can see, there are a few generated email addresses. What this has done, under the hood, is using a Google Dork, captured the titles for each person that has microsoft listed under their portfolio as working or have worked. Then, it takes the format defined in the <code>run_search()</code> function.</p>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>Notice that names.each section? Modify that depending on the format you discovered for the company (as we learned how to do in the section before). In this case, <code>tarr[0]</code> and <code>tarr[-1]</code> are firstname and lastname respectively. *</p>
<p>This script is one I use personally, and so I modify it myself, if you want to make a PR to add custom functionality, feel free.</p>
<p>* Note, things can get a bit whacky when middle names are introduced. So just know this is not a fool proof method.</p>
<p>Now you have these emails, the world is your oyster. Pass them into <a href="http://weleakinfo.com">weleakinfo.com</a>? (See my last article).</p>
<h3>Bonus: Password Spraying</h3>
<p>If you’re doing a pentest, you can use these emails to your advantage. Quite often, bruteforcing a companies email with a single email and 100k passwords, is your way to getting blocked by a SIEM, or even getting the account locked which impacts on production (if you’re a pentester you’ll know the struggle :P), which we don’t want.</p>
<p>One very unique way to acheive this, as taught to me by <a href="https://medium.com/@adam.toscher/">atoscher</a>, is to try each email with a single password, such as <code>Summer2018</code>, or <code>Fall2018</code>. Many companies implement quarterly password rotation policies, in the hope to make passwords more unpredictable and secure. What actually ends up happening is people resort to using weaker passwords as they can’t remember a new password every quarter. A very common usage of this is people using passwords like <code>Summer2018</code>.</p>
<p>What else is cool about this method, is you can usually feed it through a load of VPN’s, (<em>cough</em> ProxyDock <em>cough</em>), and then try legitmate services like gmail, microsoft link, sharepoint, the list can go on. Your chances of getting blocked, especially if you regularly rotate IP addresses, useragents, and individuals, is very low.</p>
<p>That’s all for this week 0x00’ers! Stay tuned, next week I am going to bring you “Active Recon - Deeper than Nmap”, the name might change, we’ll see.</p>
<p>Make sure you drop a comment if you loved this article, please like it if I helped you, and share this everywhere. The more shares we get on this article, the more people we can educate,  and bring to 0x00sec. Lets see if we can get 1000 reads on this article!</p>
<p>Stay Snappy <img src="https://0x00sec.org/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"></p>
<p>- pry0cc</p>
            <p><small>9 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/osint-0x02-linkedin-is-not-just-for-jobs/6774">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-0x02-linkedin-is-not-just-for-jobs/6774</link>
          <pubDate>Tue, 22 May 2018 11:20:18 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-6774</guid>
          <source url="https://0x00sec.org/t/osint-0x02-linkedin-is-not-just-for-jobs/6774.rss">OSINT 0x02 - LinkedIn is not just for jobs</source>
        </item>
        <item>
          <title>OSINT - Passive Recon and Discovery of Assets</title>
          <dc:creator><![CDATA[pry0cc]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <h1>OSINT - Passive Recon and Passive Discovery Of Assets</h1>
<p>Sup 0x00’ers, to kick this badass series off, I am going to begin with the most important aspect of pentesting. Passive Recon and OSINT. Now, do not let the word ‘passive’ fool you. This is no light recon, you can uncover vast amounts of infomation through passive recon, without ever doing anything intrusive.</p>
<h2>Define Passive</h2>
<p>My definition of the word passive is probably different to what others would define as passive. In my books, it’s anything that can be disguised as regular traffic, nothing intrusive, or easily detectable. Basically, if you can’t be distinguised as an attacker from a visitor, and you aren’t doing anything intrusive/potentially damaging, it’s passive. I know I will get a few who will argue to the death this is not 100% passive, and you’d be right, but this is still my initial pre-pentest workflow.</p>
<h2>Where do I start?</h2>
<p>Good question. This will hugely depend on what sort of pentest you’re doing. In penetration testing, there is a spectrum of different types of pentest:</p>
<ul>
<li>Black Box Pentest</li>
<li>White Box Pentest</li>
<li>Anything in between</li>
</ul>
<p>A Black Box Pentest is when you’re simulating an attacker, you’re given a single starting host, and usually a list of in-scope IP addresses, and that is all. You must attempt to discover services, network design, and things of that nature.</p>
<p>A White Box Pentest is similar, except you are given everything that an internal employee (and more) would have, this includes application source code, network design configurations, diagrams, stuff like that.</p>
<p>Both types of Pentest have their place, typically a Black Box Pentest is more telling than a White Box Pentest, as it shows what an external attacker could discover with little starting infomation. In this series, we’re going to be covering the former, Black Box Pentesting, as it is the most common sort of Pentest, and will be what most of you are looking for.</p>
<p>Now, if you read the previous paragraphs, you’ll quickly notice that I mentioned that you may be given a list of in-scope IP addresses. To simply scan all of these IP’s and be done with it is very unrealistic, and so you should first  begin with your asset discovery stage. Now there are a tonne of ways we can do this, and I am going to use Google as an example of this, and we’re going to be using the company website as our starting point.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <a href="https://www.google.com/" target="_blank" rel="noopener">google.com</a>
  </header>
  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/276;"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/e/8/e8462b3eb6c9719abd8d9662d30555bb46f5e9c4_2_690x276.gif" class="thumbnail" width="690" height="276" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/e/8/e8462b3eb6c9719abd8d9662d30555bb46f5e9c4_2_690x276.gif, https://0x00sec.s3.amazonaws.com/original/3X/e/8/e8462b3eb6c9719abd8d9662d30555bb46f5e9c4.gif 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/e/8/e8462b3eb6c9719abd8d9662d30555bb46f5e9c4.gif 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/e/8/e8462b3eb6c9719abd8d9662d30555bb46f5e9c4_2_10x10.png"></div>

<h3><a href="https://www.google.com/" target="_blank" rel="noopener">Google</a></h3>

<p>Google's 22nd Birthday! #GoogleDoodle</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<h3>Burp Suite Passive, as observent as Sherlock Holmes</h3>
<p>What can we do with this? The first thing I like to do, is actually visit the website with my browser configured to use Burpsuite as a proxy, and with a root SSL cert installed. I am not going to explain how to do this, if anybody wants to write an article on how to do this feel free and I’ll link it here!</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/0/0ed4d3056f0490a6bee08312430886589af49454.png" alt="enter image description here" width="" height=""></p>
<p>If you look on the side bar of your BurpSuite, under <code>Target &gt; Site map &gt; https://www.google.com/</code></p>
<p>We can already see a quick overview of immediate file structure of the site, loaded scripts, and also, if we take a look at the wider Site map, a long list of other requested hosts, we may decide to use this infomation later, as always in pentesting, it is better to collect too much infomation, and decide not to use it, than to remove it, and end up recollecting it unnecessarily. Remember, this is ‘passive’ recon, we need to stay very quiet in this stage, and not set off any alarm bells. *</p>
<p>If you have Burp Suite Professional, you can also right click this asset and select “Passively Scan this Host”, and it will hunt your exisiting, requested page code for known vulnerabilities, email disclosure and the like. I do not have Burp Suite Professional, and so I will not be using it <img src="https://0x00sec.org/images/emoji/twitter/smiley.png?v=9" title=":smiley:" class="emoji" alt=":smiley:"></p>
<blockquote>
<p>*Note, if this particular website does not recieve many page views, you may decide to use a VPN using the same region as the target<br>
demographic for this website. If the SOC/SIEM solutions are really<br>
sensitive, even a page view from a foreign location could create<br>
flags. If your goal is to not be detected by any monitoring solution<br>
(as usally is the goal with a good Pentest), then this might be a<br>
thing you would go for.</p>
</blockquote>
<p>Okay, so that hasn’t helped us significantly, occasionally, things will pop out like <code>/cgi-bin/</code> , <code>/admin/</code> or <code>/includes/</code>, if something does catch your eye, immediately write this down in your reporting software (perhaps in a tool like <a href="https://github.com/lair-framework/lair">Lair</a>, if somebody makes a writeup on how to spin this up, let me know, and I’ll link it here!</p>
<h3>Passive port scanning with Shodan, wait, passive, portscanning? What?</h3>
<p>So you’ve been to the website, you know at least port 80 or port 443 is open, but what else is running? You can just open up shodan, or you can use the insanely cool nmap scripts.</p>
<p>Obtain a shodan API key, (if somebody makes a tutorial on this, I’ll link it!), and place it inline with this nmap command.</p>
<pre><code class="lang-auto">nmap --script=shodan-api --script-args 'shodan-api.apikey=XXXXXX' google.com
</code></pre>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>In this image, I have censored my API key, although this is a very simple example, this will do multiple things:</p>
<ul>
<li>-sn - Disable Port Scan</li>
<li>-Pn - Skip host discovery, don’t ping the host</li>
<li>-n - Skip DNS Resolution</li>
</ul>
<p>Nmap will then realise it has nothing left to do, and will run the shodan-api script. The shodan API script will go out to <a href="http://shodan.io">shodan.io</a> and retrieve all infomation it knows about the host, including sometimes host versions and port numbers. This has been way more infomational in other circumstances, your mileage may vary.</p>
<p>The point of these tutorials is to provide a very realistic view of what you will see in a normal pentest, and usually, you will not get a single Severity 5 vulnerability with remote code execution, you’ll find 5 Severity 3’s, and you can then string these together to get a shell, to get access to a panel, or even make a very convincing phishing page. We will cover that in more detail in the exploitation section of this series.</p>
<h3>DNS Bruteforcing, but, really fast</h3>
<p>Before we go into DNS bruteforcing, we’ll look into the low hanging fruit of DNS, and that is zone transfers. Zone transfers was initially a tool used for server administrators to allow them to easily replicate a DNS database, such as transfering to new domain names. If the target company has ever migrated their website, and have little security awareness, this will usually work.</p>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>We can easily do domain transfers using a tool called <a href="https://github.com/fwaeytens/dnsenum">dnsenum</a>, it is written in perl (<a class="mention" href="https://0x00sec.org/u/nugget">@nugget</a>), and is a kind of old-reliable tool used in my pentest arsenal.  As you can see here, dnsenum uncovered a few interesting things about the host, namely:</p>
<ul>
<li>Host Address
<ul>
<li>This is the IP that you’ll get when you do a simple nslookup on the domain</li>
</ul>
</li>
<li>Wild card host
<ul>
<li>This is the IP that will be returned when you call a random subdomain, such as <code>kttfvatukbld</code>, unless you get really lucky (or unlucky, your call), and that is a real subdomain, this is usually an IP from your DNS provider, or from your ISP. If they’re really secure, the wildcard domain will be the same as the Host IP, which makes domain enumeration a bitch.</li>
</ul>
</li>
<li>Nameservers
<ul>
<li>These are the nameservers that you have used to do the lookup, usually, in a small-medium sized company, this DNS is hosted elsewhere, and can often be courtesy of the domain name registrar. This can be insanely useful infomation.</li>
</ul>
</li>
<li>MX Servers
<ul>
<li>Now this infomation is so easily overlooked, although it is very surprising what this can yield. This will reveal the MX servers of the domain, a lot of companies in the corporate space now a days will use externally hosted email, such as Google or Microsoft/Outlook, quite often these things link to the entire workflow of the company, which can lead you to discover things like Microsoft Lync Servers, Login panels for user email etc.</li>
</ul>
</li>
<li>Zone Transfers
<ul>
<li>This is quite a rare one now a days, you won’t see this work on a lot of hosts that are in the public domain, facebook, twitter etc. Although on pentests, this is surprisingly common. If this succeeds, it will return a list of all registered sub-domains, which is huge. You’re better off trying it and not finding anything, than never knowing.</li>
</ul>
</li>
</ul>
<h4>Ok, the fast bit.</h4>
<p>Ever heard of Aiodns? Well now you have. Aiodns is a DNS resolver that does synchronous calls over an asynchronous medium. In short, that means that you can efficiently make more than one call without closing the connection after each request. This means it can be, really fast.</p>
<p>Introducing <a href="https://github.com/blark/aiodnsbrute">Aiodnsbrute</a>! Blark had the smarts to turn this into a bruteforcing tool, and man it works well. I mean read this:</p>
<p>“Benchmarks on small VPS hosts put around 100k DNS resoultions at 1.5-2mins. An amazon M3 box was used to make 1 mil requests in just over 3 minutes. Your mileage may vary. It’s probably best to avoid using Google’s resolvers if you’re purely interested in speed.”</p>
<p>1 million requests, uh, what? Feed this tool a Discovery Dictionary nabbed from <a href="https://github.com/danielmiessler/SecLists">SecLists</a> (Discovery&gt;DNS&gt;subdomains-top1mil-110000.txt is great), and you’re on the road to discovering every damn subdomain this domain name has.</p>
<p>What is cooler, is that PCI compliance is a standard, and part of it’s requirements is that every host have a signed, valid certificate. Can’t have a valid certificate on an IP, so what do firms do? They create subdomains for everything they need SSL access to. Yep, you guesssed it, that includes VPN portals, email logins, development sites (please).</p>
<p>Lets try it on <a href="http://google.com">google.com</a></p>
<pre><code class="lang-auto">$ aiodnsbrute google.com
</code></pre>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>Uh, well that’s weird, why are their so many of those 92 IP addresses?</p>
<p>Those are actually the DNS resolver. Remember when we did a DNS Lookup of a wildcard? Yeah, it’s the same IP. We can easily remedy this with a grep command.</p>
<pre><code class="lang-auto">aiodnsbrute google.com | grep -v "the resolver IP"
</code></pre>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>Okay, so granted the formatting is a little broken, but this is real world pentesting people, this isn’t supposed to be glamarous!</p>
<p>Look at those subdomains, they actually go somewhere. Now you can save these IP addresses in a long text file for further examination, or maybe you want to scan them with your newly learned passive shodan skills? You can do reverse nslookups on the IP’s too and see if they resolve somewhere else.</p>
<h3>Scraping Emails</h3>
<p>You might have used this tool before, it’s pretty cool.</p>
<p>It’s called theHarvester.  What it does, is scrape google results, titles, descriptions, metadata, and looks for things resembling email addresses.</p>
<pre><code class="lang-auto">./theHarvester.py -d companydomain.com -b google
</code></pre>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span></p>
<p>For demonstration purposes, I used <a href="http://protonmail.com">protonmail.com</a>, but put in any company domain name, and you’ll usually nab a few emails. If this doesn’t work, you can try Hunter.</p>
<h3>
<a href="http://Hunter.io">Hunter.io</a>, like Google, but for emails</h3>
<p><span alt="enter image description here" class="broken-image" title="This image is broken"><svg class="fa d-icon d-icon-unlink svg-icon" aria-hidden="true"><use xlink:href="#unlink"></use></svg></span><br>
16,000 results, not bad. What this also does that is so cool is that it tells you the common pattern of emails. What you can do with this (I’ll go into this more in detail in part 2), is use this to generate email addresses from names, which can later be used for password spraying (trying a single password for every single email address).</p>
<p>We can do a lot with this infomation, we can load it into an email program and send out phishing emails, we can password spray with them (I will show you the way), or, we can check them for leaks. This where weleakinfo comes in…</p>
<h3><a href="http://Weleakinfo.com">Weleakinfo.com</a></h3>
<p>Remember those data breaches, for Adobe, Linkedin, Myspace? Stuff like that? Well the dumps from these are still out there, and people have published them, you can still find them in old magnet links around the way, however there are thousands of dumps to recover, and they’re hard to find.</p>
<p><a href="https://weleakinfo.com/">Weleakinfo</a> takes all this infomation and compiles it into one big, fast, searchable database. And if you decide to stuff all these emails in there, you might even be lucky enough to get a few old passwords, which you can now variate and try on existing company accounts, how cool is this! We haven’t even instrusively touched their servers, and we already have their account passwords? Not so fast.</p>
<p>16,000 emails! If an email lookup took you 10 seconds to do, and take down the results, (which is very fast) it would take you about 48 hours of non-stop copy pasting to go through them all.</p>
<p>If you actually want to be able to sleep, and don’t have fingers as muscly as John Cena, then I reccomend you automate it. Weleakinfo are actually nice enough to provide a public API, <a href="https://weleakinfo.com/api/public">https://weleakinfo.com/api/public</a>,  which allows 3 requests per second, if you want to go faster, try out a tool like <a href="https://0x00sec.org/t/create-your-own-private-botnet-with-proxydock/5917">ProxyDock</a></p>
<p>(If somebody wants to write an article on this, and make a tool for this, let me know and I’ll link it here)</p>
<h3>Geo2IP - Extra</h3>
<p>Okay, scenario time. You know about a hosts location, but you don’t have a clue about it’s exact details. No problem. Time to use <a href="https://github.com/pry0cc/geo2ip">geo2ip</a>. Geo2Ip is a tool I developed with <a class="mention" href="https://0x00sec.org/u/ioth1nkn0t">@IoTh1nkN0t</a>, and it basically takes a rough coordinate location, and then gives you ranges associated with that coordinate. From there, you can feed these into an nslookup tool (maybe make your own with aiodns!), and discover all assets associated with them.</p>
<h3>Reverse Whois</h3>
<p>Another tool you can use for asset discovery is <a href="http://www.viewdns.info/reversewhois/?">reverse whois</a>.</p>
<p>Now you can use these tools to enter in a company name, email address, or registrant name (obtained from your previous recon), and then go through these same steps with the newly obtained emails, domain names, and extra infomation. Repeat until you have no more passive infomation to obtain. Now you are ready for Active Recon.</p>
<p>In conclusion, there is a vast amount of infomation you can obtain just by knowing where to look. This is by no means an exhaustive list, but it contains a lot of the things that I use in my day to day OSINT that really give me a step up in the pentesting scene.</p>
<p>Let me know in the comments if you liked this article, and make sure to click that &lt;3 button to let me know you want more like this. And be sure to share this if you learnt anything to spread the <a href="https://www.youtube.com/watch?v=3DZ1tWsnLeQ">knowledge</a>!</p>
<p>Thank you for reading, and as always, stay snappy <img src="https://0x00sec.org/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
            <p><small>13 posts - 7 participants</small></p>
            <p><a href="https://0x00sec.org/t/osint-passive-recon-and-discovery-of-assets/6715">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/osint-passive-recon-and-discovery-of-assets/6715</link>
          <pubDate>Thu, 17 May 2018 11:39:03 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-6715</guid>
          <source url="https://0x00sec.org/t/osint-passive-recon-and-discovery-of-assets/6715.rss">OSINT - Passive Recon and Discovery of Assets</source>
        </item>
        <item>
          <title>Yet another Drupal scanner – Drupwn</title>
          <dc:creator><![CDATA[Nitrax]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <hr>
<p><strong>DISCLAIMER:</strong> Article originally published on <a href="https://www.immunit.ch/blog/2018/04/10/yet-another-drupal-scanner-drupwn/" rel="noopener nofollow ugc">immunIT</a>.</p>
<hr>
<p>Hi fellas,</p>
<p>Today, I will introduce you a new tool, developed for the sake of my penetration testing activities, named <a href="https://github.com/immunIT/drupwn" rel="noopener nofollow ugc">Drupwn</a> which claims to provide a reliable and efficient way to perform enumerations on Drupal web applications.</p>
<p>You may think, why yet another tool whereas there exist plenty of alternatives on the market.<br>
Well, the answer is straightforward, they are unreliable. Indeed, none of them is actively maintained and are sorely lacking of features. This is to fill this particular gap that Drupwn is born.</p>
<p>Drupwn is a python script, following a modular architecture for maintenance and enhancement purposes, which allows enumerating various kind of information that could be valuable to any security assessment against such platform.</p>
<h1>Architecture</h1>
<p>Before diving into the main subject, let’s take a look on its architecture.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/5/54ac237417a0c7c48537ecbc7dc2cbaf3207eedd.JPG" alt="architecture" data-base62-sha1="c52UzLVGaanJ3otQrJZq7DIZFiB" width="352" height="500"></p>
<p>As you can see on the picture above, the engine and plugins parts are completely independent, allowing to easily add modules without having the modify the tool core engine.</p>
<p>Each plugin inherits from the abstract class APlugin, providing a better overall structure alongside the whole code base. Upstream the design concern, this inheritance provide a multi threading support by design, deporting this brainteaser, which is parallelization, to the core engine.</p>
<p>Each plugin is designed as following :</p>
<pre><code class="lang-bash">class Example(APlugin):
    """This class is an example.
    """

    def __init__(self, request, logger, config):
        """This is the class constructor, allowing to set the number of threads as well as the logger configuration.
        """
        super().__init__(config["thread"])
        self.logger = logger
        self.request = request

    def run(self):
        """This method is the plugin entrypoint. This is where the magic happen.
        """
</code></pre>
<p>Once the plugin created and added to the plugins folder, we must refer it within the dispatcher and the parser in order to ensure its support by the reflective factory.</p>
<p>Quite easy right ? Thanks to this design pattern, anyone is able, within a few minutes, to add new functionalities to improve the Drupwn’s behaviors!</p>
<h1>Functionalities</h1>
<p>To fit to as much as possible of situations, Drupwn supports:</p>
<ul>
<li>Basic authentication</li>
<li>Cookie manipulation</li>
<li>User-Agent modification</li>
<li>Logging</li>
<li>Request sending speed</li>
<li>Enumeration range customization</li>
</ul>
<p>Upstream those passive functionalities, this python3 script actually provides 6 modules, described below.</p>
<h2>User enumeration</h2>
<p>As its name suggests, this module is used to enumerate the registered users on the platform assessed.<br>
In fact, depending on the Drupal version, an unauthenticated user could be able to enumerates the existing users through the <strong>/user/{ID}</strong> resource.</p>
<p>Cause, code is more explicit than words, here is a piece of pseudo code, explaining the module inner working.</p>
<pre><code class="lang-auto">for id between 0 and 3000
    request the resource /user/id
    if a redirection occurred
        get the username within the returned URL
    else if success
        get the username within the source code returned
    else if forbidden
        the username is not retrievable
</code></pre>
<h2>Node enumeration</h2>
<p>When publishing an article, the CMS create a node, associated with a slug. Lambda users use the slug name to access a given article. However, it is quite tedious to enumerate all the website’s pages using combinations of alphanumeric chars. Of course, spidering can be a good way to accomplish this job but, it is noisy as hell and a better solution exist.</p>
<p>Indeed, by iterating on the resource <strong>/node/{ID}</strong>, we can retrieve the associated slugs and map the whole website content. This can help to find unlinked pages which can results by sensitive information gathering.</p>
<h2>Default files enumeration</h2>
<p>Well, this module just check if the default installation files are present on the web server, allowing to improve the server side hardening, reducing the attack surface.</p>
<h2>Theme enumeration</h2>
<p>Theme enumeration can seem useless however, some free themes available online can be backdoored, which is an easy win situation. This enumeration simply use a wordlist and print out the name of the installed themes.</p>
<h2>Module enumeration</h2>
<p>This module is very similar to the previous one nevertheless, we are commonly face to hardened installation, avoiding any kind of module enumeration.<br>
Modules are, in 99 % of the time, the failure point of a Drupal application. This is why, finding a workaround is inescapable to ensure the assessment reliability.</p>
<p>Here is how this plugin works:</p>
<pre><code class="lang-auto">for each module in the wordlist
    check if the status code is not equal to 404
    if 200
        check the information in the module.info and extract its version as well as its default files
    else if 403
        retrieve its default files
</code></pre>
<h2>Fingerprinting</h2>
<p>Fingerprinting a Drupal application can be quite difficult. Indeed, none of the CMS default files allows to efficiently determinate the version deployed. To remedy this situation, Drupwn uses several locations to accomplish this task.</p>
<pre><code class="lang-auto">while we have no result
    check bootstrap.inc
    check landing page
    check HTTP header
</code></pre>
<h1>Usage</h1>
<p>Drupwn works out of the box thanks to its dockerization.</p>
<pre><code class="lang-bash"># Build the container
docker build -t drupwn .

# Run the docker
docker run --rm -it drupwn --help
</code></pre>
<p>If docker seems unfriendly to you. Drupwn can be used directly on any system using pip3 and python3. To do so, follow the guidelines below:</p>
<pre><code class="lang-bash"># Install dependencies
pip3 -r install requirements.txt

# Run Drupwn
python3 drupwn.py --help
</code></pre>
<h1>Examples</h1>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/f/ff2278d6affbfb3c2554332f3160dd9335cd93f5.JPG" alt="help" data-base62-sha1="Ap1BSrWBmKNJuXawpfKU3LzPu4d" width="569" height="500"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/7/74cab2c98a581a4eed9eee28eae47d17fc638011.png" alt="modules" data-base62-sha1="gFbFhAgVfwBVwqFRxQ8RI4EKOGd" width="611" height="405"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/f/f2d4abd44c923037eb7e064fd7e07fbfa02758e5.png" alt="dfiles" data-base62-sha1="yEbc10x7efYUw3F1Mz5DtRR4vxr" width="612" height="298"></p>
<h1>Conclusion</h1>
<p>I believe this tool provides good capabilities of enumeration that can definitely help any pentester conduct, with efficiency and reliability, his security assessment.</p>
<p>As any open source project, pull requests are widely welcome! Here is a short list of wanting features that will be implemented later:</p>
<ul>
<li>TOR network support</li>
<li>Proxy support</li>
<li>Vulnerability detection</li>
</ul>
<p>Hope you enjoyed this article,<br>
Best,<br>
Nitrax</p>
            <p><small>13 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/yet-another-drupal-scanner-drupwn/6247">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/yet-another-drupal-scanner-drupwn/6247</link>
          <pubDate>Tue, 10 Apr 2018 09:15:53 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-6247</guid>
          <source url="https://0x00sec.org/t/yet-another-drupal-scanner-drupwn/6247.rss">Yet another Drupal scanner – Drupwn</source>
        </item>
        <item>
          <title>Whats the most anonymous active scanning technique?</title>
          <dc:creator><![CDATA[anon8932282]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello guys,</p>
<p>That’s my very first post here. I’m new to hacking and I’m learning the Reconnaissance phase. I’m also completely new to Networking… but I’m always thinking how anonymize all my techniques. <em>I would like to ask which are the most anonymous active recon technique that you guys are applying today.</em></p>
<p>I already started doing a little research. Trying to figure it out, I gathered some interesting techniques that I would like to talk/share with you guys:</p>
<ul>
<li>Idle / Zombie Scan</li>
<li>Proxychains + Tor + Nmap</li>
<li>Decoy and Fragmentation attacks</li>
</ul>
<p>Well, since <strong>I’m just learning</strong>, I’m a little bit lost with all that info. My first intention was understand how could I <em>anonymize</em> the following tools on the network: <em>SpiderFoot, ReconDog, Red Hawk v.2, Devploit, Sn1per</em>, etc…</p>
<p>But digging into it I found some <a href="https://security.stackexchange.com/questions/120708/nmap-through-proxy/120723" rel="nofollow noopener">technical issues</a> about some techniques(nmap with proxy), for example:</p>
<ul>
<li>“only normal TCP connections will be possible with the proxy, no SYN and FIN scan. (…) DNS lookup is not possible through the proxy”</li>
<li>“ICMP ping can not be done to see if a host is alive, since ICMP is not TCP. So you might need to skip the host discovery step if your targets are only accessible through the proxy (-Pn)”</li>
</ul>
<p>From <a href="https://ai.arizona.edu/sites/ai/files/AILabCybersecurityPapers/rohrmann_et_al_2016_anonymous_port_scanning_performing_network_reconnaissance_through_tor.pdf" rel="nofollow noopener">here</a>, I found:</p>
<ul>
<li>“To hide the scanning computer’s IP address, it was necessary to eliminate pinging by setting the –Pn flag. The –sT flag needed to be set in order to run the scan using TCP instead of UDP 4. The –sV flag allows for version scanning and does not leak the scanner’s IP address. The –O (OSDetection), and -A (OS detection, version detection, script scanning, and traceroute) did reveal the IP address because Nmap bypassed Proxychains during part of the execution”</li>
</ul>
<p>From my little research, almost all of the content was directed to “Proxy + Tor + Nmap”, but what about the other tools? How can I manage them to run through Tor too? If Nmap + Tor doesn’t accept SYN scan, OS detection, traceroute, etc (without reveal IP)… how can I run an anonymous recon? The Idle Scan could handle the host discovering, but what about the rest of the recon? I was reading the post “How to Become Anonymous like Notorious Blackhats - Stealthiest Setup” and saw that: “don’t hack over tor” so… I’m kind confused now. I really appreciate any opinion about that.</p>
<p>Ps: Sorry if it is a silly question, or if it sounds script kiddie because of the tools, but I’m really trying to understand and learn everything as possible here. <strong><em>So I really really really appreciate all answers from the Masters here!</em></strong> <img src="https://0x00sec.org/images/emoji/twitter/fire.png?v=9" title=":fire:" class="emoji" alt=":fire:"></p>
<p>Ps2: Sorry if my question wasn’t clear enough, english is not my main language.</p>
            <p><small>18 posts - 8 participants</small></p>
            <p><a href="https://0x00sec.org/t/whats-the-most-anonymous-active-scanning-technique/5678">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/whats-the-most-anonymous-active-scanning-technique/5678</link>
          <pubDate>Thu, 01 Mar 2018 01:23:43 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-5678</guid>
          <source url="https://0x00sec.org/t/whats-the-most-anonymous-active-scanning-technique/5678.rss">Whats the most anonymous active scanning technique?</source>
        </item>
        <item>
          <title>Real Penetration Tests: Equalizers and Dirty Tricks</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Firstly, due to my insane schedule, I do not get to interact with all of you as I would like.</p>
<p>Let me take this opportunity to state that many of you are doing incredible work with the content of your posts; I do read just about everything released here on the Big 0; I am proud to be here among such talented people.</p>
<p>My goal for this year is to really try and be a more active member of  the wider InfoSec/Hacker community; this is a small step in that direction…</p>
<p><strong><em>1) Background</em></strong></p>
<p>This essay will examine an external, blackbox penetration testing engagement I ran as a solo tester against a the regional headquarters of a Fortune 500 (the target network itself could be called a medium sized enterprise of around 300 -500 hosts, not counting servers and web appliances).</p>
<p>Ultimately, I gained ingress through exploiting a gap in the perimeter of the client’s network; this gap was created by a small IT/Web Dev/Web Marketing company the regional office had contracted.</p>
<p>Some of my career has been spent working under management that did not believe or trust in what I do. They needed me because important clients and/or governing/certification(s) bodies demanded they hire someone to perform penetration tests.</p>
<p>Call me a sucker, but I really care about what I do and I believe in trying to inspire change with my work.</p>
<p>In order to inspire that change in the face of general indifference, I quickly discovered that only full exploitation of targets could combat management’s apathy, draw needed attention to vulnerabilities and justify my employment to the powers that be.</p>
<p>Anything less would be minimized or excused; unless I gained a shell or accessed the target (at a minimum), I would need to debate multiple parties expressing magical thinking concerning the effectiveness of firewalls and AV/AM.</p>
<p>With little understanding of penetration testing, management often influenced or decided on the parameters, objectives and/or scope of the engagements I undertook.</p>
<p>This meant I was often short on resources even though I need little to ply my trade; at Schneider Electric I had a Harvard degree worth of security tool licenses (Nexpose, Metasploit Pro, Nessus, etc.)left over by my predecessors that I never touched.</p>
<p>I hate the very idea of using heavily automated tools for penetration testing. My belief is that a tool like Nessus should be used in audits and vulnerability assessments by IT, whereas my job is to find and exploit those holes IT is not likely to ever find themselves.</p>
<p>The resource I was routinely denied was one penetration testers often have little of anyway: engagement duration, the amount of company hours allotted to a penetration test</p>
<p>During the term of my employment when the penetration test detailed herein was undertaken, the work (or billed) hours I was allotted for each engagement were short.</p>
<p>The objectives that were established during the scope of engagements during this period rarely changed: ingress/gain a foothold within the LAN, exploit hosts or a host within scope, escalate privilege(s) and establish persistence within the network(s).</p>
<p>I was always right behind the eightball duration wise, so I could not afford much time for backtracking, jumping down every rabbit hole or cherry picking just the right tool.</p>
<p>I learned to treat each engagement as if it were a living thing with its own pulse and rhythm. I was along for the ride and used every trick I could to remain atop the avalanche.</p>
<p>Though I hid it as to not antagonize management, I loved every second of those engagements.</p>
<p>An Equalizer (I also think off them/call them  Dirty Tricks) are words I use for software that is an improvised offensive or defensive staple of my engagement arsenal, even though it is not a security tool.</p>
<p>As for the name “Equalizers” or “Dirty Tricks”, I had thought about the Joker’s lapel flower, a mundane gag made dangerous (spraying acid, poison gas, etc.) by the Joker’s use of strategy, tactics, intelligence and instincts (insanity?).</p>
<p>After all, Joker’s lapel flower isn’t really a long range weapon, it likely wouldn’t be very accurate, it would be slow to deploy and would need a direct hit to specific areas of a target’s physiology to be effective.</p>
<p>Joker must use guile to counteract the limitations above: perhaps faking an injury to put an enemy/victim within range or retreat into a closet to restrict the use of evasive action by an enemy/victim.</p>
<p>The ideas, strategies and tactics behind each Equalizer/Dirty Trick are more important to me than the tools themselves (and will be explained in the final section).</p>
<p>Weaponizing mundane software with strategy/tactics without changing any code speaks to the “thinking around corners” mindset that allows me to react, flow and improvise to the circumstances of an engagement…</p>
<p>My penetration testing philosophy is that I am engaged in a contest of recognizing /utilizing resources and advantages.</p>
<p>The better I become at using every resource at my disposal, the better I will become at harvesting advantages from engagement environments.</p>
<p>These posts will include images from a real world penetration test I’ve undertaken where these tool(s)l or technique(s) played a major part: maybe the tool saved me substantial time, spared me frustration or yielded results that made an impact on  the meetings, presentations and reporting afterward.</p>
<p><strong><em>2) The Engagement: Key Tactics, Tools and Methodology</em></strong></p>
<p><strong>1.DownThemAll!  -</strong> is a browser extension for Firefox released under the GNU General Public License. This extension can function as an advanced Download Manager. It can also allows a user to download or list all of the links, images or embedded objects contained in a website/web page, with both HTTP and FTP protocols supported.</p>
<p><strong>2. HackBar -</strong> In my humble opinion, HackBar is a must have tool for manually testing web applications. The most basic functionality of this extension allows you to toggle on/off a space below your browser where you can construct and execute (or copy and paste) various variations of a URL.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/bebcf3d64da0575a36fa48af05c6c0e99ed4a8a7.PNG" width="690" height="182"></p>
<p>_<strong>Image directly above:</strong> blue == HackBar toggle, Purple == HackBar dropdown, Red == DownThemAll! options/management interface(s)</p>
<p>So to start, here is the website of an organization; I needed ingress and often ingress is going to be gained through a web application or website on the perimeter.</p>
<p><strong>Image directly below:</strong> Prior DNS enumeration with tools like Fierce, Dig and NSlookup cross referenced with online sources (to be covered in another post) showed the site below as being hosted by an IP within the range of the target domain (and within the scope of the engagement).<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/0/0140770975cbb3002c0e3512b06dddcc1db866ea.jpg" width="690" height="294"></p>
<p>I utilize DownThemAll! to begin my enumeration of  a target’s web presence (my other methods will be covered in a future post) in search of a  foothold.</p>
<p>I will do this while other methods of enumeration I put in play (Dirbuster,  Nikto, OneTwoPunch for certain IP/Masscan for full CIDR, Sn1per if time is way too short) work themselves out.</p>
<p>Depending on the composition of the hosts/appliances on a target LAN, of those aforementioned/similar tools,  I may only run an ultra mellow, tightly focused  port scan.</p>
<p>This is the norm when I engage targets in the industrial/energy sectors, as some network appliances responsible for critical infrastructure (PLCs, SCADA, etc.) can be disrupted or made to crash under the force of a -T2 SYN/ACK (-sS) Nmap scan.</p>
<p>In a Red Team type engagement , I tend to  only run  the  tools I mentioned above against external facets of a target network. This way the scans are easier to obfuscate in keeping with the methodologies of real world attacks: the activity gains  cover from the cacophony that is traffic on today’s internet, plus further obfuscation via methods such as proxychains, VPNchains, Tor (TCP based or TCP/UDP based after advanced prep), I2P, and multi-hop SSH.</p>
<p>To my mind, other than daily training/self improvement for performance,enumeration is the most important part of an engagement.</p>
<p>Time management withstanding, I will manually investigate/probe findings disclosed by a tool during enumeration. Regardless of how a pain point/point of interest may find my attention, I review them through manual methods, comparing/contrasting/cross referencing my findings vs. the initial results.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/0/0396c8e7cac46d134c89cbfe73404e2a416da961.png" width="690" height="355"><br>
<strong>Image directly above:</strong> <em>DownThemAll! is run against the target site, producing a dropdown listing 200+ files/media on the site within seconds. By examining the results and the directory structures of where the results reside, I get an instant, comprehensive  look at possible points of interest.</em></p>
<p>Searching through the list of files/links/embedded media present on the site., I am most interested in the directories/directory structure where these resources reside on the site (remember, DownThemAll! can detect resources reachable by HTTP and FTP)…</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c5cc893ad1c74556b61e50ed3ce23f6e83aab68f.jpg" width="690" height="311"></p>
<p><strong>Image directly above:</strong> Lower on the list, CMS directories are found due to DownThemAll detecting HTM related to the pages…</p>
<p>When a CMS directory is discovered (and you can navigate it rather than getting served a 403 Forbidden) , it is worth enumerating  for instances of data leakage, at minimum.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c5cc893ad1c74556b61e50ed3ce23f6e83aab68f.jpg" width="690" height="311"></p>
<p>**Image directly above:**If a CMS directory (or any directory really) contains these or similar/related words, my attention is grabbed.</p>
<ol>
<li>
<strong>“sharing.htm”-</strong> Hints at controls/site/front end functionality capable of effecting/manipulating media to interact with backend resources.</li>
</ol>
<p>Forms/menu based I/O often enables vulnerabilities/exploitable configurations where prefab websites are concerned (PHP and JS tend to be a force multiplier of this).</p>
<p><strong>“sharing.htm”</strong> hints at interactions between different resources/levels of the development stack with a means of content storage/data transfer originating on the target host.</p>
<ol start="2">
<li>
<strong>“users.htm” and “myaccount.htm”-</strong> Hints at there being a high probability that credentials are available somewhere  in the back end with connectivity/interaction with form/menu based I/O in the front end.</li>
</ol>
<p><strong>Image directly below:</strong> Each of these .htm examples hint at the possibility that this site has forms/menus I can attempt to abuse outside of an  Administrator Panel. If everything on the site is fully updated and configured to Best Practice,  gaining access to a web based administrative console (examples: Wordpress Admin Panel, C Panel) is likely a time/resource sink.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/8/82a0abe2d3e555af5407a556842b5c91ffe77f5c.png" width="690" height="277"></p>
<p>The .htm examples above hint that a search for error logs on the site may also be worthwhile; if the CMS directories (and especially sensitive portions of it) are not hidden/unreachable to visitors, than a configuration issue making error logs searchable/viewable  (while displaying sensitive data such as failed logins) are not out of the question.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/7/7911459a885e6da1729fdf3ee814b42549702385.jpg" width="690" height="331"></p>
<p><strong>Image directly above</strong>: I toggle HackBar on, choose the “Load URL” option (which populates the blank dropdown field with the URL in the browser of that tab) adding “/cms” to the end of the URL, followed by choosing the “Execute” option.</p>
<p><strong>The CMS belonged to am IT/Web Dev company hired by the client to care for their web presence. Images/captions detailing what I found after landing in/enumerating the CMS directory/directories of the targetedt site mostly speak for themselves.:</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/2/27482f30fa417025b639aa6a6144e2e00ee2e528.PNG" width="690" height="297"></p>
<p><strong>Images directly above and below:</strong> It appears the IT/Web Development company servicing this website for the regional branch of a Fortune 500 company leaves a user logged into the CMS at all times.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/a/ac121a710687644bc34b364d873540c1871c2f09.PNG" width="690" height="332"></p>
<p><strong>Image below and those that follow it show data leakage perfect for myriad variety of password attacks social engineering attacks</strong>:<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/c/c7068967384a1f10abf97af0bdf31373150c708a.PNG" width="690" height="310"><br>
<strong>Image directly above with close up of the image directly below:</strong> I watched up to the minute updates to the status of company employees, tasks and events in real time via my accessing of the “Notifications” tab.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/a/ae3f8db659a7bfb3338327c2008b55a12c694ef2.PNG" width="690" height="426"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/1/1698a9d54e48b834a5657ebaa98332ec9347ae9c.png" width="690" height="317"></p>
<p><strong>Images directly above with close up of the image directly below:</strong> Reading portions of e-mails from the e-mail tab; these were a few minutes old, complete with full names.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/5/54d02f20d31ba4b4d7382b99de7047d385980a5a.PNG" width="690" height="301"></p>
<p><strong>Image directly below</strong>: Employee names /positions, rating of time spent on the site with graphs charting developer tasks underway.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/f/ffb8b9bebcdcffb0bc84bdb0e6e103429a815d41.png" width="690" height="306"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/3/35d5e43fcd38742e906bd57e8ae30d2351799bf9.PNG" width="690" height="298"></p>
<p><strong>Image directly above:</strong> Employee names, company e-mail addresses, company cell phone numbers, project status of their current project for this client and “Notes”.</p>
<p>The “Notes section” is a sort of short bulletin board for the employees to save a message concerning the status of task/project they are responsible for providing to the client.</p>
<p>I collected/saved (copy and pasted) all communications I found throughout the client site/client network, both employee to employee and employee to client.</p>
<p>Almost all of the employees that maintained a presence on the CMS of the client’s site also used multiple public facing social media accounts; while attacking these were out of scope, collecting data from them were not, as long as the accounts were set as visible to the public.</p>
<p>All of the employees had signed releases for the client months prior. These releases  allowed the client /entities contracted by the client the right to collect<br>
this data for the purposes of security testing, audits and criminal investigations</p>
<p>The employees were notified that by setting personal or business social media accounts to private, that those accounts became off limits for any manner of data collection relating to security testing,</p>
<p>All of the employees with public social media accounts posted textual content regarding their personal and work lives on a regular basis.</p>
<p>I collected/saved (copy and pasted) the varying lengths of textual communications on relevant social media accounts/client networks whenever they interacted with a fellow employee or the client/persons employed by the client.</p>
<p>This allowed me to study/collect nuances of their written communications through cross referencing them:</p>
<p>These were labeled as:</p>
<p>A) employee to employee (at work) positive, employee to employee (at work) negative, employee to employee (at work) neutral,</p>
<p>B) employee to employee (leisure) positive, employee to employee (leisure) negative, employee to employee (leisure) neutral,</p>
<p>C)employee to client (work )positive, employee to client (work )negative, employee to client (work )neutral</p>
<p>D)employee to client (leisure )positive, employee to client (leisure) negative, employee to client (neutral )</p>
<p>This system allowed me to catalogue the responses/nuances of each individual employees when interacting with each other at work, when they were not working (leisure), when interacting with the client while working/while off the clock,when doing any of the latter in a good,stressed or neutral mood. (etc.).</p>
<p>I could label work/ leisure based on the time stamps on social media/site textual content(e-mail, Notes, Posts) and sometimes that content itself.</p>
<p>This system allowed me to organize/amass my collection for rapid deployment of banter as a means of impersonation toward exploitation ( when combined with information from the data leaks I had found).</p>
<p>Often, social engineering all rides on causing a target to react in such a way that they trigger the method of exploitation you have deployed against them.</p>
<p>By developing rough proximity of multiple employees reactions during calm and stress, I raised the probability of my succesfully deploying a social engineering attack.</p>
<p>For example, sending a spearfishing e-mail that capitilizes on a mistake an employee had made last week that a co-worker had reacted with annoyance to.</p>
<p>By repeating much of the message in the e-mail (using the annoyance of one employee vs. the guilt of another) while adding “I need to you to fix this; I am catching hell for your mistake…” I may be able to numb the targets better judgement for the moments it takes to deploy a payload (while the negative emotions involved have a higher probability of limiting back chatter regarding my message).</p>
<p>The initial scope of the engagement had social engineering attacks off the table. However,  the contract governing the engagement stated that the client could add phishing/spearfishing to the scope at any time ( which would automatically extend the billed hours/duration of the engagement) as an added, bonus objective.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/ce0cbc1fd1e234ce4a9d097dafb3f6e925df3f69.PNG" width="690" height="309"></p>
<p><strong>Image directly above:</strong> Team schedule for the  month with team To-do list populated with tasks they were obligated to provide for the client.</p>
<p><strong>Image directly below below:</strong> Captured templates for the official digital/paper letterhead that had been created by the contractors for the client; some versiona of the templates had been prepared for automated e-mail deployment by the client.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/4/4f59729e4a0c321016b9351585b6540e54d4f82e.PNG" width="690" height="445"></p>
<p>Image directly below: The official invoice template belonging to the client. Created by the contractor, the client utilized the template anytime they billed for payment, whether by digital or physical media.</p>
<p>Some versions of the templates had been prepared for automated e-mail deployment by the client.</p>
<p>Notice HackBar; during an engagement,It is important that I have the most control of my traffic possible. Editing a URL without HackBar could lead to attention I don’t want; what if when I was editing the URL in my address bar it was executed by error, tripping a key term detected by Fortinet, which in turn e-mails a member of IT?<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/5/52e062545665148f21e80dca81ecd5b438e14bab.png" width="690" height="421"></p>
<p><strong>Image directly below:</strong> Open tickets with employee names and a description of the issue(s) listed with the state of ticket.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/6/60e1b814e290f78d0d7ffe4e52baa99c64f9a1ce.png" width="690" height="297"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/cb14e54b1bc367928f51e708a957f5c7fc88d9de.PNG" width="690" height="383"></p>
<p><strong>Image directly above and below:</strong> The Account Details page had the account data of the user logged into the CMS populating the form data:Full Name, Email Address, Username, Password, Role, Phone number and Website.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/0/0e05ae5f956191e4705461b3ba0e7e687805d8ee.PNG" width="690" height="299"></p>
<p><strong>Important considerations  regarding the CMS:</strong></p>
<p>A) I connected to the contractor’s CMS while enumerating our mutual client’s website, I instantly gained Administrative access, whereas I had no privileged access at all before.</p>
<p>While this privilege looked to be pruned on the CMS (I can access almost everything in a read fashion, but cannot change much in a write fashion), this was still a dangerous game the developers are playing.</p>
<p>B) This user account seemed to be permanently  logged into the CMS; per the “My Account Details”, field,  this account was stated to have an Administrator role/level of privilege.</p>
<p>C)This default Administrator account seemed to be  the default level of privilege a user gained when accessing the CMS (at least until l a user entered their unique employee credentials).</p>
<p>D) I counted over 20 unique usernames on the CMS. It is likely that the CMS was left in this condition so that the contractor’s employees (and possibly the client) could keep track of the progress of projects undertaken by other employees, even if they were having some temporary credential issue.</p>
<p>E)The contractor’s CMS was not expressly within scope, so I couldn’t attack it directly.</p>
<p>However, I could enumerate the contractor’s web presence; after doing so (which will be covered in another post), I discovered that the contractor in question was fond of a Sitepoint-like, multi site/domain CMS solution.</p>
<p>I think it is likely this CMS is reachable and reaches to multiple networks/domains in the client network…</p>
<p>Having opened DownThemAll!, I noticed two things (outlined in red):<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/4/416b1b13e39031cd827736c35f6046514cece4c2.PNG" width="690" height="451"></p>
<ol>
<li>The name of this CMS page is “contractor WebApp”; my gut said high likelyhood  that the CMS was connected to multiple domain/network segments belonging to the client.</li>
<li>Using DownThemAll! once more, the dropdown revealss multiple CMS entries, then a “<a href="http://www.client.com" rel="noopener nofollow ugc">www.client.com</a>” entry, which I haven’t seen yet when running the extennsion on the CMS.</li>
</ol>
<p>So I navigate to it…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/2/24fc86eab7a63c5a402f93798a7421924c966ad4.jpg" width="690" height="334"><br>
<strong>Image directly above -</strong> The first thing that stands out is that the SSL/TLS certificate does not look like it is issued by a Certificate Authority; the first site did not have this issue…</p>
<p><strong>Image directly below:</strong> I deploy DownThemAll!, and many results radically different than the first search on the original home page are found. The first being a link that equates to <strong>https:/ / 0.0.0.0 /~clientsite .com/</strong><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/7/7ab95907c8b8ef402a23907940f210a3060e3edc.PNG" width="690" height="401"></p>
<p>Directly below: Using with HackBar, we head there…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/f/f6d952caf7c1f64adf333698d67ddcea3fb0cc7f.png" width="690" height="239"></p>
<p>Directly below: We use HackBar to visit http:/ / 0.0.0.0 (IP redacted)…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/6/67f70bd90e7dca647ea6eee14fa8b01c5b7cf5c3.png" width="690" height="267"></p>
<p>Looks like we found our way out of the web directory responsible for the site; there is no longer any HTTP/HTTPS URL in the search bar, only the IP.</p>
<p>Let’s try something back on the root directory. We go back to http: / 0.0.0.0 / ~clientsite. com and use DownThemAll!..<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/3/32c9f8f7a51192443a29de2d1ff490de47c8e11e.PNG" width="690" height="211"></p>
<p>We have two more entries for https:/ / clientsite. com / and http: // clientsite. com/, except they have the symbols for a Windows binary/executable, which we haven’t seen yet.</p>
<p><strong>Image directly below -</strong> Also, we have an entry for https:// clientsite .com/ internal/ corp2.htm; we head there…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/0/005f945b9b996632040c23b700be32b9ac53ac5f.PNG" width="690" height="300"></p>
<p><strong>Image directly below -</strong> We end up in an employee internal corporate account…from 2006 (at least a decade old at that point), evidenced by the latest entry in the company calender…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/7/7b03faa94a07bcc09bc1c8db52d1cd480268b006.PNG" width="690" height="250"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/a/abf724b2ea09d2ba673c3cb67f9dc5731cb37a0f.PNG" width="690" height="253"></p>
<p><strong>Image directly above -</strong> Down them all shows some interesting results; notice that HTTPS is back in play, a bunch of unknown documents, some labeled Outlook 2000, XP, or  and Server 2003…</p>
<p>Image directly below - After checking one of the links, I find this…<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/d/d3e831251425b449e175c955998d7cab470ab63e.PNG" width="690" height="187"></p>
<p><strong><em>3) Closing Statements</em></strong></p>
<p>So what happened?</p>
<p>We will follow the second half of this penetration test at another time. What happened is that I had utilized the contractor’s CMS to jump into an internal computer that had been utilized by the client’s former helpdesk/IT staff; the CMS was in no way secured at that moment vs. trespass.</p>
<p>The contractor stated that they had counted on multiple security technologies within the network and a WAF on the host in question, all of which “failed” to secure the CMS during the engagement.</p>
<p>The other “www .client.com” host I ended up in was on the network used internally within the headquarters by the client’s employees.</p>
<p>Thus, I utilized the CMS as a pivot to gain ingress onto a host on the inner perimeter of the LAN/Intranet.</p>
<p>The webpage without the expected SSL/TLS certificate had been a host where a mockup of the site had been constructed for development.</p>
<p>I began outside the network and ended this essay on a host running a mess of outdated software inside corporate headquarters…</p>
<p>The example images I’ve shown were caught by DownThemAll! and searched/expanded via HackBar during a real penetration test.</p>
<p>The images I’ve shown were by no means all of them pertaining to DownThemAll!, the CMS or the website during this specific engagement.</p>
<p>However, I’ve kept you too long already; so let’s wrap things up with two more things.</p>
<p>First: If you happened by the LinkedIn of some of the employees belonging to the IT/web developers in question, you would have seen the words “security expertise” thrown around quite a bit.</p>
<p>This is just one reason why penetration testing is important: we are the acid test that shows a company the truth worth of what it is paying for.</p>
<p>A security incident can establish this truth as well, though this revelation will almost always be far more painful and expensive.</p>
<p>The internet is now a brave place; untested things left in this space will be tested by someone, which may end up deciding ownership preemptively.</p>
<p>Second: the reason I believe DownThemAll! is worth this level of exhibition is that far more often than not, the extension provides me with many significant options/functions with very little time sink.</p>
<p>During many engagements, time is the main nemesis of the pentester.</p>
<p>In the engagement documented by this article, I was on the website with an open browser window just prior to deploying DownThemAll!. Perhaps three to five seconds after hitting the toolbar icon, the extension populated results; I noticed the entries for the CMS directory perhaps ten to fifteen later.</p>
<p>In less than thirty seconds, DownThemAll! provided multiple paths leading to viable methods for threatening the target network: initially, password attacks, configuration issues with the site (such as the CMS) and social engineering attacks (not in scope, though my pentest report analyzed the risks).</p>
<p>With little investment, DownThemAll! provides versatile, multi-applicable, strategic intelligence with easily identifiable value</p>
<p>Multi-applicable strategic intelligence - At minimum, discovery of CMS directories led to myriad resources capable of weaponization for reasons of exploitation and/or resources capable of repurposing for tactics that supported those purposes.</p>
<p>This included, but was not limited to: employee names, company e-mail/invoice/inquiry templates,employee names with job titles, phone numbers (multiple per employee in many cases), Account Login credentials (with username/password, password length,e-mails attached/phone number attached to account), target intelligence (employee/team schedules, employee/team To-do list, messages, ticketing system, etc.)and suspect site configurations.</p>
<p>Easily identifiable value - The value of the data provided by DownThemAll! is easy to identify, requiring little time or energy to analyze or apply effectively.</p>
<p>The data displayed by the extension is easy to process as findings are conveyed in a simple manner: a vertical column in descending order with few controls, colored white and gray.</p>
<p>I have found that this presentation helps me with processing the data when comparing, contrasting or applying critical thinking skills. (example: prioritizing which single instance of two web servers you will enumerate first based on the directories, files and links present in each servers DownThemAll! table).</p>
<p>Furthermore, I believe the presentation aids me in utilizing the data in an improvisational, spontaneous and/or creative manner.</p>
<p>Versatile - The tool can be applied with ease and haste. Unless changes are being made through the controls or management interface (which I very rarely find a need to adjust), the longest prep for deployment of the extension involves a web browser being opened to the website/web page in question(and execution of the add-on by way of the tool bar icon).</p>
<p>Thus, it should have little interference with or impede other tools/strategies being; I have yet to have experience any interactions between the extension and another tool (including other browser extensions).</p>
<p>The intended functionality of the extension allows for downloading all manner and number of files, links and embedded content (all three can be downloaded any combination of ways: separately, compiled as a text-based list, downloaded from a list, etc.) off of a website, web page,browser tab or off browser tabs.</p>
<p>The functions in the paragraph above can aid in capturing data for later reporting, for finding otherwise hidden links/files/embedded content on a site and many other tasks during/after an engagement.</p>
<p>Another bonus with DownThemAll! is actually its earliest key function: it can function as a more conventional download manager. This includes download by way of multi-part download (quickened downloads by receiving the data in pieces, assembling it when the download ends), Metalink (able to download data/checksums for one file from over multiple URLs at once) while being able to stop, restart and pause downloads.</p>
<p>Sometimes you need to download something during an engagement, but the connection speed is terrible, whether by browser or terminal.</p>
<p>As a download manager, DownThemAll! does seem to speed things up more than I remember similar browser extensions or software doing. It does this while allowing you to focus on the engagement rather than that download that keeps failing.</p>
<p>Links:</p>
<p>DownThemAll:<a href="https://addons.mozilla.org/en-US/firefox/addon/downthemall/" rel="noopener nofollow ugc">https://addons.mozilla.org/en-US/firefox/addon/downthemall/</a></p>
<p>Note: Firefox over version 51 cannot use DownThemAll! (or multiple other add-ons), so plan accordingly for security issues related to outdated browsers.</p>
<p>HackBar: <a href="https://addons.mozilla.org/en-US/firefox/addon/hackbar/" rel="noopener nofollow ugc">https://addons.mozilla.org/en-US/firefox/addon/hackbar/</a></p>
            <p><small>6 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/real-penetration-tests-equalizers-and-dirty-tricks/5512">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/real-penetration-tests-equalizers-and-dirty-tricks/5512</link>
          <pubDate>Sat, 17 Feb 2018 08:43:07 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-5512</guid>
          <source url="https://0x00sec.org/t/real-penetration-tests-equalizers-and-dirty-tricks/5512.rss">Real Penetration Tests: Equalizers and Dirty Tricks</source>
        </item>
        <item>
          <title>Multithreaded Remote Backup Scanner</title>
          <dc:creator><![CDATA[larkwiot]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hello all,</p>
<p>I am looking for feedback on my backup finding tool.</p>
<p><strong>What is it and what does it do?</strong><br>
It’s a Python script that utilizes requests and multiprocessing to concurrently scan a remote file to find a backup of it, given URLs.</p>
<p><strong>How does it do it?</strong><br>
On a more detailed level, it takes any amount of URLs and then parses them to break them into pieces: The subdomain and domain is the first piece, then the path, then the file, then the file extension. So <a href="http://www.google.com/var/example.php" rel="noopener nofollow ugc">www.google.com/var/example.php</a> would be broken up into <a href="http://www.google.com" rel="noopener nofollow ugc">www.google.com</a>, /var/, example, and .php. From there it creates a process for each URL and uses its dictionary of extensions and name versions to test nearly 2500 possible backups of the given file. e.g., if <a href="http://www.google.com/var/example.php.old" rel="noopener nofollow ugc">www.google.com/var/example.php.old</a> exists, it will find it. It then displays the results.</p>
<p><strong>How fast is it?</strong><br>
This is something I am working on, because it takes 8 minutes. Not 8 minutes per URL, just 8 minutes flat because of the multiprocessing.</p>
<p><strong>Where is it?</strong><br>
</p><aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/larkwiot/backupfinder" target="_blank" rel="noopener nofollow ugc">GitHub</a>
  </header>
  <article class="onebox-body">
    <img src="https://0x00sec.s3.amazonaws.com/original/2X/9/97c03c17a6ed37450cc26eeeb06eaeae0c3e8c32.png" class="thumbnail onebox-avatar" width="400" height="400">

<h3><a href="https://github.com/larkwiot/backupfinder" target="_blank" rel="noopener nofollow ugc">larkwiot/backupfinder</a></h3>

<p>Contribute to larkwiot/backupfinder development by creating an account on GitHub.</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>
<p></p>
<p><strong>What Python version is it?</strong><br>
I wrote it 2.7, but tjcater made a port to 3.something.something.</p>
<p>Feel free to ask questions or give comments/suggestions.</p>
<p>Thanks!</p>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/multithreaded-remote-backup-scanner/4308">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/multithreaded-remote-backup-scanner/4308</link>
          <pubDate>Sun, 12 Nov 2017 21:12:11 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-4308</guid>
          <source url="https://0x00sec.org/t/multithreaded-remote-backup-scanner/4308.rss">Multithreaded Remote Backup Scanner</source>
        </item>
        <item>
          <title>A pretty good URL scanner</title>
          <dc:creator><![CDATA[Retr1]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>I came accross this pretty good URL scanner called urlscan. It is still in beta but it works pretty good and is accurate and can obtain a lot of information. Plus it is a passive recon tool, meaning you don’t touch the target directly. +5 stealth!</p>
<p>Just a quick find I wanted to share</p>
<p><a href="https://urlscan.io/" class="onebox" target="_blank" rel="nofollow noopener">https://urlscan.io/</a></p>
            <p><small>11 posts - 8 participants</small></p>
            <p><a href="https://0x00sec.org/t/a-pretty-good-url-scanner/3959">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/a-pretty-good-url-scanner/3959</link>
          <pubDate>Wed, 18 Oct 2017 18:02:19 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-3959</guid>
          <source url="https://0x00sec.org/t/a-pretty-good-url-scanner/3959.rss">A pretty good URL scanner</source>
        </item>
        <item>
          <title>IP logger | new api-ish service</title>
          <dc:creator><![CDATA[Logic-gate]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hey Guys,</p>
<p>First post here, <img src="https://0x00sec.org/images/emoji/twitter/innocent.png?v=9" title=":innocent:" class="emoji" alt=":innocent:"></p>
<p>I am here to introduce a new aspect of a project I am working on(<a href="http://ki.tc" rel="nofollow noopener">http://ki.tc</a>). An IP logger with CLI in mind. Now, I have taken an API approach to this, so all calls are JSON dependent. Apart from my introduction, I would appreciate new ideas or rather feedback from the community as to further enhance the service…here goes…</p>
<p><em>Creating a link:</em></p>
<pre><code class="lang-auto"> curl -i -H "Content-Type: application/json" -X POST -d '{"url": "http://google.com"}' http://ki.tc/
</code></pre>
<p><em>Response:</em></p>
<pre><code class="lang-auto">{
  "url_short": {
    "_id": "b24a138a7f1bce6c493bc", 
    "admin_link": "http://ki.tc/url_shortner/b24a138a7f1bce6c493bc", 
    "link": "http://ki.tc/d93da", 
    "time": "Sun, 27 Aug 2017 18:35:16 GMT", 
    "url": "http://google.com"
  }
}
</code></pre>
<p><code>_id</code> is not retrievable, so save it.</p>
<hr>
<p><em>Admin Access:</em></p>
<pre><code class="lang-auto">curl -i -H "Content-Type: application/json" -X GET http://ki.tc/url_shortner/b24a138a7f1bce6c493bc
</code></pre>
<p><em>Response:</em></p>
<pre><code class="lang-auto">{
  "_id": "b24a138a7f1bce6c493bc", 
  "url_build": {
    "_id": "b24a138a7f1bce6c493bc", 
    "admin_link": "http://ki.tc/url_shortner/b24a138a7f1bce6c493bc", 
    "link": "http://ki.tc/d93da", 
    "time": "Sun, 27 Aug 2017 18:35:16 GMT", 
    "url": "http://google.com"
  }, 
  "url_id": 194249668
}
</code></pre>
<p><em>Admin access updated(after someone visits the link). Updated with every Access attempt.</em></p>
<pre><code class="lang-auto">{
  "2017-08-27 18:39:19": {
    "165914": {
      "access_id": "ae3c63d61f35", 
      "access_time": "Sun, 27 Aug 2017 18:39:19 GMT", 
      "ip_address": "X.X.X.X", 
      "user_agent": "Mozilla/5.0 (X11; Linux x86_64)"
    }
  }, 
  "_id": "b24a138a7f1bce6c493bc", 
  "url_build": {
    "_id": "b24a138a7f1bce6c493bc", 
    "admin_link": "http://ki.tc/url_shortner/b24a138a7f1bce6c493bc", 
    "link": "http://ki.tc/d93da", 
    "time": "Sun, 27 Aug 2017 18:35:16 GMT", 
    "url": "http://google.com"
  }, 
  "url_id": 194249668
}

</code></pre>
<p>Each access object is nested with a time-of-access key, which in return is nested with an identifier. Not to be confused with <code>access_id</code>.</p>
<hr>
<p><em>Delete Link(DELETE METHOD | admin link)</em></p>
<pre><code class="lang-auto">curl -i -H "Content-Type: application/json" -X DELETE http://ki.tc/url_shortner/b24a138a7f1bce6c493bc
</code></pre>
<p><em>Response:</em></p>
<pre><code class="lang-auto">{
  "result": true
}

</code></pre>
<hr>
<p>After finishing, I realized that I spelled shortener wrong <code>shortner</code>…speechless <img src="https://0x00sec.org/images/emoji/twitter/sweat_smile.png?v=9" title=":sweat_smile:" class="emoji" alt=":sweat_smile:"></p>
<hr>
<p>Anyways, I would appreciate any feedback, productive or destructive…doesn’t matter as long as it is feedback.</p>
<p>Cheers,</p>
            <p><small>12 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/ip-logger-new-api-ish-service/3437">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/ip-logger-new-api-ish-service/3437</link>
          <pubDate>Tue, 29 Aug 2017 19:48:00 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-3437</guid>
          <source url="https://0x00sec.org/t/ip-logger-new-api-ish-service/3437.rss">IP logger | new api-ish service</source>
        </item>
        <item>
          <title>ORFinder, the easy way to abuse mail servers</title>
          <dc:creator><![CDATA[Nitrax]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hi fellas,</p>
<p>Let me introduce you my last tool, <a href="https://github.com/Nitr4x/ORFinder" rel="nofollow noopener">ORFinder</a></p>
<p>ORFinder claims to be able to find any smtp services, exposed over the internet, vulnerable to open relay attack.<br>
Such attack relies on the fact that the sender / receiver addresses are not checked by the underlying mail server, allowing to perform phishing attacks or any kind of fraud. Which could be valuable for any OPSEC.</p>
<p><strong>DISCLAIMER: I’m not responsible for misuse or for any damage that you may cause! You agree that you use this software at your own risk.</strong></p>
<p><strong>Note: The usage of a VPN could disrupt the tool behaviors. Stay tuned for updates</strong></p>
<h2>How it works</h2>
<p>Here is, in a few lines, the tool workflow:</p>
<pre><code class="lang-bash">Get IP ranges according to the given country code
For each IP
	Check if the smtp service is running
	if True
		Check if the service is vulnerable to open relay attack
</code></pre>
<p>Pretty straightforward, isn’t it ?</p>
<h2>Usage</h2>
<h3>Build</h3>
<p>To build the container, just use this command:</p>
<pre><code class="lang-bash">docker build -t orfinder .
</code></pre>
<p>Docker will download the Debian image and then execute the installation steps.</p>
<blockquote>
<p>Be patient, the process can be quite long the first time.</p>
</blockquote>
<h3>Run</h3>
<p>Once the build process is over, get and enjoy your new open relay scanner !</p>
<pre><code class="lang-bash">docker run -it --rm orfinder -c COUNTRY_CODE
</code></pre>
<blockquote>
<p>Don’t forget to regularly pull this repository for updates.</p>
</blockquote>
<h2>FAQ</h2>
<p>Here is a few questions that you guys asked me on IRC.</p>
<h3>How did you get the IP ranges of a given country ?</h3>
<p>I advise you to check the Loader <img src="https://0x00sec.org/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"> I don’t want to disclose the source here to avoid Google indexing.</p>
<h3>How did you detect open services ?</h3>
<p>The detection is performed through a simple TCP SYN scan.</p>
<h3>How did you detect if a given service is vulnerable ?</h3>
<p>Once the TCP connection established with the target, I send the following commands and check the return value.</p>
<pre><code class="lang-bash">HELO domain.com
MAIL FROM: domain@gmail.com
RCPT TO: domain-rcv@gmail.com
</code></pre>
<p>If each of those commands return 250, it means that the service is potentially vulnerable to open relay attacks. I said potentially cause, some mail servers implement security measures that cannot be detected without being, prior, root <img src="https://0x00sec.org/images/emoji/twitter/stuck_out_tongue.png?v=9" title=":stuck_out_tongue:" class="emoji" alt=":stuck_out_tongue:"> .<br>
Consequently, a manual check should be done once the vulnerable service has been detected.</p>
<h3>Is it safe to use ?</h3>
<p>TCP SYN scan is, probably, the stealthiest way to perform port scanning. Moreover, our requests should be drowned by the bots scanning the internet constantly.</p>
<p>Upstream, the vulnerability check, instantiate a TCP connection with the target. For privacy reasons, I chose to proxify each request made through TOR not to disclose the end user identity.</p>
<h2>Last words</h2>
<p>Contributions are welcome if you have ideas to enhance this tool <img src="https://0x00sec.org/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"></p>
<p>I hope you enjoyed your reading.</p>
<p>Best,<br>
Nitrax</p>
            <p><small>8 posts - 6 participants</small></p>
            <p><a href="https://0x00sec.org/t/orfinder-the-easy-way-to-abuse-mail-servers/3237">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/orfinder-the-easy-way-to-abuse-mail-servers/3237</link>
          <pubDate>Mon, 07 Aug 2017 15:31:37 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-3237</guid>
          <source url="https://0x00sec.org/t/orfinder-the-easy-way-to-abuse-mail-servers/3237.rss">ORFinder, the easy way to abuse mail servers</source>
        </item>
        <item>
          <title>HACK BACK! Phineas Fisher</title>
          <dc:creator><![CDATA[whatskrakan_01]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p><a href="https://ghostbin.com/paste/6kho7" rel="nofollow noopener">https://ghostbin.com/paste/6kho7</a><br>
<a href="https://pastebin.com/BMb543G9" rel="nofollow noopener">https://pastebin.com/BMb543G9</a><br>
On July 5, 2015, Hacking Team’s Twitter account was compromised by an unknown assailant who ended up publishing 400GB of data including alleged e-mails, invoices, and source code of the company. Zero days for Adobe Flash( CVE-2015-5119) which allowed an attacker to open apps on a victims PC through a webpage. Along with that, there was a buffer overflow attack on Adobe open type manager that allowed for privilege escalation to bypass sand-boxing capabilities. There was evidence that Hacking team did business with Sudan and the Lebanese Army, and sold tools to Bahrain and Kazakhstan.</p>
<p>The hacker who claimed responsibility for this attack called themselves Phineas Fisher. They previously attacked a spyware firm named Gamma International. The way he got in was from a zero-day root exploit in an embedded device inside the companies corporate network, after scanning the internal network, he found an exchange email server which he was able to get the password for. How he was able to crack this is a mystery, since the password was P4ssword. From there, he was able to get the passwords of every user in the company in plain text. You can read a more in depth article about it <a href="http://news.softpedia.com/news/finfisher-s-account-of-how-he-broke-into-hackingteam-servers-503078.shtml" rel="nofollow noopener">here</a></p>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/hack-back-phineas-fisher/3152">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/hack-back-phineas-fisher/3152</link>
          <pubDate>Wed, 02 Aug 2017 20:04:56 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-3152</guid>
          <source url="https://0x00sec.org/t/hack-back-phineas-fisher/3152.rss">HACK BACK! Phineas Fisher</source>
        </item>
        <item>
          <title>Are there more tools like ProbeKit for gathering and manipulating wifi data?</title>
          <dc:creator><![CDATA[ragnar]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>I am thinking about creating one myself / build on ProbeKit, but am wondering if there are such tools already in existence from which I can get ideas etc. I couldn’t find many by just Googling.</p>
<p>Sorry if it’s a noob/silly question, I am a small time lurker here with little knowledge of security and related fields.</p>
            <p><small>18 posts - 7 participants</small></p>
            <p><a href="https://0x00sec.org/t/are-there-more-tools-like-probekit-for-gathering-and-manipulating-wifi-data/2955">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/are-there-more-tools-like-probekit-for-gathering-and-manipulating-wifi-data/2955</link>
          <pubDate>Mon, 17 Jul 2017 12:16:19 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2955</guid>
          <source url="https://0x00sec.org/t/are-there-more-tools-like-probekit-for-gathering-and-manipulating-wifi-data/2955.rss">Are there more tools like ProbeKit for gathering and manipulating wifi data?</source>
        </item>
        <item>
          <title>Elicitation Guide?</title>
          <dc:creator><![CDATA[Bugsy]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Im an extremely Extroverted Person.   I love people, to the point i have full blown conversations with people inside a store, or gas station, as if we have been friends for years.  I dont really have that much knowledge base about exploits, or full on pentesting…YET!</p>
<p>I am still learning, but i know that in a lot of “hypothetical Situations” i can rely on my social skills heavily to do a lot of the work.   One of my white hat friends is always amazed at how much work load i could possibly save just by being a people person.</p>
<p>I have read hundreds of books, watched plenty of lectures, and practiced many techniques revolving around reading peoples body language, judging tone of voice to feelings, and using my ability to gain someones trust in 5 minutes or less.  I recently have found myself going into hotels, businesses, etc…etc… to see how long i can blend in before anyone notices.  You would be surprised how many people dont care to ask who this in a button up and tie, walking around with an iPad is.</p>
<p>There is just, something so Clandestine about it, as if i was living in a spy film that drives me to do it.   I wont do anything crazy and go into government buildings, or do any damage, However it is amazing how fast you can sharpen your social skills by just pretending, Either in person, or over the phone.</p>
<p>My tech skills are not up to par with most in this awesome community…but my social skills are definitely a strong suit worth sharing.   Its one of the few things i can try to contribute to the community for the time being.</p>
<p>So my question is,  Would there be anyone interested in a guide to “Pretending” ?</p>
<p>If so let me know below, and include certain topics, or situations you would like me to include.</p>
            <p><small>25 posts - 9 participants</small></p>
            <p><a href="https://0x00sec.org/t/elicitation-guide/1751">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/elicitation-guide/1751</link>
          <pubDate>Tue, 07 Mar 2017 17:36:21 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1751</guid>
          <source url="https://0x00sec.org/t/elicitation-guide/1751.rss">Elicitation Guide?</source>
        </item>
        <item>
          <title>WhichCDN: How to automate CDN detection</title>
          <dc:creator><![CDATA[Nitrax]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Hi fellas,</p>
<p>First of all, I wanted to apologize for my lack of activities the last month. Indeed, I was overwhelmed by my work and my training for my <a href="https://www.offensive-security.com/information-security-certifications/oscp-offensive-security-certified-professional/" rel="noopener nofollow ugc">OSCP</a> certification which was quite time consuming <img src="/images/emoji/twitter/cold_sweat.png?v=9" title=":cold_sweat:" class="emoji" alt=":cold_sweat:"></p>
<p>By the same token, would you be interested in my feedback about OSCP?</p>
<p><a href="https://0x00sec.org/t/whichcdn-how-to-automate-cdn-detection/1587/1">Click to view the poll.</a></p>
<p>Well, today article is going to be focused on my last project, <a href="https://github.com/Nitr4x/whichCDN" rel="noopener nofollow ugc">whichCDN</a>.</p>
<p>As you already know, the recon phase is primordial and determine if your attempts to access the targeted system will be successful.</p>
<p>A multitude of tools allows performing ports scan, DNS enumeration, CMS detection and various other types of assessments. However, none of those allow you to easily and efficiently detect if a given website is protected by a CDN (Content Delivery Network).</p>
<p>CDNs become more and more popular those days and provide features to shield websites against numerous types of attacks such as:</p>
<ul>
<li>Denial of Service</li>
<li>Distributed Denial of Service</li>
<li>Distributed Reflection Denial of Service</li>
<li>XSS, SQLI through WAF (Web Application Firewall)</li>
</ul>
<p>Among those security measures, they allow to speed up the loading of your website by improving the cache system, load balancing, browser optimization, JavaScript minimization, etc.</p>
<p>CDNs are a real challenge for pentesters / hackers which often hide the target’s real address, preventing any further system based attacks. Its detection will result in a gain of time, avoiding unnecessary assessments.</p>
<p>WhichCDN implements five methods detection:</p>
<h3>Whois Detection</h3>
<p>CDNs could impact the whois command results by changing several fields e.g. Name Server, nserver, etc.</p>
<h3>Error Server Detection</h3>
<p>A few CDNs disclose information when we try to directly access the IP address resolved by the host command, exposing themselves.</p>
<h3>HTTP header Detection</h3>
<p>Some CDNs could be quite intrusive and modify the HTTP header by adding or replacing existing fields which allow detecting their presence.</p>
<h3>DNS Detection</h3>
<p>When resolving the DNS of a given domain name, it is common to find the name server associated to the CDN in place.</p>
<h3>Subdomain Detection</h3>
<p>Big companies often use a subdomain to configure their CDN, by trying to access such subdomain, it is possible to determine which technology is used.</p>
<p>Let’s try it on 0x00sec</p>
<h4>Usage</h4>
<pre><code class="lang-bash">whichCDN http://example.com | example.com
</code></pre>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/a/a71cdb08d27fe3baaa939f0873a8e10f6f23a64d.png" width="483" height="177"></p>
<p>As you can see on the picture above, <a href="http://0x00sec.org">0x00sec.org</a> is protected by Cloudflare. It is just as simple as that.</p>
<h2>Supported CDNs</h2>
<ul>
<li>Cloudflare</li>
<li>Incapsula</li>
<li>Cloudfront</li>
<li>Akamai</li>
<li>Airee</li>
<li>CacheFly</li>
<li>EdgeCast</li>
<li>MaxCDN</li>
<li>Beluga</li>
<li>Limelight</li>
<li>Fastly</li>
<li>Myracloud</li>
<li>Microsft Azure</li>
</ul>
<h2>Axes of improvement</h2>
<p>I don’t know yet if it is possible to bypass such security measures but once done, it would be awesome to add attack vectors to work around those filtration systems.</p>
<p>Moreover, I would like to populate the list of supported CDN with other service providers such as:</p>
<ul>
<li>Azion</li>
<li>ArvanCloud</li>
<li>Beluga</li>
<li>DN77</li>
<li>CDNetwork</li>
<li>CDNsun</li>
<li>CDNvideo</li>
<li>ChinaCache</li>
<li>ChinaNetCenter</li>
<li>Highwinds</li>
<li>KeyCDN</li>
<li>Level3</li>
<li>NGENIX</li>
<li>Quantil</li>
<li>SkyparkCDN</li>
<li>Verizon Digital Media services</li>
<li>Turbobyte</li>
</ul>
<h2>Contribution</h2>
<p>Don’t hesitate to contribute to this project if you are aware of other ways to detect CDNs. Lastly, feel free to contact me if you know websites using a specific type of CDN that is not supported yet!</p>
<p>I hope that you enjoyed this article.</p>
<p>Best,<br>
Nitrax</p>
            <p><small>8 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/whichcdn-how-to-automate-cdn-detection/1587">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/whichcdn-how-to-automate-cdn-detection/1587</link>
          <pubDate>Mon, 13 Feb 2017 10:29:32 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1587</guid>
          <source url="https://0x00sec.org/t/whichcdn-how-to-automate-cdn-detection/1587.rss">WhichCDN: How to automate CDN detection</source>
        </item>
        <item>
          <title>Introduction to Carrot2</title>
          <dc:creator><![CDATA[n3xUs]]></dc:creator>
          <category>Reconnaissance</category>
          <description><![CDATA[
            <p>Welcome everyone! In this article, I’ll try to briefly introduce you to the amazing <em><strong>Carrot2 Clustering Engine</strong></em>. I don’t know about you, but I only found out about this tool a couple of days ago and I thought it was worth sharing it.</p>
<p>So,</p>
<p>##<span class="hashtag">#What</span> is Carrot2?</p>
<blockquote>
<p>Carrot2 is an Open Source Search Results Clustering Engine. It can automatically organize small collections of documents (search results but not only) into thematic categories.</p>
</blockquote>
<p>– Official <a href="http://project.carrot2.org/" rel="noopener nofollow ugc">Carrot2 Website</a></p>
<p>What does this mean? Well, let me show you:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/3/3df4b1e7d17d9f942cbdb602ccd678b8daa4593a.png" width="690" height="238"></p>
<p>You’ll be greeted with this quite simple and straight forward homepage.</p>
<p>Let’s try searching for <code>0x00sec</code>.<br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/d/d0ca9d89a13d026f6aa8279da72c41e659a04715.png" width="690" height="333"></p>
<p>As you can see in the green rectangle, we have 3 viewing options: <em>Folders</em> (picture above)</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/b5ad0ce01d0a1d90bfb3375a780cfeb411d2e63a.png" width="690" height="332"></p>
<p><em>Circles</em></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/e/e7e94bedc86a57dd1adfb9cd87f40f3b3a71790a.png" width="690" height="333"></p>
<p>And <em>FoamTree.</em></p>
<p>As I’ve highlighted in the first image, there are a few topics that immeadiatly caught my interest, those are:</p>
<ul>
<li>
<p>A website (<a href="http://0x00sec.org">0x00sec.org</a>)</p>
</li>
<li>
<p>Topics related to that website</p>
</li>
<li>
<p>A related website (P^3)</p>
</li>
</ul>
<hr>
<p><em><strong>Side Note numero uno</strong>: In the <strong>Folders</strong> option, the topics are ordered by relevance (most relevants come first); In the <strong>Circles</strong> option, size = relevance (bigger = more relevant); The <strong>FoamTree</strong> option follows the same logic as <strong>Circles</strong>.</em></p>
<p><em><strong>Side Note numero dos</strong>: Of course there will be some topics that are little or not at all related to what you’re trying to find, I mean, I don’t know about you, but I’m not very interested in “SEC Men’s Basketball Championship”.</em></p>
<p><em><strong>Side Note numero tres</strong>: For the rest of this post, I’ll be using the <strong>Circles</strong> option.</em></p>
<hr>
<p>As I have previously stated, the website is the most interesting topic, so let’s follow the rabbit!</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/ba19a90cf64b1189385f5bde27f58f1d8098d509.png" width="690" height="333"></p>
<p>On the right end corner you see the ‘search for more like this option’. We click it, and the website returns us the search result for <code>0x00sec.org</code></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/f/f286c80dd3d70f583356a4194fec5e69020a0396.png" width="690" height="333"></p>
<p>Now, we see that a lot of the topics the search returns are titles of posts or categories within this website (we know that because, well, we are the users of this webiste. However, someone doing proper research would have to spend some time reviewing and analyzing each topic and link).</p>
<hr>
<p>This pretty much covers Carrot 2. As demonstrated, it can be used for subjects like this where our purpose is to gather information on something/someone, maybe find some new data correlations between one or more subjects or it can be used as an actual search engine, like to search <code>Mems</code> - no, not memes, Mems!</p>
<p>Oh! You don’t know what that is? Well, here you go:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c132a91e54eb1021baad03a57df85e4a59dd0036.png" width="690" height="330"></p>
<p>Ta dah! Pretty cool right?</p>
<hr>
<p>This brings us to the end of the post! I hope you’ve enjoyed this simple example and also that it encourages you to try Carrot2 for yourselves (<a href="http://search.carrot2.org/stable/search" rel="noopener nofollow ugc">Carrot2 Search</a>), I’m sure you’ll like it as much as I do.</p>
<p>Until we meet again sometime &amp; somewhere in the space-time continuum!</p>
            <p><small>7 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/introduction-to-carrot2/1470">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/introduction-to-carrot2/1470</link>
          <pubDate>Wed, 18 Jan 2017 19:15:31 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1470</guid>
          <source url="https://0x00sec.org/t/introduction-to-carrot2/1470.rss">Introduction to Carrot2</source>
        </item>
  </channel>
</rss>
