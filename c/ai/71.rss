<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:discourse="http://www.discourse.org/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Artificial Intelligence - 0x00sec - The Home of the Hacker</title>
    <link>https://0x00sec.org/c/ai/71</link>
    <description>Topics in the &#39;Artificial Intelligence&#39; category </description>
    
      <lastBuildDate>Thu, 07 Jan 2021 19:37:47 +0000</lastBuildDate>
      <atom:link href="https://0x00sec.org/c/ai/71.rss" rel="self" type="application/rss+xml" />
        <item>
          <title>Machine learning-assisted Fuzzer finds 31 new vulnerabilities</title>
          <dc:creator><![CDATA[kris]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>Hey all. This post will briefly describe how a machine learning enabled-fuzzer, NEUZZ, outperformed 10 non-ML-assisted fuzzers on 10 real programs to find 31 unknown vulnerabilities. NEUZZ was created by researchers from Columbia University, She et al in 2019. NEUZZ is open source software available on <a href="https://github.com/Dongdongshe/neuzz" rel="noopener nofollow ugc">GitHub</a>.</p>
<p>The increased performance and opportunities provided by machine learning is why I created a <a href="https://security.kiwi" rel="noopener nofollow ugc">machine learning course for hackers</a> called Security Kiwi which launched today. The course starts off beginner-friendly with the fundamentals and we quickly work our way into practical exercises, neural networks and other fun stuff.</p>
<p>Eventually, learners build larger machine learning projects: automated email malware collection, facial recognition for OSINT, threat prediction, ‘cyber weather’ prediction, and more. I want to encourage the use of ML and experimentation with ML in a non-academic/commercial environment, so much of the course content is free. Videos, downloads, Q&amp;A, discussion, etc available to patreon supporters. New content is added twice a month, and weekly in January.</p>
<p>Anyway, onto the good part, ML-assisted fuzzing.</p>
<p><em>N.B.</em> If there’s another security-related machine learning article (from behind a journal paywall, for example) you’re interested in and want me to discuss in detail (rather than this very brief overview), reply below or hit me up on <a href="https://twitter.com/krisbolton" rel="noopener nofollow ugc">twitter</a> (via DM). I’m also on the 0x00Sec discord (Kris). I added a quick list of academic databases to the bottom of the page.</p>
<h2>How NEUZZ Works</h2>
<p>NEUZZ was created using TensorFlow &amp; Keras, two open source machine learning libraries security kiwi will cover shortly. Most fuzzers use evolutionary algorithms behind the scenes which aim to increase the coverage of the inputs they test, in a bid to find as many vulnerabilities as possible. The authors of NEUZZ note the main limitation of evolutionary algorithms is their inability to model the structure of the optimization problem (increasing coverage is an optimization problem). Gradient descent, the mathematical concept underlying many neural network implementations doesn’t suffer from this limitation (don’t worry we won’t be diving into any math). The researchers set out to create a prototype and test the hypothesis that neural networks can be used to improve fuzzer performance.</p>
<p>As we can’t cover the foundations of machine learning in a paragraph or two, we will be over-simplifying and glossing over some of the internal workings discussed in the research article. NEUZZ takes initial seed inputs and generates new inputs iteratively, using the technique we mentioned earlier, gradient descent.</p>
<h2>What is Gradient Descent?</h2>
<p>Gradient descent is a process used to find the lowest error rate by updating model parameters and following the direction of the slope until it reaches a valley; the valley represents a low error rate and thus high accuracy. Slopes? Valleys? Complex math is often made more digestible by visualizing the problem. This type of thinking can be strange to begin with, stay with me as I explain.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/3X/d/7/d7ffd0fc9e59af6b20cb469b598f257fd670f0b4.jpeg" alt="" data-base62-sha1="uOOJTawYoQCjyDPZ6Vuv1qUszJy" width="383" height="437"></p>
<p>Figure 1 shows gradient descent, the algorithm follows the slope of the curve until it finds the low point. Each point on the graph is after a change to internal model parameters, slowly the algorithm learns to increase accuracy (and reduce error/loss). However, you can plot in more dimensions, and this can dramatically shift your understanding of how machine learning actually works.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/3X/2/5/25c8abd0aa444d5cd46dd2554ed8f437952afca9.jpeg" alt="" data-base62-sha1="5ofBlvhbxoq2BNnVxbB40D0L3gl" width="458" height="373"></p>
<p>Figure 2 shows a 3D representation of the problem space the algorithm has to optimize. The blue dot is the representation of parameters and their change through time (the black line) as the algorithm is exposed to new data and the loss is optimized (reduced as much as possible). Projected below the 3D representation in figure 2 is another type of representation you may come across; topographic, the same as you may be familiar with from a geographic map showing the height of the terrain. Figure 2 shows the same concept as Figure 1, one is 2D and the other 3D.</p>
<p>An analogy may illuminate these figures further. Gradient descent can be seen as a blind-folded mountaineer attempting to find their way down a mountain only by feeling the gradient of the terrain. The security kiwi page on optimization algorithms, and gradient descent in particular, will be added on February 4th.</p>
<h2>Back to NEUZZ</h2>
<p>Using the process of gradient descent NEUZZ identifies the input bytes with the highest gradient values, these indicate a higher level of importance to the neural network and have a higher chance of causing a major change to the program’s behaviour. The neural network (a three-layered network) models the target program’s behaviour. The neural network is incrementally refined using observed behaviours during fuzzing (i.e. new training data is generated and learned from). When major changes in behaviour are detected, traces are recorded for manual analysis.</p>
<p><em>The security kiwi page discussing neural networks will be added on January 21st, and the whole Training Models chapter will be added shortly after.</em></p>
<h2>NEUZZ Results</h2>
<p>TDLR; 31 vulnerabilities not discovered by 10 other fuzzers including two CVEs (CVE-2018-19931 and CVE-2018-19932).</p>
<p>She et al, break down their evaluation into answering research questions they created at the start to guide their work.</p>
<ol>
<li>Can NEUZZ find more bugs than existing fuzzers?</li>
</ol>
<p>NEUZZ finds the following bugs in 6 programs; out-of-memory, memory leak, assertion crash, integer overflow and heap overflow. While other fuzzers tested find up to 3 or 2 of these bug types. See the image below for detail.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2.png" data-download-href="/uploads/short-url/3IL4FTiBxLHZGhZm93LObh9MymS.png?dl=1" title="Screenshot 2021-01-07 at 19.20.02" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2_2_499x375.png" alt="Screenshot 2021-01-07 at 19.20.02" data-base62-sha1="3IL4FTiBxLHZGhZm93LObh9MymS" width="499" height="375" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2_2_499x375.png, https://0x00sec.s3.amazonaws.com/optimized/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2_2_748x562.png 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/1/a/1a15c7692f22ffe6945564f995a2781c9bade3c2_2_10x10.png"></a></div><p></p>
<ol start="2">
<li>Can NEUZZ achieve higher coverage than existing fuzzers?</li>
</ol>
<p>She et al ran each fuzzer against 10 different programs for 24 hours and recorded the edge coverage of each. This describes how much of the program was tested to find vulnerabilities. The image below shows this comparison after 24 hours.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690.png" data-download-href="/uploads/short-url/4MhfiAP5ziP0MyL9BbTDalfVlMk.png?dl=1" title="Screenshot 2021-01-07 at 19.20.15" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690_2_517x219.png" alt="Screenshot 2021-01-07 at 19.20.15" data-base62-sha1="4MhfiAP5ziP0MyL9BbTDalfVlMk" width="517" height="219" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690_2_517x219.png, https://0x00sec.s3.amazonaws.com/optimized/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690_2_775x328.png 1.5x, https://0x00sec.s3.amazonaws.com/optimized/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690_2_1034x438.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/2/1/217dc89dea39033889ae1b37669cb3c057583690_2_10x10.png"></a></div><p></p>
<p>The following image shows edge coverage over time. Consider NEUZZ’s speed and coverage rate versus the other fuzzers tested. The reason for its vastly superior speed and coverage is what we discussed before. The use of gradient descent and complementary neural network techniques to solve the limitation of solving it as an optimization problem.</p>
<p>Thanks for reading. I hope this was interesting.</p>
<p>As I mentioned, if you have any machine learning research papers you would like me to cover in detail, or project ideas for security kiwi please get in touch (<a href="https://security.kiwi/contact" rel="noopener nofollow ugc">email</a>, <a href="https://twitter.com/krisbolton" rel="noopener nofollow ugc">twitter</a>, discord) or reply below. Don’t expect a quick turn-around, a proper write-up and research takes time. Additionally, if you have any questions I’m happy to answer them.</p>
<p>Academic databases:</p>
<ul>
<li><a href="https://ieeexplore.ieee.org/Xplore/home.jsp" rel="noopener nofollow ugc">IEEE Xplore</a></li>
<li><a href="https://dl.acm.org/" rel="noopener nofollow ugc">ACM Digital Library</a></li>
<li><a href="https://www.sciencedirect.com/" rel="noopener nofollow ugc">Science Direct</a></li>
<li><a href="https://arxiv.org/" rel="noopener nofollow ugc">Arxiv</a></li>
</ul>
<h2>References</h2>
<p>Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray, and Suman Jana. <em>NEUZZ: Efficient Fuzzing with Neural Program Smoothing.</em> <a href="https://arxiv.org/abs/1807.05620" rel="noopener nofollow ugc">https://arxiv.org/abs/1807.05620</a></p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/machine-learning-assisted-fuzzer-finds-31-new-vulnerabilities/24499">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/machine-learning-assisted-fuzzer-finds-31-new-vulnerabilities/24499</link>
          <pubDate>Thu, 07 Jan 2021 19:37:47 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-24499</guid>
          <source url="https://0x00sec.org/t/machine-learning-assisted-fuzzer-finds-31-new-vulnerabilities/24499.rss">Machine learning-assisted Fuzzer finds 31 new vulnerabilities</source>
        </item>
        <item>
          <title>Machine Learning for Security</title>
          <dc:creator><![CDATA[kris]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>Hi all, I’ve been building a machine learning course focused on security called Security Kiwi (<a href="https://security.kiwi" rel="noopener nofollow ugc">https://security.kiwi</a>) for a few months and it’s almost ready.  The course material is based on my learning and tinkering during a BSc and MSc. However, you don’t need a degree to understand ML. The course is designed for anyone who is interested - you don’t need to be “good at math” or an excellent programmer to learn. The main language is Python, if you’re a bit rusty or new there will be a short Python refresher.</p>
<p>I’ve bought interesting insights from the world of academic research which is usually behind journal paywalls. Eventually, once we have learned the foundations of ML we’ll discuss research and create interesting projects, some based on research. Active projects ideas include: email malware collection systems, facial recognition for OSINT and cyber attack prediction. Potential areas of discussion &amp; projects include: threat detection (insider, external), malware detection, threat prediction, threat projection (e.g. determining what stage of an attack and threat actor is likely currently at), breach detection and more.</p>
<p>The first part of the course launches on the 7th of January, and new content will be added regularly. I don’t like the idea of putting a hefty financial barrier in front of knowledge, so the majority of the content is freely accessible, with video walkthroughs, downloadable workbooks, Q&amp;A and other materials designed to make learning easier and more successful part of Patreon support tiers.</p>
<hr>
<p>In the meantime, I’ll walk you through a dataset designed for testing machine learning-based intrusion detection systems which we use in the course. We’ll build a few useful tools and gain an understanding of simple dataset manipulation needed when we are first shopping around for a dataset.</p>
<h2>Why do we need a dataset?</h2>
<p>Machine learning isn’t only focused on algorithms and state-of-the-art techniques like convolutional neural networks. We need an understanding of datasets and data science techniques. In our fictional scenario here, we are planning to create an intrusion detection system. We want to scan live network data and decide if the traffic is potentially malicious.</p>
<h2>Gaining a Simple Overview of a Dataset</h2>
<p>Once we have our idea (creating an intrusion detection system), we want to look for datasets which suit our needs. First, we want to stop and consider our requirements, so we can understand what we need to actually do with our dataset. That process is a little dry for the first introduction to machine learning for some, so you can read about that on Security Kiwi on January 7th. We’ll focus on practical skills using the Python libraries Pandas and matplotlib to gain an overview of what’s inside a dataset.</p>
<p>You can follow along with the code in a <a href="https://colab.research.google.com/drive/13rMDvYJnpMY52hSaLItdP1j_521mmxKT?usp=sharing" rel="noopener nofollow ugc">Google live code environment</a> (Google Colab).</p>
<p>We’ll be looking at the first 5,000 rows of the URG’16 dataset created by Maciá-Fernández et al. We can’t look at the whole thing, as it’s 52GB of data. UGR16 contains real and synthetic  <em>netflow</em>  v9 data captured from sensors within a tier-3 ISP over four months. Typically, datasets only cover days or weeks. The ISP is a cloud service provider, providing virtualized services such as WordPress, Joomla, email, FTP etc. Victim machines were colocated alongside real clients and attacker machines placed outside the network. Synthetic attacks are generated at fixed and random times, allowing anomaly detectors to be assessed. Real botnet traffic captured from the malware  <em>Neris</em>  was inserted into the network data during capture.</p>
<h3>Get the Data</h3>
<p>Below we download a file containing the first 5,000 rows of the URG’16 dataset I created. In the course we will setup and use <a href="https://jupyter.org/" rel="noopener nofollow ugc">Jupyter Notebooks</a>, however, here we work solely with Google Colab.</p>
<pre><code class="lang-python">import requests

DOWNLOAD_REPO = "https://raw.githubusercontent.com/krisbolton/machine-learning-for-security/master/"
DOWNLOAD_FILENAME = DOWNLOAD_REPO + "ugr16-july-week5-first5k.csv"
DATASET_FILENAME = "ugr16-july-week5-first5k.csv"

response = requests.get(DOWNLOAD_FILENAME)
response.raise_for_status()
with open(DATASET_FILENAME, "wb") as f:
    f.write(response.content)
print("Download complete.")
</code></pre>
<p><code>DOWNLOAD_REPO</code>  is the URL a repository containing datasets,  <code>DOWNLOAD_FILENAME</code>  is the name of the file we want to download contained in that repository, these are combined in line 2.  <code>DATASET_FILENAME</code>  allows you to get the filename when it is created locally. We then use the  <code>requests</code>  library to fetch the dataset, check for errors ( <code>.raise_for_status()</code> ), create a  <em>file object</em>  using  <code>open()</code> , create a  <em>file writer</em>   <code>write()</code>  using the content of the request, and finally print a message so we know when it’s done.</p>
<h2>Explore the Data</h2>
<h3>Data Overview</h3>
<p>Initially, we want to know what type of data is contained within the dataset, how many rows we have and other simple data points such as this. Below we use the Python library Pandas to read the CSV file, convert it into a pandas <em>dataframe</em> and print information about the dataframe.</p>
<p>If you’re unfamiliar a dataframe is a <a href="https://en.wikipedia.org/wiki/Data_structure" rel="noopener nofollow ugc">data structure</a> with rows and columns, similar to a table, which makes working with data much easier.</p>
<pre><code class="lang-auto">import pandas as pd
df = pd.read_csv("ugr16-july-week5-first5k.csv")
df.info()
</code></pre>
<p>We  <code>import</code>  pandas as the variable  <code>pd</code>  (a convention), read the contents of the CSV file into the variable  <code>df</code>  (stands for dataframe (another convention)) and we use the  <code>info()</code>  method on df which provides a basic summary of the dataframe.</p>
<p>The output of <code>info()</code>:</p>
<pre><code class="lang-nohighlight">&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 4999 entries, 0 to 4998
Data columns (total 13 columns):
2016-07-27 13:43:21    4999 non-null object
48.380                 4999 non-null float64
187.96.221.207         4999 non-null object
42.219.153.7           4999 non-null object
53                     4999 non-null int64
53.1                   4999 non-null int64
UDP                    4999 non-null object
.A....                 4999 non-null object
0                      4999 non-null int64
0.1                    4999 non-null int64
2                      4999 non-null int64
209                    4999 non-null int64
background             4999 non-null object
dtypes: float64(1), int64(6), object(6)
memory usage: 507.8+ KB
</code></pre>
<p><code>info()</code>  shows us information about each column in the dataset as rows in this output. General information is provided, number of entries (remember most data structures count from 0, 0 to 4,999 means there are 5,000 entries), 13 columns, memory usage and information about those 13 columns. The first column in  <code>info()</code>  is the heading of the dataset columns (in this case the dataset creators didn’t use headings), the second is the number of instances of a record, third the type of entry (in this can it cannot be null) and then the data type.</p>
<h3>Visual Overview of Numerical Data</h3>
<p>Below we visualise the different numerical data within the dataset using  <em>matplotlib</em>  and its  <em>histogram</em>  feature. This can be useful to gain an understanding at-a-glance of the distribution or shape of numerical data within a dataset. Here we don’t gain much insight.</p>
<pre><code class="lang-python">import matplotlib.pyplot as plt
df.hist(bins=50, figsize=(30,15))
plt.show()
</code></pre>
<p>The output:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd.png" data-download-href="/uploads/short-url/qk9ror2YzCTeEvZvU7KXLMtjqfX.png?dl=1" title="" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd_2_690x349.png" alt="" data-base62-sha1="qk9ror2YzCTeEvZvU7KXLMtjqfX" width="690" height="349" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd_2_690x349.png, https://0x00sec.s3.amazonaws.com/optimized/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd_2_1035x523.png 1.5x, https://0x00sec.s3.amazonaws.com/optimized/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd_2_1380x698.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/b/8/b87fb228c61156528926d427acfa694d62959cbd_2_10x10.png"></a></div><p></p>
<h2>View the Raw Data</h2>
<p>Lets actually view some of the data using the Pandas dataframe we made earlier.</p>
<pre><code class="lang-python">df.head()
</code></pre>
<p>The  <code>head()</code>  function prints the first  <em>n</em>  rows from a dataset, the default is 5, however, you can pass values within the parentheses (e.g.  <code>head(50)</code>  for the first 50). The  <code>tail()</code>  function shows entires from the end of a dataset. Viewing snippets like this allows us to see the actual values within our dataset without viewing the whole thing - with datasets in the order of gigabytes, opening such large files can be a task in itself.</p>
<p>The output:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a.png" data-download-href="/uploads/short-url/hKqTaWQJoIr21C2aJmBE4WotRhM.png?dl=1" title="" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a_2_690x154.png" alt="" data-base62-sha1="hKqTaWQJoIr21C2aJmBE4WotRhM" width="690" height="154" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a_2_690x154.png, https://0x00sec.s3.amazonaws.com/optimized/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a_2_1035x231.png 1.5x, https://0x00sec.s3.amazonaws.com/optimized/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a_2_1380x308.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/7/c/7c64ab6a7bc7f30798c89a62d21e36c61df6827a_2_10x10.png"></a></div><p></p>
<p>You’ll notice the column headings aren’t particularly helpful, especially without reading the paper which launched the dataset and finding the methodology for how the researchers captured this data. The researchers used NFDUMP to create netflow v9 data capture, so we can look up that format and infer each column data. Then we can use a pandas dataframe function to add the correct headings to each column. This is only for us to understand what we’re looking at, we wouldn’t do this for our algorithm. Machine learning algorithms only work well with numerical data. We discuss this, and how to transform data into various types of numerical data in sections coming January 7th.</p>
<p>Below we add column headings by assigning a List to our dataframe (<code>df</code>):</p>
<pre><code class="lang-auto">df.columns = ['Date time', 'Duration', 'Source IP',
              'Destination IP', 'Source Port', 'Destination IP',
              'Protocol', 'Flag', 'Forwarding status', 'ToS',
              'Packets', 'Bytes', 'Label']
df.head()
</code></pre>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac.png" data-download-href="/uploads/short-url/uBV51iQ0tYqNdMtTy15V8yFW86o.png?dl=1" title="" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac_2_690x173.png" alt="" data-base62-sha1="uBV51iQ0tYqNdMtTy15V8yFW86o" width="690" height="173" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac_2_690x173.png, https://0x00sec.s3.amazonaws.com/optimized/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac_2_1035x259.png 1.5x, https://0x00sec.s3.amazonaws.com/optimized/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac_2_1380x346.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/3X/d/6/d68a94015e5ba29210d9956b3c63da4c4e413cac_2_10x10.png"></a></div><p></p>
<p>Much better, we can understand what we’re looking at now.</p>
<h2>Understanding the Data</h2>
<p>So what have we just looked at and how can it be used? This dataset contains labelled data, you may have noticed the Label column stating whether the traffic is background traffic or attack traffic. Labelled data has a known state, which you can use to train machine learning algorithms the different between normal background traffic and malicious traffic. Patterns in the timing or size of payloads, for example, may be determined to be indications of an attack by a machine learning algorithm. This is referred to as Supervised Machine Learning, where the algorithm is supervised by showing it how something should be with labels. There are other types of machine learning, including Unsupervised which works on unstructured and unlabelled data to derive insight.</p>
<p>We will go through these in more detail and in order to ease you into machine learning and on to intermediate and advanced topics, as well as interesting and useful projects.</p>
<h2>Final Thoughts</h2>
<p>I hope this little tutorial sparked an interest in machine learning and how it can be used for cyber security purposes. Check out the references below for more information on some of the things we discussed. You can use the contact form on <a href="https://security.kiwi" rel="noopener nofollow ugc">https://security.kiwi</a> to get in touch.</p>
<hr>
<h2>References</h2>
<ol>
<li>Maciá-Fernández, G., Camacho, J., Magán-Carrión, R., García-Teodoro, P., and Therón, R. (2018)  <em>UGR‘16: A new dataset for the evaluation of cyclostationarity-based network IDSs</em>. Elsevier. <a href="https://www.sciencedirect.com/science/article/pii/S0167404817302353" rel="noopener nofollow ugc">https://www.sciencedirect.com/science/article/pii/S0167404817302353</a>
</li>
<li>University of Granada (2016)  <em>UGR’16: A New Dataset for the Evaluation of Cyclostationarity-Based Network IDSs.</em>  <a href="https://nesg.ugr.es/nesg-ugr16/" rel="noopener nofollow ugc">https://nesg.ugr.es/nesg-ugr16/</a>
</li>
<li>Pandas (2020a). <em>Pandas - Python Data Analysis Library</em>. <a href="https://pandas.pydata.org" rel="noopener nofollow ugc">https://pandas.pydata.org</a>
</li>
<li>matplotlib (2020). <em>Matplotlib: Python plotting</em> <a href="https://matplotlib.org" rel="noopener nofollow ugc">https://matplotlib.org</a>
</li>
<li>Pandas (2020b). <em>pandas.DataFrame</em>. Pandas Documentation. <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html" rel="noopener nofollow ugc">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html</a>
</li>
<li>NFDUMP (2014) NFDUMP Overview. <a href="http://nfdump.sourceforge.net/" rel="noopener nofollow ugc">http://nfdump.sourceforge.net</a>
</li>
<li>McKinney, W. (2017)  <em>Python for Data Analysis</em> . O’Reilly Media. <a href="https://www.amazon.com/Python-Data-Analysis-Wes-Mckinney/dp/1491957662?tag=0x00sec03-20" rel="noopener nofollow ugc">https://www.amazon.com/Python-Data-Analysis-Wes-Mckinney/dp/1491957662</a>
</li>
</ol>
            <p><small>2 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/machine-learning-for-security/24321">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/machine-learning-for-security/24321</link>
          <pubDate>Tue, 22 Dec 2020 16:13:56 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-24321</guid>
          <source url="https://0x00sec.org/t/machine-learning-for-security/24321.rss">Machine Learning for Security</source>
        </item>
        <item>
          <title>Any Idea on relating web technologies with Evolutionary Algorithm(Optimization)?</title>
          <dc:creator><![CDATA[qeifar]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>I am on my way to seek for something to do for research on it. So, I am planning on relating web technologies and optimization techniques. So, any ideas/ title for the research ?</p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/any-idea-on-relating-web-technologies-with-evolutionary-algorithm-optimization/2471">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/any-idea-on-relating-web-technologies-with-evolutionary-algorithm-optimization/2471</link>
          <pubDate>Mon, 19 Jun 2017 15:04:52 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2471</guid>
          <source url="https://0x00sec.org/t/any-idea-on-relating-web-technologies-with-evolutionary-algorithm-optimization/2471.rss">Any Idea on relating web technologies with Evolutionary Algorithm(Optimization)?</source>
        </item>
        <item>
          <title>About the Artificial Intelligence category</title>
          <dc:creator><![CDATA[pry0cc]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>(Replace this first paragraph with a brief description of your new category. This guidance will appear in the category selection area, so try to keep it below 200 characters. <strong>Until you edit this description or create topics, this category won’t appear on the categories page.</strong>)</p>
<p>Use the following paragraphs for a longer description, or to establish category guidelines or rules:</p>
<ul>
<li>
<p>Why should people use this category? What is it for?</p>
</li>
<li>
<p>How exactly is this different than the other categories we already have?</p>
</li>
<li>
<p>What should topics in this category generally contain?</p>
</li>
<li>
<p>Do we need this category? Can we merge with another category, or subcategory?</p>
</li>
</ul>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/about-the-artificial-intelligence-category/1020">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/about-the-artificial-intelligence-category/1020</link>
          <pubDate>Wed, 31 Aug 2016 17:05:22 +0000</pubDate>
          <discourse:topicPinned>Yes</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1020</guid>
          <source url="https://0x00sec.org/t/about-the-artificial-intelligence-category/1020.rss">About the Artificial Intelligence category</source>
        </item>
        <item>
          <title>YouTube Series on Neural Nets</title>
          <dc:creator><![CDATA[oaktree]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>I have gotten through about half of <a href="https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU" rel="nofollow noopener">this</a>. I recommend it for anyone interested in AI.</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/youtube-series-on-neural-nets/673">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/youtube-series-on-neural-nets/673</link>
          <pubDate>Wed, 29 Jun 2016 21:16:37 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-673</guid>
          <source url="https://0x00sec.org/t/youtube-series-on-neural-nets/673.rss">YouTube Series on Neural Nets</source>
        </item>
        <item>
          <title>Adventuring into Neural Networks Part 1 (Part 2 really)</title>
          <dc:creator><![CDATA[random-man]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>Hello! I apologize for not posting part 1 sooner. I know I paraded on about free time in the comment section,<br>
but unfortunately some personal events prevented me from posting earlier. Also, this is gonna be<br>
approached differently than I said it was in part 0. I feel this would be more productive than going<br>
on immediately with the other problem. Anyways, enjoy!</p>
<p>A good way to think about these systems is thinking of them as circuits, whose values are real<br>
numbers, not boolean. So, this network would be like a logic gate using functions like OR, AND,<br>
etc., however it instead uses functions that operate on the real line. Why do I bring<br>
this up? Well, I saw this represented this way elsewhere, and I thought it was a well suited way<br>
to think of these systems. So, there are multiple kinds of neural networks, such as feed-forward,<br>
back propagated, etc. So as we remember, a perceptron is a model of a single neuron, with some number<br>
of inputs with their weights. Then ofcourse, the sums of the products of the weights and inputs are<br>
normalized with the activation function, typically the sigmoidal function, the inverse of the sum<br>
of one and e raised to the negated input ( 1/(1+e^-x) ).</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/dd4e179d389c9ff652c340e2288bcefea04fd5cf.png" width="400" height="315"></p>
<p>Also, one thing we must know with the sigmoidal activation function is that a return value like 0.999<br>
may as well be considered 1, since the function only asymptotically approaches 1. Large positive<br>
values are brought down near 1 and large negative values are brought down to 0. But we use the Sigmoidal<br>
function becuase it is continuous in its domain, so we can perform calculus on it. There are other<br>
functions used to normalize, or activation functions, out there that are used, such as the step functions.<br>
Let’s look at a quick perceptron to solve OR.</p>
<p><a href="http://pastebin.com/u7nyrufC" class="onebox" target="_blank" rel="noopener nofollow ugc">http://pastebin.com/u7nyrufC</a><br>
Here, we have a simple single neuron network to do the OR function. Notice that False values are given out by the sigmoidal function as 0.5, while True values are larger than that. Since we know this, we can just make the final program give out an answer of True or False based on the numerical reply. As long as results from the network are consistent, we can interprete them as we see fit. Now, in most applications, neural networks with multiple layers of neurons are used, not just single neurons.</p>
<p>There are multiple styles of training… The kind we are currently focused on, supervised learning, is all about giving the network the expected outcome, along with inputs. Kind of like using flash cards to study, you get the input, you decide on your answer, then you flip the card, telling you how wrong you are. So, let’s use this kind of learning to train an AND neural network. Remember the calculations we talked about before? We’ll be using those. However, we do not always need to use the sigmoidal function as an activation function, keep in mind. For this example, we will actually be using the step function. We’ll be using a step function, which takes any input, and returns either 1 or 0 based on whether or not the input is larger than a certain threshold t. This time, we’ll be using a different weight change calculation, and we’ll be using “learning rates”, which are values affect the size of the values we adjust the weights by, therefore also affecting how fast the neural network learns. Perhaps this method may be more effective than the one we previously went over? Maybe less? Anyways, we’ll be calculating the weight change with learning_rate*(target-output)*input. Let’s train an AND function. For the initial weights, we will generate some randomized real numbers between 0 and 1. So here’s a simple example of training the AND net.</p>
<p><a href="http://pastebin.com/MU8rLh5J" class="onebox" target="_blank" rel="noopener nofollow ugc">http://pastebin.com/MU8rLh5J</a></p>
<p>Works nicely. As you can see, the step function is useful for these kinds of binary functions. Now, when training a neural network for NOR and using the step function, we run into a problem. Notice that for any 2 weights (0)*w1 + (0)*w2 &gt;= 1 is never a true statement. We fix this by adding a bias input. What is a bias input? It is simply an input with a constant value. We will see this more in part 2.</p>
<p>I know this one is a bit short, but I rather put this one out instead of waiting. Like I said, I’ve been a little more busy than expected :P. In future parts, we’re gonna cover other algorithms, like SVMs and whatnot. We’ll go on there. so I hope you come to find this series interesting or enjoyable ;).</p>
            <p><small>6 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/adventuring-into-neural-networks-part-1-part-2-really/536">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/adventuring-into-neural-networks-part-1-part-2-really/536</link>
          <pubDate>Wed, 01 Jun 2016 20:13:44 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-536</guid>
          <source url="https://0x00sec.org/t/adventuring-into-neural-networks-part-1-part-2-really/536.rss">Adventuring into Neural Networks Part 1 (Part 2 really)</source>
        </item>
        <item>
          <title>Adventuring into Neural Nets (Part 1)</title>
          <dc:creator><![CDATA[random-man]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>Hello! Random-man reporting. So this is gonna be a quick write up on some basic neural network stuff, and I’ll probably divide it in 2 parts. First off, let me say that I’m not a professional computer scientist or mathematician. I want to head down that route when I get to the point in life, but for now, I’m just an amateur. Just a disclaimer <img src="/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"> . I’m learning this as I write on it.</p>
<h2>What is a Neural Network?</h2>
<p>A neural network is sort a man-made “emulation” of a real neural network, that is a subset of an actual brain. Now, if you asked ME whether or not a complex neural network would produce a real “intelligence”, that is, a being with true consciousness, I’d probably say no, at least for now. However, they could definitely be used to produce something along the same level as a plant or simple minded animal :D. That’s very useful.</p>
<p>So as we all know in life, not ALL problems are easy to solve with a computer. At least, the way to programmatically solve them isn’t always obvious. If we have a set of numbers, we know that sorting them is definitely a task for a computer, and there are many ways to do this. Of course this is obvious to all who have read some of <a class="mention" href="https://0x00sec.org/u/oaktree">@oaktree</a>’s great stuff on sorting, and taken a look at Bogo sort, perhaps one of mankinds most beautiful creations. But ask a computer whether or not this is a picture of a dog.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/c83b9db01dffe3f5bc35443bccbace590b8b9d3d.jpg" width="227" height="222"></p>
<p>Is there an obvious solution? Probably not. This is where neural networks come to use in our endeavors. The idea of a neural network is that we setup a system that will take some input. It will most likely produce an arbitrary outcome based on it’s initial conditions. Then the output is judged on a criteria of being our desired outcome. Based on this, the system will shift its conditions based on our feedback. So a classical computational problem may be something like…</p>
<p>Programmer: Hey, if I ask you for the arithmetic mean of a set of numbers, I want you the return the ratio of the sum of    all  the elements to the total cardinality, or number of elements in the set. Got it?<br>
Computer: Yeah seems legit.</p>
<p>But let us now consider a different style of problem.</p>
<p>Programmer: Hey, I have a situtation that you can never truly understand because you are only a computer, but I need you to produce a correct outcome based on such  a situation. Since you can’t “really” understand the situation, I’m gonna give you some input, you can first give me some random output, and I’ll tell you how correct you are based on that. That way, you’ll start to get a feel for what kinds of results come from different kinds of inputs.<br>
Computer: …</p>
<p>So that’s a real simplified set of ideas to digest. Let’s take a look at a bit of theory to understand the structure of a simple neural network setup. With a neural network, we have three fundamental parts. We have the inputs, then we have a “black box” or “hidden layer” in the middle, where the input is processed, and then we have the output. This may as well describe any program though huh? Neural networks are special though.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/e81c5d4b77b5c0556ece0e83d4a7c1cf685c528b.jpeg" width="511" height="350"></p>
<p>Now let’s briefly look at an EXTREMELY simple neural net, one that produces a very basic outcome.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/4c5a6cde2861d9a4c59e1e794b3ff0fa99d0f1bf.png" width="690" height="400"></p>
<p>As you can see, we have three inputs, which are all connected to the one neuron in the middle layer. But notice how each input connection has a “weight” to it. The end outcome, y, is simply the sum of the product of the input values and their weights, well, actually, it’s probably a normalized result from an Activation function, but we’ll get there. Let’s write up a quick function for the simplest kind of neural network. One dubbed the “perceptron”. Let’s take a quick look first.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/0b17bc8db5a8d4496ae6c92ef435c658e56813e6.png" width="690" height="110"></p>
<p>So, let’s take this progressively. The inputs are gonna be real numbers. Each is muliplied by it’s weight, then they are summed for the final outcome in the end layer. So, we can describe any outcome for a given set with this function, expressed in symbolic and code form. Where I stands for input and w is the weight for that input.</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/f60151d15ba1ece227abb036e6db45ee316e375c.gif" width="59" height="54"></p>
<pre><code class="lang-auto">def perceptron(_in1, _in2, _w1, _w2):
    return _in1*_w1+_in2*_w2
</code></pre>
<p>Now, let’s briefly generalize this situation and simplify for N inputs :).</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/c2f3a794f4b9513d75447e43ff9bc2be61a0edcd.gif" width="59" height="54"></p>
<pre><code class="lang-auto">def gen_perceptron(_in,_w):
    ret = 0
    for i in range(len(_in)):
        ret = ret + _in[i]*_w[i]
    return ret/abs(ret)
</code></pre>
<p>That way, we get either +/-1 as an answer. Now, taking this last binary value is called our “Activation function”. In this case, we have simplified it. In many other applications, though, the<br>
activation function takes other forms. In this article, we are gonna do something a little different and talk about the sigmoid activation function…</p>
<p>Now, since we are just starting out in neural networks, we are not gonna tackle a true A.I. problem yet, for now, let’s tackle something simple and logical. We will use the techniques of neural networks, though. Now, since we have a basic understanding of some of these concepts, let’s try and build a neural network and train it for a simple problem I will describe soon. This is definitely not a problem that needs a neural net to solve, but let’s tackle it to practice our skills and get a better understanding of things <img src="/images/emoji/twitter/smiley.png?v=9" title=":smiley:" class="emoji" alt=":smiley:">.  Sometimes, instead of trying to understand the theory and dwelve deeply, we may first want to take what we know, roll with it, and DO something with it. In future articles, I’ll definitely go into more thorough and detailed explanations of things. For now, we may just want to get used to some of the ideas of a neural network, and practice a little application of one, just to get our feet a little wet.</p>
<p>Now, in trying to make a neural network for our problem, we shall look at a new Activation function. That is, a sigmoid function. It takes the mathematical form of…</p>
<h2>
<img src="//0x00sec.s3.amazonaws.com/original/1X/cbba084a1b15112a459e7f9c9678b6ce22ddfc7a.png" width="485" height="323"><br><br>
Why would we use a function like this? Well, I couldn’t tell you all of the reasons as I’m still learning this too, but I can tell you that sigmoid functions are great for squashing values. This function will take any x as input as toss it somewhere between 0 and 1. If you are unfamiliar with the “e”, that is Eulers number. It is a very special number, like pi, and trying to explain the significance of it here will bring us to quite a tangent. e is a transcendental number, it could never be a solution of a polynomial with rational coefficients, and it is widely known as a common exponential and logarithmic base. If you are not familiar with all of the mathematical terms, don’t worry, we will look at them as we encounter them more in the future. To solve the problem I will describe briefly, we are going to first train the neural network! We shall first randomly set its initial conditions, then we will give it input, let it guess, then give it output on whether or not it was correct. Based on this, it will adjust its weights to better optimize for the situation! This is gonna be an example of what is called “Back Propagation”. Now, let’s look at a goal or problem… We want to train the neural net to emulate the following truth table logic…</h2>
<h2>Input    Input    Input    Output<br>
0        0        1        0<br>
1        1        1        1<br>
1        0        1        1<br>
0        1        1        0</h2>
<p>What’s the secret sauce? It just takes the value in the left most column. So, we know we’re gonna need 3 inputs. They are gonna be weighted as well. Our gameplan is to take these three inputs, multiply each by their weights, pass the sum of those through the sigmoid function, evaluate the error, and adjust the weighted values. Now notice that since all our input values are either zero or one, the results that are being passed to the sigmoid are really just gonna be the sums of a subset of the weights. Let’s take a look at some of the mathematical operations we will partake in with respect to this particular problem.</p>
<ol>
<li>To get the value we will push through the sigmoid function:</li>
</ol>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/ee9f0f8508dd5754e4d2478f6b8bc15b19b9e36a.gif" width="59" height="54">   </p>
<p>Simple enough, we take the sum of the products of the weights and inputs.</p>
<ol start="2">
<li>Sigmoid function to “normalize” the outputs of neuron:<br>
(note- what I mean by normalization is that we are bringing the outputs to be between 0 and 1)</li>
</ol>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/022e42dc2503f707e5c71de6cbb71b60f35ebbc9.gif" width="58" height="38"></p>
<p>For the next formula, I’m just gonna refer to the Sigmoid function as S(x) for simplicity <img src="/images/emoji/twitter/stuck_out_tongue.png?v=9" title=":stuck_out_tongue:" class="emoji" alt=":stuck_out_tongue:"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/1X/ed7d5c0c5b8c66f643af6272ff28c0ebfc75948a.gif" width="61" height="18"></p>
<p>Now, the S’(O) is the derivative of the sigmoid function taking the neural network output as an input. I will not go into the Calculus of the derivative, but I will briefly try to give an intution incase you are not familiar with the concept of a derivative. Consider a linear function, that is a line, like y = mx + b. Notice that the slope of the line remains the same at any point along the line. However, in a non-linear function, or a curve, the slope changes as we move along the function. So, the derivative is an algebraic formula we can use to find the slope on the curve at that particular part of the curve.</p>
<p>You might be asking, why the hell are we multiplying by that?!!? Well just chill out and put down the bat. I can explain. So take another look at the curve of the sigmoid function. Notice that the closer y-value is to either 0 or 1, the smaller the derivative, or slope at that point is. Makes sense, because if the value is really close to the right answer, which in this case is either 0 or 1, we don’t want to adjust the weight as much. We’re just using some of the mathematical forces of nature and of this function here to our advantage is all. The e-value, in this formula, is not Eulers number! In this formula, it is an error value, the difference between the result and the desired output.</p>
<p>Why multiply by the error value? Because we want to make our change to the weights proportional to the error, or how badly the neural net screwed up on that particular try. Now we also multiply by the Input value, which in this situation, is either a 1 or a 0. Why? I’m gonna be completely honest with you, I am not completely sure why. However, when/if I find that out, I will definitely try to explain it in part 2 of this.</p>
<p>So, the main idea is that we are gonna adjust the weights with a value that is proportional to the error. Which makes sense since we’re trying to optimize this baby little by little…</p>
<p>(note- In part 2, or in a future part, I will attempt to better explain the back propagation algorithm <img src="/images/emoji/twitter/slight_smile.png?v=9" title=":slight_smile:" class="emoji" alt=":slight_smile:"> )</p>
<p>Whats left after this? Well, we gotta write this thing, and train it a bunch of times! I’m gonna wrap this post up so the two parts are in more digestible smaller chunks. I’m gonna start on it tonight, but I don’t know if it will be posted by tomorrow. Hopefully soon. I hope you had a fun or at least an interesting time reading this, and  I am excited to continue on this topic!</p>
<p>(Note: For the first part of this, I didn’t want to be too mathematically rigorous. It was more meant to get you used to some of the aspects of neural networks. For part 2, I plan on discussing how we will actually train this thing. Then, in future parts, I’ll probably start off from the basics again, but with more rigorous explanations. I hope I haven’t made any errors writing this late at night :P, and if I did, please feel free to point them out. Thanks for reading.)</p>
            <p><small>16 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/adventuring-into-neural-nets-part-1/488">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/adventuring-into-neural-nets-part-1/488</link>
          <pubDate>Thu, 26 May 2016 05:32:47 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-488</guid>
          <source url="https://0x00sec.org/t/adventuring-into-neural-nets-part-1/488.rss">Adventuring into Neural Nets (Part 1)</source>
        </item>
        <item>
          <title>InfoSec and Artificial Intelligence</title>
          <dc:creator><![CDATA[cr1ms0n1r1s]]></dc:creator>
          <category>Artificial Intelligence</category>
          <description><![CDATA[
            <p>hello 0x00sec members!! This is my first post so i will do my best not to make it too complicated.<br>
First i want to clarify that I’m no expert in either AI or InfoSec so if i give any false information please let me know.</p>
<p>In this post i will give a brief introduction to both Artificial Intelligence and InfoSec fields and then show some uses of AI in InfoSec.</p>
<p><strong>Artificial Intelligence:</strong><br>
Artificial Intelligence is the field of computer science with creates algorithms that make machines exhibit intelligence.</p>
<p><strong>Information Security:</strong><br>
Information security is the practice of keeping information either in electronic or physica form safe from any unauthorized access.</p>
<p>You might be wondering, well how do i combine AI with InfoSec?</p>
<ul>
<li>intelligent algorithms can be used to identify and automatically response to cyber threats.</li>
<li>AI-based algorithms could provide instant feedback of any malicious activity within a network.</li>
<li>intelligent systems can predict cyber attack and automatically defend the network</li>
</ul>
<p>Those are just some uses I thought if you have any other ideas please let me know. The field of InfoSec could benefit a lot from Artificial Intelligence as long as we make sure we don’t create a real-life Skynet. Thank you all for reading this post I’ll do my best to improve next time.</p>
            <p><small>6 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/infosec-and-artificial-intelligence/427">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/infosec-and-artificial-intelligence/427</link>
          <pubDate>Fri, 20 May 2016 19:34:49 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-427</guid>
          <source url="https://0x00sec.org/t/infosec-and-artificial-intelligence/427.rss">InfoSec and Artificial Intelligence</source>
        </item>
  </channel>
</rss>
