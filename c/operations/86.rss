<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:discourse="http://www.discourse.org/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Operations - 0x00sec - The Home of the Hacker</title>
    <link>https://0x00sec.org/c/operations/86</link>
    <description>Topics in the &#39;Operations&#39; category Category for Topics about Operations.</description>
    
      <lastBuildDate>Tue, 10 Oct 2023 13:48:37 +0000</lastBuildDate>
      <atom:link href="https://0x00sec.org/c/operations/86.rss" rel="self" type="application/rss+xml" />
        <item>
          <title>An Investigation of Tracking Hidden Services</title>
          <dc:creator><![CDATA[0xf00I]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>In this article, I will take you through my thought process while conducting an investigation, aiming to identify and collect sources of intelligence. Specifically, we will focus on using OSINT (Open Source Intelligence) sources related to the Deep and Dark Web domain. Our primary goal is to monitor intelligence information from the following sources: ‘markets’ and ‘cyber criminal activities.’ While I will present a case I worked on some time ago, I won’t provide details about the case itself. Instead, I will discuss the tools I used and how to conduct a hunt. As you join me on this journey, I hope you don’t get lost in my thought process.</p>
<h2><a name="case-study-1" class="anchor" href="https://0x00sec.org#case-study-1"></a>Case Study</h2>
<p>Your mission, should you choose to accept it, is to trace and identify the relationship between two onion sites and demonstrate that they are owned by the same entity or individual. Additionally, trace their blockchain fingerprints to a registered cryptocurrency exchange.</p>
<p>Site A - operates as an onion market, facilitating the sale of hacking tools and personal identifying information (PII).<br>
Site B - appears to be a platform offering personal hacking services.</p>
<p>A word of caution : Be cautious not to be deceived by appealing headlines you may come across while conducting a passive search on the Dark Web, This message will self-destruct in 5…4…3…</p>
<p>Tools For Dark Web Onion Sites</p>
<ul>
<li><a href="https://www.torproject.org/" rel="noopener nofollow ugc"><strong>Tor Browser</strong></a></li>
<li><a href="https://www.walletexplorer.com/" rel="noopener nofollow ugc"><strong>Wallet Explorer</strong></a></li>
<li><a href="https://www.blockchain.com/explorer" rel="noopener nofollow ugc"><strong>Blockchain Explorer</strong></a></li>
<li><a href="https://oxt.me/" rel="noopener nofollow ugc"><strong>OXT</strong></a></li>
<li><a href="https://osintframework.com/" rel="noopener nofollow ugc"><strong>OSINT Framework</strong></a></li>
</ul>
<p><strong>Wallet Explorer</strong> is useful as it identifies all Bitcoin addresses owned by a single wallet. When dealing with cryptocurrencies, one wallet may own numerous addresses.</p>
<p>The <strong>Blockchain Explorer</strong> is like an interactive map of the blockchain, while <strong>OXT</strong> analyzes the blockchain to extract high-level information. You browse these high-level information instead of a direct representation of the data stored in the blockchain.</p>
<h2><a name="fingerprints-2" class="anchor" href="https://0x00sec.org#fingerprints-2"></a>Fingerprints</h2>
<p>So, how do we link the relationship between two dark web onion sites? The Dark Web is an uncharted, chaotic conglomerate of sites. At times, .onion sites often go down for prolonged periods of time or entirely disappear.</p>
<p>For instance, in this case, we’re trying to find a link between two different onion sites. The first step is to identify the administrators and popular vendors of such sites. Many vendors operate on various markets with the same details across all sites. Some are also active on discussion forums. Then, we delve into the site’s structure by searching for email addresses, Bitcoin addresses, and identifying technologies. We scan for open ports and hidden paths.</p>
<p>So, let’s begin by creating an intelligence profile. Take note of the following:</p>
<ul>
<li>Username / Alias</li>
<li>Date of account creation / Online, Offline (map out an activity pattern)</li>
<li>PGP public key (Important! Reused keys indicate related accounts)</li>
<li>Type of merchandise offered</li>
<li>Methods of contact</li>
</ul>
<p>Also, writing style, also known as stylometry, plays a role. Certain phrases, slang terms, and colloquialisms are associated with specific geographic locations and rarely occur elsewhere. Conversely, actors can employ various writing styles or different languages to manipulate research and lead it to incorrect conclusions. One famous case is the ‘Shadow Brokers.’ Writing styles serve as characteristics that aid in fingerprinting, all while concealing true attributes. ‘Broken English’ is effectively performing its task by obstructing search algorithms.</p>
<p>Next, conducting a quick crawl and observation of the sites, I noticed a couple of things. The site B is running on the ‘Apache web server,’ which is fairly standard. However, what gets interesting is that the site operator seems to have forgotten to disable the <a href="http://httpd.apache.org/docs/2.4/mod/mod_status.html" rel="noopener nofollow ugc">Apache status module</a>, also known as mod_status or server-status. This module provides information about the requests Apache is currently serving and has recently served. The information includes:</p>
<ul>
<li>The time the server was last started/restarted and the duration it has been running.</li>
<li>Averages, including the number of requests per second, the number of bytes served per second, and the average number of bytes per request.</li>
<li>Details about the current hosts and requests being processed.</li>
</ul>
<p>Furthermore, there are numerous resemblances between the sites, but we require evidence to confirm that they are actually owned or operated by the same individual or organization. However, further investigation showed profiles of interest, one labeled as Admin and another as a vendor, both engaged in multiple activities like leaking sensitive data and exploiting low hanging fruit, Bunch of skiddie, Like any newcomer trying to build a reputation, they left a trail of footprints behind. So, I decided to temporarily suspend the investigation of the sites and instead focus on gathering more information about these profiles. My goal is to determine whether I can link them to any profiles or accounts on other sites.</p>
<p>Starting with the administration of Site A, it is now time to cross-reference that intelligence profile and search for any useful information. I was able to trace the username across various forums, one of which is xss[.]is. In case you’re unfamiliar, “xss is a Russian forum that hosts discussions on vulnerabilities, exploitation, malware, and various other cyber-related topics.” To thoroughly scope the profile, I initiated a quick crawl to retrieve a link. Upon checking the link, I received no response, indicating that the site is no longer operational. Additionally, the profile associated with it has been inactive since the last recorded activity in 2021. To investigate further, I decided to run the site through <a href="https://web.archive.org/web/" rel="noopener nofollow ugc">WebBackMachine</a> to see if any snapshots are available:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/2/d/2debbf3cc3490e3e4a34e3c94df12c2bf205f93e.png" data-download-href="/uploads/short-url/6yezs7PUujy4rKf7H64jvBarvT8.png?dl=1" title="ddd" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/3X/2/d/2debbf3cc3490e3e4a34e3c94df12c2bf205f93e.png" alt="ddd" data-base62-sha1="6yezs7PUujy4rKf7H64jvBarvT8" width="690" height="154" data-dominant-color="F80101"></a></div><p></p>
<p>The site contains snapshots dating back to approximately 2018, with additional snapshots from 2019, 2020, and 2021. It’s time to conduct a manual inspection of these snapshots. As we delve into the snapshots, we discover a subdomain labeled ‘Subscription’ and ‘Services.’ Interestingly, it turns out that the site was offering hacking services before it went offline.</p>
<p>What’s even more intriguing is that before it transformed into a hacker-for-hire service, it started as a personal blog in the 2018 snapshot. This blog featured articles on hacking, tools, and related topics. As we carefully examine all of this, we managed to collect the following information:</p>
<p>Site A:</p>
<ul>
<li>Bitcoin Address</li>
<li>A real name linked to the administration alias</li>
<li>Country of residence</li>
<li>Email Address</li>
</ul>
<p>Site B:</p>
<ul>
<li>Bitcoin Address</li>
<li>Email Address</li>
</ul>
<p>Now that we’ve managed to collect some valuable information on the administration of Site A and we know that the Admin has an interest in hacking services, we still need evidence that links the site to it. Let’s examine the bitcoin addresses evidence.</p>
<h3><a name="blockchain-forensics-on-transactions-3" class="anchor" href="https://0x00sec.org#blockchain-forensics-on-transactions-3"></a>Blockchain Forensics On Transactions</h3>
<p>From a single Bitcoin address, various insights can be derived, including the total number of transactions, the sources and amounts of incoming funds, the destinations and amounts of outgoing funds, a historical timeline of transactions, and identification of other associated Bitcoin addresses within the same wallet. This is where the website <a href="https://www.walletexplorer.com/" rel="noopener nofollow ugc">Wallet Explorer</a> and <a href="https://oxt.me" rel="noopener nofollow ugc">OTX</a> become relevant and come into play.</p>
<p>Usually, the first approach is to start looking for patterns and correlations to link multiple addresses. We also map the flow of funds and relationships between addresses to uncover suspicious activities or money laundering schemes and extract and analyze additional data associated with transactions, timestamps to gain further insights.</p>
<p>With this tool, we are able to identify any other bitcoin addresses owned by the same wallet.</p>
<p>When we input the address into the explorer, the displayed data includes transaction records, each with specific information like dates and the amounts sent or received. Notably, one of the transactions received funds from an unfamiliar sender (address beginning with “06f”), allowing us to discern the shared ownership of these addresses and subsequently unveil the complete wallet.</p>
<p>With a transaction history dating back to 2019, we now have a time frame that matches our investigation. Let’s proceed to scrutinize the individual transactions associated with each of these Bitcoin addresses.</p>
<p>These two sites are related since their bitcoin addresses come from the same wallet, confirming that the individuals behind them are the same.</p>
<h3><a name="tracing-the-payments-through-to-an-exchange-4" class="anchor" href="https://0x00sec.org#tracing-the-payments-through-to-an-exchange-4"></a>Tracing the payments through to an exchange</h3>
<p><strong>Transaction History</strong> explores how funds have moved in and out of the address, potentially revealing patterns or connections to other addresses.</p>
<p>Most of the transactions paid into these accounts resemble normal transactions when viewed on the blockchain. However, following the transactions, some use more addresses, possibly indicating a bitcoin mixing service. This is normal, as many actors use a mixing service, or cryptocurrency tumbler, to guarantee anonymity by essentially scrambling the addresses and the payments made.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/3X/7/3/738cc3a2bf356c4cd5ce461086913cf5718b254f.png" data-download-href="/uploads/short-url/gucuGPCr2GwcE5nFlb6ft6Zfvz1.png?dl=1" title="wlt" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/3X/7/3/738cc3a2bf356c4cd5ce461086913cf5718b254f_2_690x241.png" alt="wlt" data-base62-sha1="gucuGPCr2GwcE5nFlb6ft6Zfvz1" width="690" height="241" srcset="https://0x00sec.s3.amazonaws.com/optimized/3X/7/3/738cc3a2bf356c4cd5ce461086913cf5718b254f_2_690x241.png, https://0x00sec.s3.amazonaws.com/original/3X/7/3/738cc3a2bf356c4cd5ce461086913cf5718b254f.png 1.5x, https://0x00sec.s3.amazonaws.com/original/3X/7/3/738cc3a2bf356c4cd5ce461086913cf5718b254f.png 2x" data-dominant-color="F0EEF3"></a></div><p></p>
<p>Likely, the bitcoin address is of an exchange, or it may be a well-used bitcoin tumbling service, explaining the large volume of bitcoin addresses it holds in its wallet, allowing it to essentially scramble transactions.</p>
<p>Here, we have successfully conducted research to establish the relationship between the two sites, confirming that they are indeed owned by the same person. Additionally, we have tracked down the market administration. However, it’s important to note that using open-source information on the dark web and the blockchain can only take you so far.</p>
<h1><a name="de-anonymization-5" class="anchor" href="https://0x00sec.org#de-anonymization-5"></a>De-anonymization</h1>
<p>Remember that vendor I mentioned earlier, who also piqued our interest? Well, it turns out that this vendor was promoting malware. According to the announcement, the malware has multiple features, one of them being ransomware. The vendor was offering a beta version for testing before purchase. So, I decided, why not? I’m something of a malware enthusiast myself. During the analysis, I found a web address for a TOR hidden service, which appears to be provided to the victim to pay for the decryption key. Next, let’s de-anonymize and identify the hosts of these infrastructure.</p>
<p>In de-anonymizing the dark web infrastructure, we can enable hosting providers to reduce illegal activity on their networks and enhance tracking, potentially leading to shutting down these operations. This is often performed with ransomware operations. So, how does it work?</p>
<p>The sites are accessible only on The Onion Router (TOR) network. One approach involves identifying self-signed TLS certificates and specific icons, known as favicons, associated with the site.</p>
<h2><a name="tools-6" class="anchor" href="https://0x00sec.org#tools-6"></a>Tools</h2>
<ul>
<li><a href="https://www.shodan.io" rel="noopener nofollow ugc">Shodan</a></li>
<li><a href="https://www.nslookup.io/" rel="noopener nofollow ugc">Nslookup</a></li>
<li><a href="https://search.censys.io/" rel="noopener nofollow ugc">Censys</a></li>
</ul>
<h3><a name="tls-certificate-matching-7" class="anchor" href="https://0x00sec.org#tls-certificate-matching-7"></a>TLS certificate matching</h3>
<p>An SSL/TLS certificate contains identifying information, such as a unique serial number and cryptographic key information, which is traceable if reused on other web properties. A key principle of operating on the dark web is to maintain anonymity, so certificates providing identity attestation can actually help pinpoint the operator behind a website.</p>
<p>Web crawlers, such as Shodan, provide a powerful method for indexing the public internet. They provide a myriad of information about host computers that are running internet-enabled services. One of the services Shodan provides is cataloging TLS certificate information. By leveraging Shodan’s index, A simple whois check shows that this host belongs to M247 LTD Singapore. When visiting the site, we face a blank screen; however, we can verify that the TLS certificate serial number is the same as that used for the site hosted on TOR hidden services, which we can attribute to a specific hosting provider. Four domains have been listed as A records in Domain Name System (DNS) records with the IP address since 2021.</p>
<p>These domains were registered using a privacy domain registration proxy service by the malware operator. However, tracing the favicon file in the web root directory as ‘favicon.ico,’ we can obtain this file and calculate a hash value for it. Unfortunately, Shodan doesn’t keep an index of these favicon file hashes.</p>
<p>So I moved on and decided to follow the TOR hidden service link we found earlier. I noticed that the link contains an identifier that is presumably unique to each victim, something like this:</p>
<pre><code class="lang-auto">https://{url}/id=aaaaa
</code></pre>
<p>Enum the URL Endpoints, we see that the link contains several HTTP parameters. So, I thought, directory traversal? And just like that, bingo. I’ll leave the rest for you to guess.</p>
<p>In conclusion, I hope you’ve picked up a few tricks from this little spiel. This post was meant to give you a sneak peek into how a hunt goes down and to drop some knowledge on the OSINT tools we like to play with. But, you know, life in the digital shadows ain’t always this straightforward. It’s all about patiently waiting for the other guys to slip up, or sometimes, they just hand us the info on a silver platter. It’s mind-boggling how many vendors out there keep making the same boneheaded OPSEC blunders, I tried to keep it vague, of course, can’t spill the beans on the real deal. Gotta keep those cases cookin’ in the shadows.</p>
            <p><small>3 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/an-investigation-of-tracking-hidden-services/37328">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/an-investigation-of-tracking-hidden-services/37328</link>
          <pubDate>Tue, 10 Oct 2023 13:48:37 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-37328</guid>
          <source url="https://0x00sec.org/t/an-investigation-of-tracking-hidden-services/37328.rss">An Investigation of Tracking Hidden Services</source>
        </item>
        <item>
          <title>Data Lifetime (64 61 74 61)</title>
          <dc:creator><![CDATA[blankdash]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Data Lifetime is a system problem</p>
<p>Any piece of software we build has a possibility of being vulnerable to either<br>
a known flaw or a zero day vulnerability. Using such malicious parties will continue to gain access to the machine. Although it’s highly impossible to become immune to such attacks, we could build systems putting our best effort to minimize the impact of such critical compromises.</p>
<p>Reducing the risk of sensitive data exposure is an essential part of this process.how do we do that, you might ask. To be frank most of the compromises that happen are related to common sense.</p>
<p>~ Encryption Keys</p>
<p>~ Passwords / Multi-Factor Authentication</p>
<p>~ Financial Documents</p>
<p>~ Medical Information</p>
<p>In a system at any point of execution, such sensitive data could be leaked. The duration of time given for the sensitive data remains in a system and its propagation through the system as Data Lifetime. A Data Lifetime and the risk of exposure is directly proportional. If a piece of data is stored in a device for a relatively long period of time the risk of that being exposed increases along with the time.</p>
<p>These issues are not usually taken seriously by the people, the data lifetime issue also receives much less attention than vulnerabilities, this lead to rarely addressed cases in OS, Programming Languages etc.</p>
<p>Data Lifetime Problems:<br>
Usually when a Data is deleted it’s not actually deleted instead the system just ignores the binary value of that data in the hardware. These binary value can be read, which could lead to recover the data unless those binary values are tampered or replaced with a different sets of values. We define the lifetime of sensitive data in_terms of the following components.</p>
<p>~ Where copies of this data endup</p>
<p>~ How long these copies survive before being cleared or otherwise destroyed.</p>
<p>The persistence of the binary values in the hardware (i.e. HDD, SSD, RAM, etc). Whenever you copy a piece of data they need not be identical to each other. E.g. : A password could have different encodings in its lifetime</p>
<p>A same password in a windows machine could have a LM hash value or an NTLM hash value. In a Linux machine it would be as a shadow file, or each time you copy this piece of pass text it could end up as Unicode, ASCII, UTF-8, Keyboard scan cases, base-6e encoded etc.</p>
<p>The death of the data is usually when the encoding pattern is forgot or the encryption key is lost in such a way that the original data is unreadable or not recoverable or the data was overwritten.</p>
<p>Propagation:<br>
~ Sensitive data propagates through many parts of the system leaving traces behind, few of them are listed below.</p>
<p>~ Interrupt context keyboard queue: Linux reads keystrokes during a hardware interrupt and appends them to a circular queue</p>
<p>~ Process “tty” buffer: The OS copies characters from the interrupt-context queue into a tty buffer.</p>
<p>~ Window system event queue: The X server reads characters from the tty buffer into its own event queue.</p>
<p>~ Network buffer, Widget Buffer, String Buffers are few more additions.</p>
<p>None of these data is erased as soon as they were used, these were only erased to make room for the next incoming data. If there wasn’t any other process that required the buffer memory these data would be there for ages.</p>
<p>Data can also propagate to the persistent storage through a range of mechanisms:</p>
<p>~ Core dump</p>
<p>~ Hibernation</p>
<p>~ Checkpointing</p>
<p>~ Paging</p>
<p>~ Application Specific</p>
<p>Possible Outsider Threats:</p>
<p>~ Online remote attacks : Example Bluekeep Vulnerability</p>
<p>~ Offline Physical attack : EG, Improper depose of unencrypted devices.</p>
<p>~ Online Physical attacks : EG, tap buses, read memory etc</p>
<p>~ Accidental Leakage : E.g., Human error, Insider threat</p>
<p>Possible fix for Data Lifetime threats:</p>
<p>Reducing Data Lifetime:</p>
<p>~ Make Data clearing automatic : Data stored in the buffers should be validated for their needs from time to time and should be flushed if they are no longer required.</p>
<p>~ Provide Policy trade-offs : Encryption, Zeroing or pinning would be helpful.</p>
<p>~ Design for data lifetime : Program design could have a positive impact, for instance a program should validate passwords each time rather than storing them in the cache.</p>
<p>~ Identify sensitive data : Components that care about data lifetime must be treated as sensitive and proper care should be taken care off.</p>
<p>Provide Secure defaults : Impose minimal security features for every sensitive function.</p>
<p>Although there is a long way towards a secure the way that we interact these small implications would be beneficial. Its time to considered even the fractional part of the vulnerability such as Data lifetime to be highly important.</p>
<p>Reference : <a href="https://benpfaff.org/papers/dlsp.pdf" rel="nofollow noopener">https://benpfaff.org/papers/dlsp.pdf</a><br>
Link to original post : <a href="https://blankdash.wordpress.com/2019/12/23/data-lifetime-64-61-74-61/" rel="nofollow noopener">https://blankdash.wordpress.com/2019/12/23/data-lifetime-64-61-74-61/</a></p>
<ul>
<li>blankdash</li>
</ul>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/data-lifetime-64-61-74-61/18227">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/data-lifetime-64-61-74-61/18227</link>
          <pubDate>Mon, 23 Dec 2019 07:07:22 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-18227</guid>
          <source url="https://0x00sec.org/t/data-lifetime-64-61-74-61/18227.rss">Data Lifetime (64 61 74 61)</source>
        </item>
        <item>
          <title>[DCA] Orchestration</title>
          <dc:creator><![CDATA[Nitrax]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><strong>Disclaimer: I’m not the author of the content below. I just aggregated public contents to create a knowledge base.</strong></p>
<hr>
<p>Hi fellas,</p>
<p>Here we go, the first article about the prior mentioned DCA series. Today, we will cover the points approached in the orchestration section of the exam.</p>
<h3>Complete the setup of swarm mode cluster with managers and worker nodes</h3>
<h4>Create a Docker Swarm cluster</h4>
<p>Make sure the Docker Engine daemon is started on the host machines.</p>
<ol>
<li>Open a terminal and ssh into the machine where you want to run your manager node. This tutorial uses a machine named <code>manager1</code>. If you use Docker Machine, you can connect to it via SSH using the following command:</li>
</ol>
<pre><code class="lang-bash">$ docker-machine ssh manager1
</code></pre>
<ol start="2">
<li>Run the following command to create a new swarm:</li>
</ol>
<pre><code class="lang-bash">$ docker swarm init --advertise-addr &lt;MANAGER-IP&gt;
</code></pre>
<blockquote>
<p><strong>Note</strong>: If you are using Docker Desktop for Mac or Docker Desktop for Windows to test single-node swarm, simply run <code>docker swarm init</code> with no arguments. There is no need to specify <strong>–advertise-addr</strong> in this case. To learn more, see the topic on how to <a href="https://0x00sec.org/engine/swarm/swarm-tutorial/index.md#use-docker-for-mac-or-docker-for-windows">Use Docker Desktop or Mac or Docker Desktop for Windows</a> with Swarm.</p>
</blockquote>
<p>In the tutorial, the following command creates a swarm on the <code>manager1</code> machine:</p>
<pre><code class="lang-bash">$ docker swarm init --advertise-addr 192.168.99.100
Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
    192.168.99.100:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
</code></pre>
<p>The <strong>–advertise-addr</strong> flag configures the manager node to publish its address as <strong>192.168.99.100</strong>. The other nodes in the swarm must be able to access the manager at the IP address.</p>
<p>The output includes the commands to join new nodes to the swarm. Nodes will join as managers or workers depending on the value for the <strong>–token</strong> flag.</p>
<ol start="2">
<li>Run <strong>docker info</strong> to view the current state of the swarm:</li>
</ol>
<pre><code class="lang-bash">$ docker info

Containers: 2
Running: 0
Paused: 0
Stopped: 2
  ...snip...
Swarm: active
  NodeID: dxn1zf6l61qsb1josjja83ngz
  Is Manager: true
  Managers: 1
  Nodes: 1
  ...snip...
</code></pre>
<ol start="3">
<li>Run the <strong>docker node ls</strong> command to view information about nodes:</li>
</ol>
<pre><code class="lang-bash">$ docker node ls

ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader

</code></pre>
<p>The * next to the node ID indicates that you’re currently connected on this node.</p>
<p>Docker Engine swarm mode automatically names the node for the machine hostname. The tutorial covers other columns in later steps.</p>
<h4>Add nodes to the swarm</h4>
<p>Once you’ve <a href="https://0x00sec.org#Create-a-Docker-Swarm-cluster">created a swarm</a> with a manager node, you’re ready to add worker nodes.</p>
<ol>
<li>
<p>Open a terminal and ssh into the machine where you want to run a worker node. This tutorial uses the name <strong>worker1</strong>.</p>
</li>
<li>
<p>Run the command produced by the <strong>docker swarm init</strong> output from the <a href="https://0x00sec.org#Create-a-Docker-Swarm-cluster">Create a swarm</a> tutorial step to create a worker node joined to the existing swarm:</p>
</li>
</ol>
<pre><code class="lang-bash">$ docker swarm join \
  --token  SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377

This node joined a swarm as a worker.
</code></pre>
<p>If you don’t have the command available, you can run the following command on a manager node to retrieve the join command for a worker:</p>
<pre><code class="lang-bash">$ docker swarm join-token worker

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
    192.168.99.100:2377
</code></pre>
<ol start="3">
<li>
<p>Open a terminal and ssh into the machine where you want to run a second worker node. This tutorial uses the name <code>worker2</code>.</p>
</li>
<li>
<p>Run the command produced by the <strong>docker swarm init</strong> output from the <a href="https://0x00sec.org#Create-a-Docker-Swarm-cluster">Create a swarm</a> tutorial step to create a second worker node joined to the existing swarm:</p>
</li>
</ol>
<pre><code class="lang-bash">$ docker swarm join \
  --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
  192.168.99.100:2377

This node joined a swarm as a worker.
</code></pre>
<ol start="5">
<li>Open a terminal and ssh into the machine where the manager node runs and run the <strong>docker node ls</strong> command to see the worker nodes:</li>
</ol>
<pre><code class="lang-bash">ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
03g1y59jwfg7cf99w4lt0f662    worker2   Ready   Active
9j68exjopxe7wfl6yuxml7a7j    worker1   Ready   Active
dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader
</code></pre>
<p>The <strong>MANAGER</strong> column identifies the manager nodes in the swarm. The empty status in this column for <strong>worker1</strong> and <strong>worker2</strong> identifies them as worker nodes.</p>
<p>Swarm management commands like <strong>docker node ls</strong> only work on manager nodes.</p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/sxZFWFSL2B70Uzb6jyAmy9tKF" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/77a3f9926ce7ffcb0bbeb9fd3d7f30ec3e1cf97b.png" alt="asciicast" data-base62-sha1="h4o8hqyaEGzyOFWqe8BZgu93oAH" width="644" height="499"></a></p>
<h3>State the differences between running a container vs running a service</h3>
<h4>Docker run</h4>
<p>The <strong>docker run</strong> command first <strong>creates</strong> a writeable container layer over the specified image, and then <strong>starts</strong> it using the specified command. That is, <strong>docker run</strong> is equivalent to the API <strong>/containers/create</strong> then <strong>/containers/(id)/start</strong>. A stopped container can be restarted with all its previous changes intact using <strong>docker start</strong>. See <strong>docker ps -a</strong> to view a list of all containers.</p>
<p>The <strong>docker run</strong> command can be used in combination with <strong>docker commit</strong> to change the command that a container runs. There is additional detailed information about docker run in the <a href="https://docs.docker.com/engine/reference/run/" rel="noopener nofollow ugc">Docker run reference</a>.</p>
<h4>Docker services</h4>
<p>When you deploy the service to the swarm, the swarm manager accepts your service definition as the desired state for the service. Then it schedules the service on nodes in the swarm as one or more replica tasks. The tasks run independently of each other on nodes in the swarm.</p>
<p>For example, imagine you want to load balance between three instances of an HTTP listener. The diagram below shows an HTTP listener service with three replicas. Each of the three instances of the listener is a task in the swarm.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e.png" data-download-href="/uploads/short-url/9X6NdrdJaAcWBTk8kyScc3Tfnqu.png?dl=1" title="Services diagram" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e_2_690x476.png" alt="Services diagram" data-base62-sha1="9X6NdrdJaAcWBTk8kyScc3Tfnqu" width="690" height="476" srcset="https://0x00sec.s3.amazonaws.com/optimized/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e_2_690x476.png, https://0x00sec.s3.amazonaws.com/original/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e.png 1.5x, https://0x00sec.s3.amazonaws.com/original/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/2X/4/45c2188715db770ebdbe4d1a19d27a00d8fa125e_2_10x10.png"></a></div><p></p>
<p>A container is an isolated process. In the swarm mode model, each task invokes exactly one container. A task is analogous to a “slot” where the scheduler places a container. Once the container is live, the scheduler recognizes that the task is in a running state. If the container fails health checks or terminates, the task terminates.</p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/TlMJZDNKZCeUYSfRbmyiKXK46" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/e891e57055be1e617f12b5b4be42c605cc174dc2.png" alt="asciicast" data-base62-sha1="xbplYloYJi7dgYjujfuYkeItWjE" width="690" height="444"></a></p>
<h3>Demonstrate steps to lock a swarm cluster</h3>
<p>In Docker 1.13 and higher, the Raft logs used by swarm managers are encrypted on disk by default. This at-rest encryption protects your service’s configuration and data from attackers who gain access to the encrypted Raft logs. One of the reasons this feature was introduced was in support of the new <a href="https://docs.docker.com/engine/swarm/secrets/" rel="noopener nofollow ugc">Docker<br>
secrets</a> feature.</p>
<p>When Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node’s memory. Docker 1.13 introduces the ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called <em>autolock</em>.</p>
<p>When Docker restarts, you must <a href="https://0x00sec.org#Unlock-a-swarm">unlock the swarm</a> first, using a <em>key encryption key</em> generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.</p>
<blockquote>
<p><strong>Note</strong>: You don’t need to unlock the swarm when a new node joins the swarm,<br>
because the key is propagated to it over mutual TLS.</p>
</blockquote>
<h4>Initialize a swarm with autolocking enabled</h4>
<p>When you initialize a new swarm, you can use the <strong>–autolock</strong> flag to enable autolocking of swarm manager nodes when Docker restarts.</p>
<pre><code class="lang-bash">$ docker swarm init --autolock

Swarm initialized: current node (k1q27tfyx9rncpixhk69sa61v) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-0j52ln6hxjpxk2wgk917abcnxywj3xed0y8vi1e5m9t3uttrtu-7bnxvvlz2mrcpfonjuztmtts9 \
    172.31.46.109:2377

To add a manager to this swarm, run **docker swarm join-token manager** and follow the instructions.

To unlock a swarm manager after it restarts, run the **docker swarm unlock** command and provide the following key:

    SWMKEY-1-WuYH/IX284+lRcXuoVf38viIDK3HJEKY13MIHX+tTt8
</code></pre>
<p>Store the key in a safe place, such as in a password manager.</p>
<p>When Docker restarts, you need to <a href="https://0x00sec.org#Unlock-a-swarm">unlock the swarm</a>. A locked swarm causes an error like the following when you try to start or restart a service:</p>
<pre><code class="lang-bash">$ sudo service docker restart

$ docker service ls

Error response from daemon: Swarm is encrypted and needs to be unlocked before it can be used. Use "docker swarm unlock" to unlock it.
</code></pre>
<h4>Enable or disable autolock on an existing swarm</h4>
<p>To enable autolock on an existing swarm, set the <strong>autolock</strong> flag to <strong>true</strong>.</p>
<pre><code class="lang-bash">$ docker swarm update --autolock=true

Swarm updated.
To unlock a swarm manager after it restarts, run the ***docker swarm unlock*** command and provide the following key:

    SWMKEY-1-+MrE8NgAyKj5r3NcR4FiQMdgu+7W72urH0EZeSmP/0Y

Please remember to store this key in a password manager, since without it you will not be able to restart the manager.
</code></pre>
<p>To disable autolock, set <strong>–autolock</strong> to <strong>false</strong>. The mutual TLS key and theencryption key used to read and write Raft logs are stored unencrypted on disk. There is a trade-off between the risk of storing the encryption key unencrypted at rest and the convenience of restarting a swarm without needing to unlock each manager.</p>
<pre><code class="lang-bash">$ docker swarm update --autolock=false
</code></pre>
<p>Keep the unlock key around for a short time after disabling autolocking, in case a manager goes down while it is still configured to lock using the old key.</p>
<h4>Unlock a swarm</h4>
<p>To unlock a locked swarm, use <strong>docker swarm unlock</strong>.</p>
<pre><code class="lang-bash">$ docker swarm unlock

Please enter unlock key:
</code></pre>
<p>Enter the encryption key that was generated and shown in the command output when you locked the swarm or rotated the key, and the swarm unlocks.</p>
<h4>View the current unlock key for a running swarm</h4>
<p>Consider a situation where your swarm is running as expected, then a manager node becomes unavailable. You troubleshoot the problem and bring the physical node back online, but you need to unlock the manager by providing the unlock key to read the encrypted credentials and Raft logs.</p>
<p>If the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using <strong>docker swarm unlock-key</strong> without any arguments.</p>
<pre><code class="lang-bash">$ docker swarm unlock-key

To unlock a swarm manager after it restarts, run the **docker swarm unlock** command and provide the following key:

    SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA

Please remember to store this key in a password manager, since without it you will not be able to restart the manager.
</code></pre>
<p>If the key was rotated after the swarm node became unavailable and you do not have a record of the previous key, you may need to force the manager to leave the swarm and join it back to the swarm as a new manager.</p>
<h4>Rotate the unlock key</h4>
<p>You should rotate the locked swarm’s unlock key on a regular schedule.</p>
<pre><code class="lang-bash">$ docker swarm unlock-key --rotate

Successfully rotated manager unlock key.

To unlock a swarm manager after it restarts, run the **docker swarm unlock** command and provide the following key:

    SWMKEY-1-8jDgbUNlJtUe5P/lcr9IXGVxqZpZUXPzd+qzcGp4ZYA

Please remember to store this key in a password manager, since without it you will not be able to restart the manager.
</code></pre>
<blockquote>
<p><strong>Warning</strong>:<br>
When you rotate the unlock key, keep a record of the old key<br>
around for a few minutes, so that if a manager goes down before it gets the new<br>
key, it may still be unlocked with the old one.</p>
</blockquote>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/taLgo9ebq1Ut1KOjF1iyvXUEb" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/8/84056f56dcc6adf7f9fed9c477f1a83a73e0e5cd.png" alt="asciicast" data-base62-sha1="iPUFyRwSyUYtb8GU5PMQIk3PlXn" width="690" height="444"></a></p>
<h3>Extend the instructions to run individual containers into running services under swarm</h3>
<p>After you <a href="https://0x00sec.org#Create-a-Docker-Swarm-cluster">create a swarm</a>, you can deploy a service to the swarm. For this tutorial, you also <a href="https://0x00sec.org#Add-nodes-to-the-swarm">added worker nodes</a>, but that is not a requirement to deploy a service.</p>
<ol>
<li>
<p>Open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named <strong>manager1</strong>.</p>
</li>
<li>
<p>Run the following command:</p>
</li>
</ol>
<pre><code class="lang-bash">$ docker service create --replicas 1 --name helloworld alpine ping docker.com

9uk4639qpg7npwf3fn2aasksr
</code></pre>
<ul>
<li>The <strong>docker service create</strong> command creates the service.</li>
<li>The <strong>–name</strong> flag names the service <strong>helloworld</strong>.</li>
<li>The <strong>–replicas</strong> flag specifies the desired state of 1 running instance.</li>
<li>The arguments <strong>alpine ping <a href="http://docker.com" rel="noopener nofollow ugc">docker.com</a></strong> define the service as an Alpine</li>
</ul>
<p>Linux container that executes the command <strong>ping <a href="http://docker.com" rel="noopener nofollow ugc">docker.com</a></strong>.</p>
<ol start="3">
<li>Run <strong>docker service ls</strong> to see the list of running services:</li>
</ol>
<pre><code class="lang-bash">$ docker service ls

ID            NAME        SCALE  IMAGE   COMMAND
9uk4639qpg7n  helloworld  1/1    alpine  ping docker.com
</code></pre>
<h3>Interpret the output of docker inspect commands</h3>
<blockquote>
<p>Required read: <a href="https://docs.docker.com/engine/reference/commandline/inspect/" rel="noopener nofollow ugc">Docker inspect</a></p>
</blockquote>
<h4>Inspect a service on the swarm</h4>
<p>When you have <a href="https://0x00sec.org#Extend-the-instructions-to-run-individual-containers-into-running-services-under-swarm">deployed a service</a> to your swarm, you can use the Docker CLI to see details about the service running in the swarm.</p>
<ol>
<li>
<p>If you haven’t already, open a terminal and ssh into the machine where you run your manager node. For example, the tutorial uses a machine named <strong>manager1</strong>.</p>
</li>
<li>
<p>Run <strong>docker service inspect --pretty </strong> to display the details about a service in an easily readable format.</p>
</li>
</ol>
<p>To see the details on the <strong>helloworld</strong> service:</p>
<pre><code class="lang-bash">[manager1]$ docker service inspect --pretty helloworld

ID:		9uk4639qpg7npwf3fn2aasksr
Name:		helloworld
Service Mode:	REPLICATED
    Replicas:		1
Placement:
UpdateConfig:
    Parallelism:	1
ContainerSpec:
    Image:		alpine
    Args:	ping docker.com
Resources:
Endpoint Mode:  vip
</code></pre>
<blockquote>
<p><strong>Tip</strong>: To return the service details in json format, run the same command without the <strong>–pretty</strong> flag.</p>
</blockquote>
<pre><code class="lang-bash">[manager1]$ docker service inspect helloworld
[
{
    "ID": "9uk4639qpg7npwf3fn2aasksr",
    "Version": {
        "Index": 418
    },
    "CreatedAt": "2016-06-16T21:57:11.622222327Z",
    "UpdatedAt": "2016-06-16T21:57:11.622222327Z",
    "Spec": {
        "Name": "helloworld",
        "TaskTemplate": {
            "ContainerSpec": {
                "Image": "alpine",
                "Args": [
                    "ping",
                    "docker.com"
                ]
            },
            "Resources": {
                "Limits": {},
                "Reservations": {}
            },
            "RestartPolicy": {
                "Condition": "any",
                "MaxAttempts": 0
            },
            "Placement": {}
        },
        "Mode": {
            "Replicated": {
                "Replicas": 1
            }
        },
        "UpdateConfig": {
            "Parallelism": 1
        },
        "EndpointSpec": {
            "Mode": "vip"
        }
    },
    "Endpoint": {
        "Spec": {}
    }
}
]
</code></pre>
<ol start="4">
<li>Run <strong>docker service ps </strong> to see which nodes are running the service:</li>
</ol>
<pre><code class="lang-bash">[manager1]$ docker service ps helloworld

NAME                                    IMAGE   NODE     DESIRED STATE  CURRENT STATE           ERROR               PORTS
helloworld.1.8p1vev3fq5zm0mi8g0as41w35  alpine  worker2  Running        Running 3 minutes
</code></pre>
<p>In this case, the one instance of the <strong>helloworld</strong> service is running on the <strong>worker2</strong> node. You may see the service running on your manager node. By default, manager nodes in a swarm can execute tasks just like worker nodes.</p>
<p>Swarm also shows you the <strong>DESIRED STATE</strong> and <strong>CURRENT STATE</strong> of the service task so you can see if tasks are running according to the service definition.</p>
<ol start="4">
<li>Run <strong>docker ps</strong> on the node where the task is running to see details about the container for the task.</li>
</ol>
<blockquote>
<p><strong>Tip</strong>: If <strong>helloworld</strong> is running on a node other than your manager node, you must ssh to that node.</p>
</blockquote>
<pre><code class="lang-bash">[worker2]$docker ps

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
e609dde94e47        alpine:latest       "ping docker.com"   3 minutes ago       Up 3 minutes                            helloworld.1.8p1vev3fq5zm0mi8g0as41w35
</code></pre>
<h3>Convert an application deployment into a stack file using a YAML compose file with docker stack deploy</h3>
<blockquote>
<p>Required read <a href="https://docs.docker.com/engine/reference/commandline/stack_deploy/" rel="noopener nofollow ugc">Docker Stack Deploy</a><br>
required read <a href="https://docs.docker.com/compose/compose-file/#service-configuration-reference" rel="noopener nofollow ugc">Service Configuration Reference</a></p>
</blockquote>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/vtoxMgJiUMaay9IhNMporfpXV" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/d/d324c670b6f259f430c755898a79d177889e9b1c.png" alt="asciicast" data-base62-sha1="u7RxgYW3sFtvAoifQthQOiictM8" width="690" height="394"></a></p>
<h3>Manipulate a running stack of services</h3>
<blockquote>
<p>Required read <a href="https://docs.docker.com/engine/reference/commandline/stack_services/" rel="noopener nofollow ugc">Docker Stack Services</a></p>
</blockquote>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/4bqsdgv46EueyOPF48Fzd70dc" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/f9a15da7d9681ee4eb66b375fa20caed4416d26d.png" alt="asciicast" data-base62-sha1="zCkC7xu5ZWoutjvpuQTRIPGtXYx" width="690" height="394"></a></p>
<h3>Increase number of replicas</h3>
<p>The scale command enables you to scale one or more replicated services either up or down to the desired number of replicas. This command cannot be applied on services which are global mode. The command will return immediately, but the actual scaling of the service may take some time. To stop all replicas of a service while keeping the service active in the swarm you can set the scale to 0.</p>
<p>The following command scales the “frontend” service to 50 tasks.</p>
<pre><code class="lang-bash">$ docker service scale frontend=50

frontend scaled to 50
</code></pre>
<p>The following command tries to scale a global service to 10 tasks and returns an error.</p>
<pre><code class="lang-bash">$ docker service create --mode global --name backend backend:latest

b4g08uwuairexjub6ome6usqh

$ docker service scale backend=10

backend: scale can only be used with replicated mode
</code></pre>
<p>Directly afterwards, run docker service ls, to see the actual number of replicas.</p>
<pre><code class="lang-bash">$ docker service ls --filter name=frontend

ID            NAME      MODE        REPLICAS  IMAGE
3pr5mlvu3fh9  frontend  replicated  15/50     nginx:alpine
</code></pre>
<p>You can also scale a service using the docker service update command. The following commands are equivalent:</p>
<pre><code class="lang-bash">$ docker service scale frontend=50
$ docker service update --replicas=50 frontend
</code></pre>
<p>The docker service scale command allows you to set the desired number of tasks for multiple services at once. The following example scales both the backend and frontend services:</p>
<pre><code class="lang-bash">$ docker service scale backend=3 frontend=5

backend scaled to 3
frontend scaled to 5

$ docker service ls

ID            NAME      MODE        REPLICAS  IMAGE
3pr5mlvu3fh9  frontend  replicated  5/5       nginx:alpine
74nzcxxjv6fq  backend   replicated  3/3       redis:3.0.6
</code></pre>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/uwKaS8HHk35Aw4H8yCfD8XtG5" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/8/892683e4549261b7f89e12d8741f3e34d65c8651.png" alt="asciicast" data-base62-sha1="jzhVMcb9zCDQradYaJRRPHOvtwl" width="690" height="394"></a></p>
<h3>Add networks, publish ports</h3>
<p>When you create a swarm service, you can publish that service’s ports to hosts outside the swarm in two ways:</p>
<ul>
<li>
<p><a href="https://docs.docker.com/engine/swarm/services/#publish-a%20services-ports-using-the-routing-mesh" rel="noopener nofollow ugc">You can rely on the routing mesh</a>. When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.</p>
</li>
<li>
<p><a href="https://0x00sec.org#Publish-a-service's-ports-using-the-routing-mesh">You can publish a service task’s port directly on the swarm node</a> where that service is running. This feature is available in Docker 1.13 and higher. This bypasses the routing mesh and provides the maximum flexibility, including the ability for you to develop your own routing framework. However, you are responsible for keeping track of where each task is running and routing requests to the tasks, and load-balancing across the nodes.</p>
</li>
</ul>
<p>Keep reading for more information and use cases for each of these methods.</p>
<h4>Publish a service’s ports using the routing mesh</h4>
<p>To publish a service’s ports externally to the swarm, use the <strong>–publish :</strong> flag. The swarm makes the service accessible at the published port <strong>on every swarm node</strong>. If an external host connects to that port on any swarm node, the routing mesh routes it to a task. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond. For more details about swarm service networking, see <a href="https://docs.docker.com/network/overlay/" rel="noopener nofollow ugc">Manage swarm service networks</a>.</p>
<h5>Example: Run a three-task Nginx service on 10-node swarm</h5>
<p>Imagine that you have a 10-node swarm, and you deploy an Nginx service running three tasks on a 10-node swarm:</p>
<pre><code class="lang-bash">$ docker service create --name my_web \
                        --replicas 3 \
                        --publish published=8080,target=80 \
                        nginx
</code></pre>
<p>Three tasks run on up to three nodes. You don’t need to know which nodes are running the tasks; connecting to port 8080 on <strong>any</strong> of the 10 nodes connects you to one of the three <strong>nginx</strong> tasks. You can test this using <strong>curl</strong>. The following example assumes that <strong>localhost</strong> is one of the swarm nodes. If this is not the case, or <strong>localhost</strong> does not resolve to an IP address on your host, substitute the host’s IP address or resolvable host name.</p>
<p>The HTML output is truncated:</p>
<pre><code class="lang-bash">$ curl localhost:8080

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...truncated...
&lt;/html&gt;
</code></pre>
<p>Subsequent connections may be routed to the same swarm node or a different one.</p>
<h4>Publish a service’s ports directly on the swarm node</h4>
<p>Using the routing mesh may not be the right choice for your application if you need to make routing decisions based on application state or you need total control of the process for routing requests to your service’s tasks. To publish a service’s port directly on the node where it is running, use the <strong>mode=host</strong> option to the <strong>–publish</strong> flag.</p>
<blockquote>
<p><strong>Note</strong>: If you publish a service’s ports directly on the swarm node using <strong>mode=host</strong> and also set <strong>published=</strong> this creates an implicit limitation that you can only run one task for that service on a given swarm node. You can work around this by specifying <strong>published</strong> without a port definition, which causes Docker to assign a random port for each task.<br>
In addition, if you use <strong>mode=host</strong> and you do not use the <strong>–mode=global</strong> flag on <strong>docker service create</strong>, it is difficult to know which nodes are running the service to route work to them.</p>
</blockquote>
<h5>Example: Run an <code>nginx</code> web server service on every swarm node</h5>
<p><a href="https://hub.docker.com/_/nginx/" rel="noopener nofollow ugc">nginx</a> is an open source reverse proxy, load balancer, HTTP cache, and a web server. If you run nginx as a service using the routing mesh,connecting to the nginx port on any swarm node shows you the web page for (effectively) <strong>a random swarm node</strong> running the service.</p>
<p>The following example runs nginx as a service on each node in your swarm and exposes nginx port locally on each swarm node.</p>
<pre><code class="lang-bash">$ docker service create \
  --mode global \
  --publish mode=host,target=80,published=8080 \
  --name=nginx \
  nginx:latest
</code></pre>
<p>You can reach the nginx server on port 8080 of every swarm node. If you add a node to the swarm, a nginx task is started on it. You cannot start another service or container on any swarm node which binds to port 8080.</p>
<blockquote>
<p><strong>Note</strong>: This is a naive example. Creating an application-layer routing framework for a multi-tiered service is complex and out of scope for this topic.</p>
</blockquote>
<h4>Connect the service to an overlay network</h4>
<p>You can use overlay networks to connect one or more services within the swarm.</p>
<p>First, create overlay network on a manager node using the <strong>docker network create</strong> command with the <strong>–driver overlay</strong> flag.</p>
<pre><code class="lang-bash">$ docker network create --driver overlay my-network
</code></pre>
<p>After you create an overlay network in swarm mode, all manager nodes have access to the network.</p>
<p>You can create a new service and pass the <strong>–network</strong> flag to attach the service to the overlay network:</p>
<pre><code class="lang-bash">$ docker service create \
  --replicas 3 \
  --network my-network \
  --name my-web \
  nginx
</code></pre>
<p>The swarm extends <strong>my-network</strong> to each node running the service.</p>
<p>You can also connect an existing service to an overlay network using the <strong>–network-add</strong> flag.</p>
<pre><code class="lang-bash">$ docker service update --network-add my-network my-web
</code></pre>
<p>To disconnect a running service from a network, use the <strong>–network-rm</strong> flag.</p>
<pre><code class="lang-bash">$ docker service update --network-rm my-network my-web
</code></pre>
<p>For more information on overlay networking and service discovery, refer to <a href="https://docs.docker.com/network/overlay/" rel="noopener nofollow ugc">Attach services to an overlay network</a> and<br>
<a href="https://docs.docker.com/network/overlay/" rel="noopener nofollow ugc">Docker swarm mode overlay network security model</a>.</p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/SARGFvegQA7H1B6pNouiKSNPZ" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/172a537a43e53395aab2fe2161e99f8c0850e1af.png" alt="asciicast" data-base62-sha1="3iVFep8UrttrobnssHt0F68PSqz" width="690" height="394"></a></p>
<h3>Mount volumes</h3>
<p>For best performance and portability, you should avoid writing important data directly into a container’s writable layer, instead using data volumes or bind mounts. This principle also applies to services.</p>
<p>You can create two types of mounts for services in a swarm, <strong>volume</strong> mounts or <strong>bind</strong> mounts. Regardless of which type of mount you use, configure it using the <strong>–mount</strong> flag when you create a service, or the <strong>–mount-add</strong> or <strong>–mount-rm</strong> flag when updating an existing service. The default is a data volume if you don’t specify a type.</p>
<h4>Data volumes</h4>
<p>Data volumes are storage that exist independently of a container. The lifecycle of data volumes under swarm services is similar to that under containers. Volumes outlive tasks and services, so their removal must be managed separately. Volumes can be created before deploying a service, or if they don’t exist on a particular host when a task is scheduled there, they are created automatically according to the volume specification on the service.</p>
<p>To use existing data volumes with a service use the <strong>–mount</strong> flag:</p>
<pre><code class="lang-bash">$ docker service create \
  --mount src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt; \
  --name myservice \
  &lt;IMAGE&gt;
</code></pre>
<p>If a volume with the same <strong></strong> does not exist when a task is scheduled to a particular host, then one is created. The default volume driver is <code>local</code>.  To use a different volume driver with this create-on-demand pattern, specify the driver and its options with the <strong>–mount</strong> flag:</p>
<pre><code class="lang-bash">$ docker service create \
  --mount type=volume,src=&lt;VOLUME-NAME&gt;,dst=&lt;CONTAINER-PATH&gt;,volume-driver=&lt;DRIVER&gt;,volume-opt=&lt;KEY0&gt;=&lt;VALUE0&gt;,volume-opt=&lt;KEY1&gt;=&lt;VALUE1&gt;
  --name myservice \
  &lt;IMAGE&gt;
</code></pre>
<p>For more information on how to create data volumes and the use of volume drivers, see <a href="https://docs.docker.com/storage/volumes/" rel="noopener nofollow ugc">Use volumes</a>.</p>
<h4>Bind mounts</h4>
<p>Bind mounts are file system paths from the host where the scheduler deploys the container for the task. Docker mounts the path into the container. The file system path must exist before the swarm initializes the container for the task.</p>
<p>The following examples show bind mount syntax:</p>
<ul>
<li>
<p>To mount a read-write bind:</p>
<pre><code class="lang-bash">$ docker service create \
  --mount type=bind,src=&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt; \
  --name myservice \
  &lt;IMAGE&gt;
</code></pre>
</li>
<li>
<p>To mount a read-only bind:</p>
<pre><code class="lang-bash">$ docker service create \
  --mount type=bind,src=&lt;HOST-PATH&gt;,dst=&lt;CONTAINER-PATH&gt;,readonly \
  --name myservice \
  &lt;IMAGE&gt;
</code></pre>
</li>
</ul>
<blockquote>
<p><strong>Important</strong>: Bind mounts can be useful but they can also cause problems. In most cases, it is recommended that you architect your application such that mounting paths from the host is unnecessary. The main risks include the following:</p>
<ul>
<li>
<p>If you bind mount a host path into your service’s containers, the path must exist on every swarm node. The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify.</p>
</li>
<li>
<p>The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.</p>
</li>
<li>
<p>Host bind mounts are non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.</p>
</li>
</ul>
</blockquote>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/sExTsGhFBPW9LgLwzYN8afuOP" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/6/61248b8520095cf4b30906fc99cea4b2aac3739d.png" alt="asciicast" data-base62-sha1="dRmBWhgZdigIkcMAiuD6lTUc8Ff" width="690" height="465"></a></p>
<h3>Illustrate running a replicated vs global service</h3>
<p>There are two types of service deployments, replicated and global.</p>
<p>For a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.</p>
<p>A global service is a service that runs one task on every node. There is no pre-specified number of tasks. Each time you add a node to the swarm, the orchestrator creates a task and the scheduler assigns the task to the new node. Good candidates for global services are monitoring agents, an anti-virus scanners or other types of containers that you want to run on every node in the swarm.</p>
<p>The diagram below shows a three-service replica in yellow and a global service in gray.</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/2X/3/35efd4d64283c0e84edc613755d2893967a74fef.png" data-download-href="/uploads/short-url/7H98P6mF3N0yoIfubZCupHGC1vp.png?dl=1" title="Diagram" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/2X/3/35efd4d64283c0e84edc613755d2893967a74fef_2_690x492.png" alt="Diagram" data-base62-sha1="7H98P6mF3N0yoIfubZCupHGC1vp" width="690" height="492" srcset="https://0x00sec.s3.amazonaws.com/optimized/2X/3/35efd4d64283c0e84edc613755d2893967a74fef_2_690x492.png, https://0x00sec.s3.amazonaws.com/original/2X/3/35efd4d64283c0e84edc613755d2893967a74fef.png 1.5x, https://0x00sec.s3.amazonaws.com/original/2X/3/35efd4d64283c0e84edc613755d2893967a74fef.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/2X/3/35efd4d64283c0e84edc613755d2893967a74fef_2_10x10.png"></a></div><p></p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/heYzOqTCEpJFNFZkwakkCv97z" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/a/aa647c322b78d9c400788d1dd52a57eee0885db9.png" alt="asciicast" data-base62-sha1="ojmsq4QtPcFwwYXKutl9MIE1lwJ" width="664" height="500"></a></p>
<h3>Identify the steps needed to troubleshoot a service not deploying</h3>
<p>A service may be configured in such a way that no node currently in the swarm can run its tasks. In this case, the service remains in state pending. Here are a few examples of when a service might remain in state pending.</p>
<blockquote>
<p>Note: If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in pending.</p>
</blockquote>
<ul>
<li>If all nodes are paused or drained, and you create a service, it is pending until a node becomes available. In reality, the first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.</li>
<li>You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks. If you specify a very large value, such as 500 GB, the task stays pending forever, unless you really have a node which can satisfy it.</li>
<li>You can impose placement constraints on the service, and the constraints may not be able to be honored at a given time.</li>
</ul>
<p>This behavior illustrates that the requirements and configuration of your tasks are not tightly tied to the current state of the swarm. As the administrator of a swarm, you declare the desired state of your swarm, and the manager works with the nodes in the swarm to create that state. You do not need to micro-manage the tasks on the swarm.</p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/jwoYTaAYr4LEqhYBuRkEI9ets" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/d/de0be78ee97c5cb8b61114c4bbb1ee05ac209ad5.png" alt="asciicast" data-base62-sha1="vGjvets3uIUse7YBCsiDymHZZbL" width="664" height="500"></a></p>
<h3>Apply node labels to demonstrate placement of tasks</h3>
<blockquote>
<p>Required read <a href="https://docs.docker.com/engine/reference/commandline/node_update/" rel="noopener nofollow ugc">Docker node update</a></p>
</blockquote>
<h4>Placement constraints</h4>
<p>Use placement constraints to control the nodes a service can be assigned to. In the following example, the service only runs on nodes with the label <strong>region</strong> set to <strong>east</strong>. If no appropriately-labelled nodes are available, tasks will wait in <strong>Pending</strong> until they become available. The <strong>–constraint</strong> flag uses an equality operator <strong>(== or !=)</strong>. For replicated services, it is possible that all services run on the same node, or each node only runs one replica, or that some nodes don’t run any replicas. For global services, the service runs on every node that meets the placement constraint and any <a href="https://docs.docker.com/engine/swarm/services/#reserve-memory-or-cpus-for-a-service" rel="noopener nofollow ugc">resource requirements</a>.</p>
<pre><code class="lang-bash">$ docker service create \
  --name my-nginx \
  --replicas 5 \
  --constraint node.labels.region==east \
  nginx
</code></pre>
<p>You can also use the <strong>constraint</strong> service-level key in a <strong>docker-compose.yml</strong> file.</p>
<p>If you specify multiple placement constraints, the service only deploys onto nodes where they are all met. The following example limits the service to run on all nodes where <strong>region</strong> is set to <strong>east</strong> and <strong>type</strong> is not set to <strong>devel</strong>:</p>
<pre><code class="lang-bash">$ docker service create \
  --name my-nginx \
  --mode global \
  --constraint node.labels.region==east \
  --constraint node.labels.type!=devel \
  nginx
</code></pre>
<p>You can also use placement constraints in conjunction with placement preferences and CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.</p>
<p>For more information on constraints, refer to the <a href="https://docs.docker.com/engine/reference/commandline/service_create/" rel="noopener nofollow ugc">docker service create CLI reference</a>.</p>
<h4>Placement preferences</h4>
<p>While placement constraints limit the nodes a service can run on, placement preferences try to place tasks on appropriate nodes in an algorithmic way (currently, only spread evenly). For instance, if you assign each node a <strong>rack</strong> label, you can set a placement preference to spread the service evenly across nodes with the rack label, by value. This way, if you lose a <strong>rack</strong>, the service is still running on nodes on other racks.</p>
<p>Placement preferences are not strictly enforced. If no node has the label you specify in your preference, the service is deployed as though the preference were not set.</p>
<blockquote>
<p>Placement preferences are ignored for global services.</p>
</blockquote>
<p>The following example sets a preference to spread the deployment across nodes based on the value of the <strong>datacenter</strong> label. If some nodes have <strong>datacenter=us-east</strong> and others have <strong>datacenter=us-west</strong>, the service is deployed as evenly as possible across the two sets of nodes.</p>
<pre><code class="lang-bash">$ docker service create \
  --replicas 9 \
  --name redis_2 \
  --placement-pref 'spread=node.labels.datacenter' \
  redis:3.0.6
</code></pre>
<blockquote>
<p>Missing or null labels</p>
</blockquote>
<blockquote>
<p>Nodes which are missing the label used to spread still receive task assignments. As a group, these nodes receive tasks in equal proportion to any of the other groups identified by a specific label value. In a sense, a missing label is the same as having the label with a null value attached to it. If the service should only run on nodes with the label being used for the spread preference, the preference should be combined with a constraint.</p>
</blockquote>
<p>You can specify multiple placement preferences, and they are processed in the order they are encountered. The following example sets up a service with multiple placement preferences. Tasks are spread first over the various datacenters, and then over racks (as indicated by the respective labels):</p>
<pre><code class="lang-bash">$ docker service create \
  --replicas 9 \
  --name redis_2 \
  --placement-pref 'spread=node.labels.datacenter' \
  --placement-pref 'spread=node.labels.rack' \
  redis:3.0.6
</code></pre>
<p>You can also use placement preferences in conjunction with placement constraints or CPU/memory constraints. Be careful not to use settings that are not possible to fulfill.</p>
<p>This diagram illustrates how placement preferences work:</p>
<p></p><div class="lightbox-wrapper"><a class="lightbox" href="https://0x00sec.s3.amazonaws.com/original/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04.png" data-download-href="/uploads/short-url/aIVSZGLm9dGeyuJ91xRhC7t8Cfq.png?dl=1" title="Diagram" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/optimized/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04_2_690x336.png" alt="Diagram" data-base62-sha1="aIVSZGLm9dGeyuJ91xRhC7t8Cfq" width="690" height="336" srcset="https://0x00sec.s3.amazonaws.com/optimized/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04_2_690x336.png, https://0x00sec.s3.amazonaws.com/optimized/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04_2_1035x504.png 1.5x, https://0x00sec.s3.amazonaws.com/optimized/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04_2_1380x672.png 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/2X/4/4b2a0b02ab577e8c79aa783cbb2c27422ddf4b04_2_10x10.png"></a></div><p></p>
<p>When updating a service with <strong>docker service update</strong>, <strong>–placement-pref-add</strong> appends a new placement preference after all existing placement preferences. <strong>–placement-pref-rm</strong> removes an existing placement preference that matches the argument.</p>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/fweACvdGhMzUFCEnFIXune226" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/3/3086d7d7fa6de44562e72de4b5b7031c553b6a80.png" alt="asciicast" data-base62-sha1="6VhOKZd2TncayFH5nUadGhnl4bu" width="664" height="500"></a></p>
<h3>Sketch how a Dockerized application communicates with legacy systems</h3>
<blockquote>
<p>Required read <a href="https://docs.docker.com/config/containers/container-networking/" rel="noopener nofollow ugc">Container networking</a></p>
</blockquote>
<h3>Paraphrase the importance of quorum in a swarm cluster</h3>
<h4>Maintain the quorum of managers</h4>
<p>If the swarm loses the quorum of managers, the swarm cannot perform management tasks. If your swarm has multiple managers, always have more than two. To maintain quorum, a majority of managers must be available. An odd number of managers is recommended, because the next even number does not make the quorum easier to keep. For instance, whether you have 3 or 4 managers, you can still only lose 1 manager and maintain the quorum. If you have 5 or 6 managers, you can still only lose two.</p>
<p>Even if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.</p>
<p>See <a href="https://docs.docker.com/engine/swarm/admin_guide/#recover-from-losing-the-quorum" rel="noopener nofollow ugc">Recovering from losing the quorum</a> for troubleshooting steps if you do lose the quorum of managers.</p>
<blockquote>
<p>Required read <a href="https://docs.docker.com/engine/swarm/admin_guide/#add-manager-nodes-for-fault-tolerance" rel="noopener nofollow ugc">Add manager nodes for fault tolerance</a></p>
</blockquote>
<h4>Recover from losing the quorum</h4>
<p>Swarm is resilient to failures and the swarm can recover from any number of temporary node failures (machine reboots or crash with restart) or other transient errors. However, a swarm cannot automatically recover if it loses a quorum. Tasks on existing worker nodes continue to run, but administrative tasks are not possible, including scaling or updating services and joining or removing nodes from the swarm. The best way to recover is to bring the missing manager nodes back online. If that is not possible, continue reading for some options for recovering your swarm.</p>
<p>In a swarm of N managers, a quorum (a majority) of manager nodes must always be available. For example, in a swarm with 5 managers, a minimum of 3 must be operational and in communication with each other. In other words, the swarm can tolerate up to (N-1)/2 permanent failures beyond which requests involving swarm management cannot be processed. These types of failures include data corruption or hardware failures.</p>
<p>If you lose the quorum of managers, you cannot administer the swarm. If you have lost the quorum and you attempt to perform any management operation on the swarm, an error occurs:</p>
<pre><code class="lang-bash">Error response from daemon: rpc error: code = 4 desc = context deadline exceeded
</code></pre>
<p>The best way to recover from losing the quorum is to bring the failed nodes back online. If you can’t do that, the only way to recover from this state is to use the <strong>–force-new-cluster</strong> action from a manager node. This removes all managers except the manager the command was run from. The quorum is achieved because there is now only one manager. Promote nodes to be managers until you have the desired number of managers.</p>
<pre><code class="lang-bash"># From the node to recover
docker swarm init --force-new-cluster --advertise-addr node01:2377
</code></pre>
<p>When you run the <strong>docker swarm init</strong> command with the <strong>–force-new-cluster</strong> flag, the Docker Engine where you run the command becomes the manager node of a single-node swarm which is capable of managing and running services. The manager has all the previous information about services and tasks, worker nodes are still part of the swarm, and services are still running. You need to add or re-add manager nodes to achieve your previous task distribution and ensure that you have enough managers to maintain high availability and prevent losing the quorum.</p>
<h3>Demonstrate the usage of templates with docker service create</h3>
<blockquote>
<p>Required read <a href="https://docs.docker.com/engine/reference/commandline/service_create/#create-services-using-templates" rel="noopener nofollow ugc">Create services using templates</a></p>
</blockquote>
<h4>Demo</h4>
<p><a href="https://asciinema.org/a/zZnpejurCS7bE7F5BQUobLHVo" rel="noopener nofollow ugc"><img src="https://0x00sec.s3.amazonaws.com/original/2X/0/0b60f98e1293fdcb796a793ae27f60814812b281.png" alt="asciicast" data-base62-sha1="1CF1e1v5l0r6trlMiqAEmktKYhj" width="664" height="500"></a></p>
<h2>Sources</h2>
<ul>
<li><a href="https://github.com/DevOps-Academy-Org/dca-prep-guide" rel="noopener nofollow ugc">Docker Certification Associate preparation guide - a list of resources to help you prepare for a successful certification</a></li>
<li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/" rel="noopener nofollow ugc">Create a Docker Swarm cluster</a></li>
<li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/add-nodes/" rel="noopener nofollow ugc">Add nodes to the Docker Swarm cluster</a></li>
<li><a href="https://docs.docker.com/engine/reference/commandline/run/#parent-command" rel="noopener nofollow ugc">Docker run</a></li>
<li><a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#services-tasks-and-containers" rel="noopener nofollow ugc">Docker services</a></li>
<li><a href="https://docs.docker.com/engine/swarm/swarm_manager_locking/" rel="noopener nofollow ugc">Lock you swarm to protect its encryption key</a></li>
<li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/" rel="noopener nofollow ugc">Deploy a service to the swarm</a></li>
<li><a href="https://docs.docker.com/engine/swarm/swarm-tutorial/inspect-service/" rel="noopener nofollow ugc">Inspect a service on the swarm</a></li>
<li><a href="https://docs.docker.com/engine/reference/commandline/service_scale/" rel="noopener nofollow ugc">Service scale</a></li>
<li><a href="https://docs.docker.com/engine/swarm/services/#publish-ports" rel="noopener nofollow ugc">Swarm publish ports</a></li>
<li><a href="https://docs.docker.com/engine/swarm/services/#connect-the-service-to-an-overlay-network" rel="noopener nofollow ugc">Connect the service to an overlay network</a></li>
<li><a href="https://docs.docker.com/engine/swarm/services/#give-a-service-access-to-volumes-or-bind-mounts" rel="noopener nofollow ugc">Give a service access to volumes or bind mounts</a></li>
<li><a href="https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/#replicated-and-global-services" rel="noopener nofollow ugc">Replicated and global services</a></li>
<li><a href="https://docs.docker.com/engine/swarm/services/#placement-constraints" rel="noopener nofollow ugc">Placement constraints</a></li>
<li><a href="https://docs.docker.com/engine/swarm/admin_guide/#maintain-the-quorum-of-managers" rel="noopener nofollow ugc">Maintain the quorum of managers</a></li>
<li><a href="https://docs.docker.com/engine/swarm/admin_guide/#recover-from-losing-the-quorum" rel="noopener nofollow ugc">Recover from losing the quorum</a></li>
</ul>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/dca-orchestration/16171">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/dca-orchestration/16171</link>
          <pubDate>Wed, 11 Sep 2019 14:34:17 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-16171</guid>
          <source url="https://0x00sec.org/t/dca-orchestration/16171.rss">[DCA] Orchestration</source>
        </item>
        <item>
          <title>[DCA] Docker Certified Associate</title>
          <dc:creator><![CDATA[Nitrax]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Hi fellas,</p>
<p>I’m currently preparing my Docker associate certification, I thought it would be a good idea to share resources with you guys. Even if the Docker documentation is well explained and straightforward, information concerning the certification is still spread into dozens of pages which could be tedious to manage.</p>
<p>It is important to note that I only aggregated information that I found over the Internet. I did not write any content that will be posted further on.</p>
<p>Below are the subjects approached in the certification as well as their grade weight.</p>
<ol>
<li>
<p><a href="https://0x00sec.org/t/dca-orchestration/16171">Orchestration (25%)</a></p>
</li>
<li>
<p>Image creation, management, and registry (20%)</p>
</li>
<li>
<p>Installation and configuration (15%)</p>
</li>
<li>
<p>Networking (15%)</p>
</li>
<li>
<p>Security (15%)</p>
</li>
<li>
<p>Storage and volumes (10%)</p>
</li>
</ol>
<blockquote>
<p>The table of contents above will be updated alongside my prep progression. Stay tuned</p>
</blockquote>
<p>Such technology may not be your main goto area however, keep in mind that increasingly services are shipped this way. Improving your knowledge about Docker could be very helpful for post-exploitation scenarios. <img src="https://0x00sec.org/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"></p>
<p>Hope you will enjoy this series.</p>
<p>Best,<br>
Nitrax</p>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/dca-docker-certified-associate/16170">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/dca-docker-certified-associate/16170</link>
          <pubDate>Wed, 11 Sep 2019 14:27:35 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-16170</guid>
          <source url="https://0x00sec.org/t/dca-docker-certified-associate/16170.rss">[DCA] Docker Certified Associate</source>
        </item>
        <item>
          <title>My Personal OSINT Techniques, Volume 2: The Kitchen Sink</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><strong>PLEASE NOTE:</strong> <em>While the first half of my OSINT release was more geared toward hacking, Red Teaming and penetration testing, I have also endeavored to make this release more valuable to others who utilize OSINT.</em></p>
<p><em>If while reading this you decide it is not applicable to your particular needs where  OSINT is concerned, then please jump to the last section.</em></p>
<p><em>At the very least, I can provide you with new resources that allow you to find almost anything that exists on the Internet.</em></p>
<p><em>I have had many opportunities to use OSINT in an investigative manner closer to the usecases present in other professions/pursuits; this has mostly occurred on occasions where I have worked the defensive side of things.</em></p>
<p><em>While the content herein may be flavored with some offensive security terms, I have endeavored to make sure the content is (at worst) broadly applicable with a little work.</em></p>
<p><em>For instance, this first section uses words/images to detail how I once used a web developers CMS as a means of OSINT.</em></p>
<p>*This CMS (and all I detail concerning it) could have been found simply (and in a way that I don’t believe to be implicitly illegal) with a web browser via Search Engine dorking against any of the employee email addresses that were present.</p>
<p><em>While an investigator may not have accessed the emails present for legal/ethical reasons, if you were investigating one of these employees, could some of these things that were in plain sight on different pages be helpful to your investigation:</em></p>
<p><em>1. Access to months worth of your target’s past/present/future work schedule; for example,  their work days/hours on or off and the physical work location they would be at.</em></p>
<p><em>2. Employee information: position at the company and contact information such as multiple work phone numbers, multiple personal phone numbers, personal email addresses and other business email addresses.</em></p>
<p><em>3. Months worth of their past/present/future activities/scheduling  via their business calender.</em></p>
<p><em>4. Similar information belonging to their co-workers.</em></p>
<p><em><strong>And finally, the contents of this release uses one idea to introduce many others; while one of the main concepts we will cover surrounds what I call “archives”, this writing will review many OSINT related sources, techniques,  thoughts and tools that can be a means to an end by themselves.</strong></em></p>
<p><em><strong>One concept may be the trunk of this tree, but it is not its roots, leaves, fruit or branches</strong></em>.</p>
<p><strong>The Kitchen Sink</strong></p>
<p>During my career as a professional hacker (which encompasses penetration testing, Red Teaming and Bug Hunting), most of the targets I have found myself engaging have consisted of companies and organizations.</p>
<p>Through targeting these entities, I often end up targeting individuals as a means to attack a company or organization.</p>
<p>In my experience, a huge portion of the OSINT that can be found on the Internet originates from companies/organizations trying to generate, maintain and facilitate commerce; the processes and materials involved in doing so manifest themselves as forms/methods of communicating that produce OSINT.</p>
<p>The best type of information you can gain to exploit (or investigate) a target is almost always going to be the information a target provides about themselves (especially an unsuspecting target).</p>
<p>However, often much of the most visible information a target puts on the Internet is heavily subjective, especially if that information is closely related to things like commerce (money).</p>
<p>Or, at the very least, the hint/involvement of things like commerce should be a concern when analyzing/reviewing OSINT.</p>
<p>Having to deal with material that may be heavily subjective can lessen the value OSINT can provide during an engagement/operation (or investigation): the presence of subjectivity further burdens processes of analysis/review.</p>
<p>As we covered in Part One, OSINT already tends to require greater logistical resources  then other forms of reconnaissance/enumeration utilized during an engagement/operation, especially since most engagements/operations won’t have the resources/logistics available that most processes for utilizing/processing OSINT assume.</p>
<p>There is a way to circumvent many of the issues that a  large percentage of OSINT may present while maximizing the advantages/resources it can provide: by targeting what I call “archives”.</p>
<p>To put it another way: we want to skip talking to the illusion the Wizard of OZ used to represent himself and jump right to pulling back the curtain, thereby more quickly/efficiently revealing the truth of the man hidden behind it.</p>
<p>Archives are large caches of data that can be publicly accessed on the Internet and tend to much more objective in nature but no less (and often more) information rich; they tend to a wealth of material that target’s are willing to make publicly accessible, though they do not want them overly visible.</p>
<p>Or perhaps the target has forgotten about the archive or access to the archive…</p>
<p>Archives are often maintained by the target (or sources that can be tied to the target) for internal use by employees or customers/clients, thereby circumventing much of the hyperbole and subjective nuances that can reduce the value of OSINT by adding time/energy to the processes necessary to convert it to relevant, actionable/applicable intelligence.</p>
<p>Better yet, searching for archives often uncovers other rich sources of OSINT other than archives.</p>
<p>What I call archives can exist in all number of forms; what they have in common is that they are publicly accessible and contain multiple pages/directories of content.</p>
<p>Often, target archives sit on some out of the way subdomain in order to assure ease of access for internal/in-house employees and assure that customers/clients and/or outsourced help can access them.</p>
<p>Sometimes archives are found in the form of open web directories or web servers of every type (such as publicly accessible FTP directories/servers).</p>
<p>Or web pages/directories with content that was not meant to be publicly accessible, but is, because it was rendered in another form (.XMLs are outstanding in this regard).</p>
<p>An archive could be made up of many documents on a target’s webpages that they thought to hide via complex directory/file names.</p>
<p>Sometimes these archives are comprised of logs created by messaging solutions (IRC, Slack, etc.) used by developer/engineer teams and/or something like commit histories (usually with a fair amount of conversation/debate) used by international teams of developers/engineers.</p>
<p>And as was the case in the archive shown in Part 1, these caches of material have often broken engagements or some phase of an engagement wide open for me…</p>
<p>The employees responsible for the archives and/or storing the material within them often did or do not have Information Security training or awareness; thus, it is not unusual to find archives that contain material perfect for building a social engineering campaign (internal email/document templates, contact information not otherwise available publicly, employee/customer/client personal identification data, etc.), PAC files, certificates, material containing valid credentials and/or providing insider knowledge of the configurations of network hosts/appliances/defenses…</p>
<p><strong>An example of an unconventional archive</strong></p>
<p><em>During an external penetration testing engagement, a web development company doing work on the target’s IP space made some mistakes that allowed me to access an OSINT rich archive.</em></p>
<p><em>The archive was found via manual searching the target’s IP space with a technique that will be discussed a bit later in this release.</em></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/f318ec3f362ad01a9314fca74de5d73361c5602d.png" alt="OC0A" data-base62-sha1="yGxqb9yIuo65t9pq4Ke6KuEgFw9" width="690" height="276"><br>
<em>Configurations that were put in place by the web development company (for the convenience of the web development company) rendered  everything seen in the images within this section publicly accessible with Administrator rights, including all of the resources that comprised the web dev provider’s Content Management System (CMS).</em></p>
<p><em>This archive provided considerable data that could have been used against either of the companies or any of the employee’s involved in this project, as I had full view of the day to day operations involved in the project the CMS was established to undertake (employee calenders which included scheduling, emails, ticketing system, tasks underway/completed, etc.).</em></p>
<p><em>Quite a bit of OSINT relevant to the web development company, it’s employees and our mutual client could be downloaded via the Media Center option or otherwise accessed via the “Manage Files” option; the contents of either could have had valuable metadata stripped from the content present there.</em></p>
<p><em>Further testing showed that this archive could have been found through other means, like Search Engine Dorking vs. email addresses belonging to web development company employees that were included in certain sections of the CMS</em>.<br>
<img src="https://0x00sec.s3.amazonaws.com/original/2X/0/09251d40e3806bdefcf63b21ee77308be47150e6.png" alt="ocz" data-base62-sha1="1iTOtLa6QfmMpRLJABxEXNYel2C" width="690" height="297"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/1d91fd7d551d5e0ba916c70681b2412c433faaf7.png" alt="ocy" data-base62-sha1="4dAD0BH9DMOujwV5Bqb414OVgUf" width="690" height="426"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/ec3f54b5a591e70f4800748db174150d5256af9c.png" alt="ocz1" data-base62-sha1="xHWmRQqlnMXHhRcmcgy0pj0unKI" width="690" height="332"><br>
<em>This yielded quite a bit of OSINT that could have been used against our mutual client and the web development company itself…</em></p>
<p><em>I could read some of the web dev provider’s internal emails to/from our mutual client and between the web development company’s employees who were working on this project</em>.</p>
<p><em>Also, I could access employee information belonging to all 11 of the web development company’s employees (which included some private/personal information for 7 of the employees via the “View Profiles” tab) working on this project, including the Sales staff involved.</em></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/79bccfd2cd29806dc4ffd5cf19a291ef8afb5517.png" alt="OcXX" data-base62-sha1="hmWiGr4wwyrXgTiIyQfuXJRUtcb" width="690" height="317"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/b0829d9742b23dd71d89c547bc7b5fa145379bbe.png" alt="oc0" data-base62-sha1="pbtSoL0IdaojafGJMFi8td4kv4a" width="690" height="270"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/6/64bf2e0bfc5183993b6735b479469c78fcfec761.png" alt="oc5" data-base62-sha1="enflzOQQK6SXHKNg5R1znwCajYZ" width="688" height="306"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/13136b212f818a1592d8538965a05a669c4f5e74.png" alt="oc1" data-base62-sha1="2IKFTT7jXLMKjt5XQk0dsmefeBu" width="690" height="310"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/b92a4a46869abe37042da52ebb11792de41e6e62.png" alt="oc2x" data-base62-sha1="qq2WaAcE5bfzUzidGbGmadBOBpw" width="690" height="297"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/6/648b37e64b397ecee6e671cb1f635a400944a7ef.png" alt="OC3x" data-base62-sha1="els1iJ4rVaZPwq5p6dVQ1HgxzLF" width="690" height="383"><br>
<img src="https://0x00sec.s3.amazonaws.com/original/2X/5/58d0642b04947912bf816b310a5203888e95780a.png" alt="oc4x" data-base62-sha1="cFGuBDbJ92iGcXhwB1juvvj2PlE" width="690" height="299"><br>
<em>The CMS also allowed me to access completed email and invoice templates the web development company had been contracted to create for our mutual client.</em></p>
<p><em>Along with the other data the CMS provided, these templates would have been the perfect finishing touch to add extra potency to social engineering attacks toward exploitation or fraud vs. either of the companies concerned.</em></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/5/5b9468453b2a45248d922f043d3db6055c2b33a7.jpeg" alt="oc2" data-base62-sha1="d49ptSpYRAY1hJFN8d26odThh4z" width="690" height="210"></p>
<p>As I mentioned in Part 1 of this release, by accident or on purpose, the majority of companies I have engaged had some manner of OSINT rich archives sitting somewhere on the Internet, publicly available.</p>
<p>Most of the attacks I conduct have a limited duration, which means I cannot spend forever looking for just these archives.</p>
<p>Fortunately, I have developed some processes to locate these and other sources of valuable intelligence as I do other things throughout all phases of an engagement, even outside of prescribed/formal reconnaissance/enumeration phases.</p>
<p>As early as possible during an engagement, I run multiple automated tools against the target’s root domain, as these require no extra attention on my part and allow me to undertake more manual methods/means of reconnaissance/enumeration.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/1b92f60bd8a11c6d62762b7d5511ec35ea130bf1.jpeg" alt="passiveadvantage" data-base62-sha1="3VVKM5zyBCzdA1Kz82IXUjDxitr" width="690" height="229"><br>
<strong>Image above:</strong> <em>Pagodo automated dorking, Datasploit and Spiderfoot all running on the same machine during an engagement. As the resources necessary to run these separately or individually are not overly taxing on a machine (<strong>I run Spiderfoot continually throughout an engagement, often in combinations with other automated tools such as Pagodo and Pymeta, using a 512 ram Dell Dimension Desktop from 2004</strong>), multiple instances can be deployed fairly quickly if need be, yielding quite a bit of invaluable information concerning a target vs. very little logistical cost in comparison.</em></p>
<p>These tools include Spiderfoot, OWASP Amass, Pymeta and Pagoda vs a root domain, which help establish what I call “Passive Advantage”: these tools are enumerating the target without any extra energy/attention investment on my part past starting the tools (and depending on the engagement/operation, starting/establishing means to obfuscate these tools).</p>
<p>This allows me to work manual methods of reconnaissance/enumeration while exponentially furthering the pool of available information I can use toward exploiting the target throughout the engagement/operation.</p>
<p>I keep running tools that help me to establish Passive Advantage throughout the engagement; as we move past the reconnaissance/enumeration proper phases, I use these tools to refine/isolate targets/possible targets of interest while I work my manual techniques.</p>
<p>For example, the reconnaissance/enumeration phases proper may see Passive Advantage tools run against a root domain, then run against a subdomain that is found as I manually search other domains/subdomains, then these tools may be run against an email address or document/hash/filename found on the subdomain as I search it manually, etc.</p>
<p>We will assume/imagine these tools for establishing Passive Advantage are running  while we will start out covering manual enumeration of Archives first.</p>
<p><strong>Manual Enumeration of Archives</strong></p>
<p><strong><a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a>: an OSINT source &amp; a source for finding OSINT</strong></p>
<p>While I have all manner of automated reconnaissance/enumeration tools running, one of the first resources I often use to begin manual enumeration of a target is <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a>, which keeps a huge archive of over 1.5 million email addresses, many of them internal/corporate email addresses; even a free account can give you access to hundreds of a target’s emails.</p>
<p>Corporate/internal email addresses have a huge quantity of value; for instance, just at base value, corporate/internal email addresses often double as the user/username component of a set of credentials…</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/b559adcf746c516730188e33b7f756f8122da78d.png" alt="hunterio1A" data-base62-sha1="pSiyCwoTs6v3iZr7WrhqlqwiW4Z" width="690" height="351"></p>
<p><strong>Above:</strong> <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> lets you search for companies with an autofill/autosearch like capacity and will enumerate their email address naming conventions (if they find they have the target’s name incorporated in this option).</p>
<p><strong>Below:</strong> The target didn’t appear via the automatic search option, so I ran the target’s root domain name in <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a>’s search bar, which enumerated 434 of the target’s internal/corporate email addresses with a free account.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/15af8a669e38a6f1cbbd5e5ebdc69189cdc403b2.png" alt="hunterio2" data-base62-sha1="35Q7uTEeUwvOtOwc6BNGBNsdqfM" width="690" height="186"></p>
<p><strong>Below:</strong> The real value of <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> is not in the collection of e-mail addresses; tools like Harvester do that as well, though it is a bit more labor intensive (and you may find value in running tools like that as well as using <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a>).</p>
<p>I find the real value of <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> rest in it’s quantification  and indexing of these addresses.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/1e9b2dd3301870cfac39485d8a31638b1d498ef8.png" alt="hunterio3" data-base62-sha1="4mKNcA3p04RHrJU6UXH9YZfhOAM" width="690" height="327"></p>
<p>For instance, <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> has broken down the most common naming convention used by the target for all email addresses.</p>
<p>The email addresses listed for a company/organization are usually divided under different generic departmental classifications; an individual employee’s placement under each classification are usually based off the individual employee position/job title <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> has enumerated (which from my experience, tend to be accurate).</p>
<p>These classifications can seriously help with target designation and further targeted recon/enumeration; for instance, the image above has fields like “Communication”, “Marketing”, “Human Resources”, etc.</p>
<p><strong>Below:</strong> Each email has the target employee’s full name, job title, a designation whether <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a> has verified the e-mail or not (green check and shield).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/ee39a6828c976aa9bc0ebdd5f5fe8cc24b27addf.png" alt="5" data-base62-sha1="xZr9vPDD3qlo6sjd2z8xNam5esD" width="690" height="131"></p>
<p><strong>Below:</strong> Most importantly a “Sources” tab showing where the e-mail address was located (and possibly verified).</p>
<p>This is exceptionally useful as it often provides many instances of OSINT and other domains/subdomains that could be sources for OSINT, some of which include blogs this employee has written (and likely the location of other blogs written by the target company’s other employees).</p>
<p>For example, this particular employee had blog entries and articles concerning them on sites belonging to the target company and a university, both of which were dated in the same years.</p>
<p>The dates are helpful for quantifying many things: for instance, it can help  estimate how long the employee has been working for the company or how long they have been involved with other organizations relating to their profession; these dates can also help establish the target’s importance/stature within both companies and/or organizations which they are involved with.</p>
<p>The “Sources” tab sometimes links to personal pages belonging to employees as well.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/f466a8d2a86fa193ac0bb2dd8ab532f6dae6434e.png" alt="hunterio4a" data-base62-sha1="yS4rSyLKPtSk1A0MIooIYmDxFBc" width="690" height="469"></p>
<p><strong>Below:</strong> The instances marked “removed” can lead to especially valuable instances/resources of OSINT, as they sometimes denote sensitive or problematic resources that the company or employee have attempted to remove; these could possibly be found by resources like the Wayback Machine.</p>
<p>They also sometimes lead to subdomains the individual’s employer have abandoned but that are still Internet accessible; this sometimes happens because the individual was employed by an entity acquired by the target company.</p>
<p>The company also acquires the domain space of that entity and incorporates it as a subdomain under their own IP space, but does not maintain it…this can present a resource containing sensitive data and/or vulnerable infrastructure.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/8/83feeff347a2692c94b2dddd2593d4442282e4ea.png" alt="hunterio5" data-base62-sha1="iPGKsgeurXgWKDEPmvUvrCL5s94" width="690" height="175"></p>
<p>I will often start looking for archives using <a href="http://Hunter.io" rel="noopener nofollow ugc">Hunter.io</a>’s classification scheme to locate the IT/Developer/Engineer (technology) based employees and look through the instances listed under the “Sources” tab.</p>
<p>My techniques for attempting to discover archives generally start with attempts to  leverage aspects/facets of the target’s technical/technological resources.</p>
<p>This usually starts with my leveraging aspects of the target’s technological/technical employees: applying search techniques or web based resources that leverage email addresses, names, unique/unusual job positions or titles belonging/related to positions encompassing Developers, Engineers and IT.</p>
<p>If that fails, my search techniques and/or  resources will leverage technology/technical related words/terms that seem unique to the target: examples include hardcoded/default username/password/credential sets I haven’t seen before, the name of some technical component, a serial number, a hardcoded IP and/or MAC address.</p>
<p>There are many reasons for this, but the main two are:</p>
<ol>
<li>Most of the company/organization archives I have found contain (or were established to store) some quantity of technical/technological resources…finding these archives often means utilizing Search Engines for things like Dorking or the Search functionality of various web based resources.</li>
</ol>
<p>Utilizing searches that leverage technological/technical based terms/words/employees raises the probability of finding archives or other worthwhile resources (the second reason is very much entwined with this probability).</p>
<ol start="2">
<li>Searching against a target’s technological/technical resources (that aren’t things like a popular product or an employee with a high public profile) often find fewer, but much more relevant, indexed Search Browser results.</li>
</ol>
<p><strong>Websites as Archives</strong></p>
<p>Sometimes, targets have material on their websites that they try and place in out of the way directories, often using complex naming conventions.</p>
<p>Or, the content may not have been placed with any special degree of cunning, but the web presence of that company/organization is spread across multiple sites/domains/subdomains.</p>
<p>Also, if a company/organization is your target or an individual you are targeting has a special attachment/relationship with a company/organization, then it is worth searching the website(s) of that entity, but you may want to gain an overview of the content of each site to gauge whether it is worth your time to search, or how much time is worth investing in searching.</p>
<p>These techniques accomplish all of those goals and can yield a solid quantity/quality of OSINT that may not be one solitary cache of material.</p>
<p>As shown in the example in the first section detailing the web developer’s CMS, one of the tools I utilize for these tasks is Firefox Browser equipped with the Link Gopher extension.</p>
<p>Link Gopher will show you all of the links present on a webpage, most of the links available on a website and all of the sites connected by links to the website/webpage.</p>
<p>When I say “links”, I mean that Link Gopher will show you the URL for, and allow you to access, the media (PDFs, JPEG, PNGs, XLS, TXT, etc.), other web pages/websites, domains/subdomains and other content on a webpage/website.</p>
<p>In the past, I used DownthemAll and Foxyspider with Link Gopher in Firefox, but they only work on older versions of Firefox unless you work some code; I have always found their results to be so similar that I do not usually bother getting DownthemAll or Foxyspider operational anymore, just Link Gopher as it works with both the newest versions of Firefox and slightly older instances of Firefox ESR.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/c/cf281e553df80546e82c63143f5d0612a4de5893.png" alt="LINKGOPHERAX" data-base62-sha1="tyAMYaLTiYUvbgWYxzMQCix9Pbl" width="622" height="500"></p>
<p><strong>Image Above</strong>: Searching a target company/organization website with Link Gopher leads to a another website belonging to the target company/organization where almost 1400 media files existed.</p>
<p>Many of these were company business documents/presentations/internal documents and many instances of what amounted to employee resumes: PDF’s (note names like Stephen, Peter, Lilian, etc.) that were meant to introduce an employee to a prospective client/company and establish their expertise.</p>
<p>These PDFs including things like extensive bios, contact information, personal anecdotes, professional experience, educational experience and interests.</p>
<p>The Link Gopher image above led directly to the links in the image below via a URL to another webpage.</p>
<p>Throughout the target company’s websites, webpages presented similar extensive background information about employees of every type throughout the company.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/0/066844677706398fd733a51bda6a378dae142c73.png" alt="LinkGopher2Z" data-base62-sha1="UGfT7R2WdFZcrgrMftaf43MYLN" width="690" height="374"></p>
<p>These links lead to full or partial biographies and career highlights teaming with OSINT, all of which include information similar to what appears in the image below, some of which are surrounded in the thick red rectangle (these webpages also included images of the employee).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/b2707592839d54e7745d0e9c240c47a1258dc1c9.png" alt="LINKGOPHER3Z" data-base62-sha1="psxVOWBb8htXHToXmRH2l3zTd0Z" width="685" height="497"></p>
<p><strong>Image Below:</strong> Other webpages contained thousands of documents covering all manner of the target company’s internal business matters; notice the randomized numbers, whereas trying to access “<a href="https://www.targetcompany.net/document/" rel="noopener nofollow ugc">https://www.targetcompany.net/document/</a>” directory itself only showed a 404 error message.</p>
<p>In other words, the full URL would have to be known and/or accessed via a fully, correctly formed link to get access to these documents.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/b09f70bb27ec040f886a207bff5f9dca202b80c4.png" alt="Linkgopher4a" data-base62-sha1="pctDjOf1ubS4AlULIvPddIuHajW" width="625" height="500"></p>
<p><strong>Image Below:</strong> Accessing a website/webpage full of the target company’s media, notice the Social Media URLs with the red redactions; these represent social media accounts belonging to the target.</p>
<p>Link Gopher does not repeat the same links; thus, repeat links are different accounts, with the red redactions in these instances likely representing different usernames used by the target for their Social Media.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/bf226feb3e3401622bb39a9809335ec2985ea1a3.png" alt="LinkGopher6" data-base62-sha1="rgQYE7Q2lwptJQ2wM9gvWyaQ2wr" width="635" height="500"></p>
<p><strong>Web Based Resources useful in locating Archives and other sources/instances of OSINT</strong></p>
<p><strong><a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a></strong></p>
<p><a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a>  (<a href="https://urlscan.io/" rel="noopener nofollow ugc">https://urlscan.io/</a>) is an invaluable tool for gathering OSINT; the two most basic functions it provides are:</p>
<ol>
<li>
<p>A scanning option that can be run against web-based resources to generate an exhaustive analysis of the target; this analysis is almost unparalled in it’s thoroughness and is easy to interactive with/navigate.</p>
</li>
<li>
<p>The ability to search all past scans/analysis the site and it’s users have generated, which (if memory serves me), numbers into the millions.</p>
</li>
</ol>
<p>Where gathering OSINT is concerned, this option to search against the site’s past results tends to gain a slight edge in the value department; this is due to the extra versatility this functionality allows.</p>
<p>Whereas generating new analysis with <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a> tends to be restricted to scanning URLs or domain names, the site’s huge archive of historical analysis can be searched against domains, IPs, filenames, hashes, or ASNs.</p>
<p>Perhaps you’ve found files belonging to the target elsewhere on the Internet; the names of these files appear to consist of random characters in no particular order, with file names much more closely resembling 3114xz7!.PDF then Apache.PDF.</p>
<p>So you search all past analysis generated by <a href="http://URL.io" rel="noopener nofollow ugc">URL.io</a>’s many users against the filenames with the seemingly random ordering/collection of characters (lthose more closely resembling 3114xz7!.PDF).</p>
<p>I have found plenty of target resources utilizing <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a>’s “Search” option (image below within the red square) with this and similar strategies; these resources have included  many variety of archives &amp; BlackHat infrastructure (whether rented or exploited) .</p>
<p>Searching in this way has caused <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a> to provide me with access to a target’s email server to before…</p>
<p><strong>Image Below:</strong> I utilize the “Search” option (surrounded in the red box) against a PDF file that was named with a random string of numbers, resulting in 29 different matches to past scans/analysis having been found (one of them is shown, redacted).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/3/39ec07bb06ead5977d61b53580d157cbf3bb9aa2.png" alt="URLSCANA" data-base62-sha1="8goUj36VPER3o3p6jNAwmYGE2tQ" width="690" height="262"></p>
<p>The first page is an extensive overview of identification data surrounding the URL in question, with the data here usually representing the entire website; the page includes any additional scans of this URL/website and an extensive listing of stored scans of websites that seem similar to this (you will often find stored scans for other websites/domains/subdomains belonging to the same target here).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/fb484324c04f342bc0a5ea3f46a309b9d0bfe064.png" alt="URLSANX1" data-base62-sha1="zQWFjgyJcxbk2a9sKfPhqYozIZ6" width="690" height="344"></p>
<p>Much of the OSINT I will discuss now would be especially helpful for use during triage/remediation of a security incident (perhaps you just search the URL or domain name in this instance).</p>
<p><strong>Image Below:</strong> The “Submission” establishes when this scan occurred and what country of origin made the request (though obfuscation may be in play)…should information herein  be helpful in discovering a source of compromise, this date/time will be helpful in establishing a timeframe of occurrences/events.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/e0ca2682cee0a84c3664a8bd43a303493682f149.png" alt="urlscanz2" data-base62-sha1="w4A3DAIx0FYXJg4iZPEIsy9Jrcd" width="690" height="259"></p>
<p><strong>Image Below:</strong> We see more identification information for the website/domain in question under “Live Information”.</p>
<p>“Domain &amp; IP Information” could be especially helpful in quantifying possible sources of an attack during incident response, as it thoroughly documents/defines every IP that <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a> has detected connecting to this IP or issuing a redirect.</p>
<p>This includes the number of redirects/connects detected and considerable information fully defining those hosts that can be viewed through multiple filters: IP Details, Subdomains, Domain Tree, Links, Certification (plus other information that is shared once one of these filters is chosen).</p>
<p><strong>Remember that <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a> could be used to investigate any of the IP connecting to this host, which could also allow you to investigate other hosts connecting to that host…combined with other data available here (such as the data under the HTTP tab), <a href="http://URLscan.io" rel="noopener nofollow ugc">URLscan.io</a> could allow investigators to defeat attempts at obfuscation and help ensure more accurate attribution.</strong></p>
<p>“Stats” section provides various connection related data, which could be useful in more quickly deducing that there is an issue or what the issue could be (example: if this was a host with an extremely limited usecase within your network, hundreds of requests in a short period could be an issue worth investigating).</p>
<p>“Detected Technologies” could make you aware of technology that has been added to a host without you or your team’s knowledge; if surrounding hosts have been compromised and this host now has analytics software common in traffic monetization installed, there could be a high probability this host has also been exploited.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/c/cbba6e8fbd10df7977fda2ee6d39c5183d0be1a2.png" alt="urlscan4z" data-base62-sha1="t4gm0tL4el13ymOhwrVpjn9XvNM" width="690" height="429"></p>
<p><strong>Image Below:</strong> HTTP Transactions allows you to look at the actual code that was involved in most of the HTTP traffic (including redirects) that URLscan detected this website/domain/host participating in.</p>
<p>In the past, this has allowed me to locate malware that was in play but had yet to be discovered or suspected.</p>
<p>Since the IP/network information surrounding every host involved is so well defined, the HTTP Transactions tab has allowed me to track down redirecting malware and/or malware calling it’s components from multiple other sites ( this tab has also helped me detect credentials that were being moved through a host on route to another host thanks to malware present).</p>
<p>Since these are real time captures of actual traffic that occurred, I have been able to find credentials of many sorts via the “Show response” option  (tokens, usernames/passwords in transit, etc.); this tab has also helped me to identify vulnerabilities present on a host or the surrounding network.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/fc75d6941f44a78e19fa5f67ee620e622a269b37.png" alt="urlscan7z" data-base62-sha1="A1mMXI7NZTMCgkNywmYnFMERoGj" width="690" height="422"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/fc2b432b9542f360310d4d4b79e530df6cb813a4.png" alt="URLscan8x" data-base62-sha1="zYN0Jico7UvLuuIxXRv6RwCBrYU" width="690" height="362"></p>
<p><strong>Image Above:</strong> The “Links” tab shows all of the links present on this website, including the target’s Social Media links with what are likely usernames and post/session identifiers, both redacted in red.</p>
<p>The “<a href="http://resources" rel="noopener nofollow ugc">http://resources</a>” links that are partially redacted in black led to another website/domain/subdomain that contained media meant for internal company and customer/client communications/distribution.</p>
<p>There is much more that <a href="http://URL.scan.io" rel="noopener nofollow ugc">URL.scan.io</a> can be utilized for OSINT wise, such as locating/investigating hashes that may be tied to the compromise of a host under the “IOC” tab, or the investigation of web based content under the “DOM”, “Content” and “API” tabs (these regularly provide the same depth of information (or more) than  HTTP Transactions do: malware, credentials, vulnerabilities, etc.).</p>
<p><strong>The Last Section</strong></p>
<p>This release has already gone overlong and I have excepted that covering my personal/favored OSINT techniques cannot be done in two volumes; it is going to have to occur over time, over multiple releases.</p>
<p>So lets end this with a few more sources in rapid order…those which have been my secret weapon for years…</p>
<p>I had seen Mamont’s Open FTP Index at <a href="http://www.mmnt.net//" rel="noopener nofollow ugc">http://www.mmnt.net//</a> mentioned in a single Reddit post on the entirety of the Internet before I tweeted about it last December.</p>
<p>You can gain a ton of OSINT from open, publicly accessible FTP sites; if a target has an open FTP site with accessible content, it will be listed here (among the many other tens or hundreds of thousands listed).</p>
<p>Mamont’s can be searched multiple ways: file names, domain names, etc…</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/704cb2fd49fc3f8b5435c96c9b6c9c7b71ad50bb.jpeg" alt="mamont" data-base62-sha1="g1rNQgDzVkxxSGxki6pBW5RbtRp" width="582" height="500"></p>
<p>And here are all the resources you will ever need to find archives online in the form of open, publicly accessible web servers:</p>
<p>There is a small sub-Reddit where the absolute kings of finding publicly accessible web directories hang out; I gift you r/opendirectories at <a href="https://www.reddit.com/r/opendirectories/" rel="noopener nofollow ugc">https://www.reddit.com/r/opendirectories/</a>…</p>
<p>I suggest you spend time at r/opendirectory regularly (while maintaining as low a profile as possible) and learn their ways; the members there often find stuff that was meant to be so private that they joke about ensuring it never leaves the sub-Reddit  (and of course, curiosity causes mass verification of these sources, which are almost always as true as they are startling); they also regularly release new sources and tools.</p>
<p><strong>Guides/sources from r/opendirectory that are worth their weight in gold:</strong></p>
<p><strong>"All resources I know related to open directories"</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/933pzm/all_resources_i_know_related_to_open_directories/" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/933pzm/all_resources_i_know_related_to_open_directories/" target="_blank" rel="noopener nofollow ugc">r/opendirectories - All resources I know related to Open Directories</a></h3>

<p>548 votes and 24 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>"Googling Open Directories"</strong><br>
</p><aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/ykhel/googling_open_directories/" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/ykhel/googling_open_directories/" target="_blank" rel="noopener nofollow ugc">r/opendirectories - googling open directories?</a></h3>

<p>66 votes and 11 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>
<p></p>
<p><strong>How To Find (Almost) Anything You Want On An Open Directory Page</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/8zcbb/how_to_find_almost_anything_you_want_on_an_open/" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/8zcbb/how_to_find_almost_anything_you_want_on_an_open/" target="_blank" rel="noopener nofollow ugc">r/opendirectories - How To Find (Almost) Anything You Want On An Open...</a></h3>

<p>102 votes and 7 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>How do I find open directories?</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/1qccxq/how_do_i_find_open_directories/" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/1qccxq/how_do_i_find_open_directories/" target="_blank" rel="noopener nofollow ugc">r/opendirectories - How do I find open directories?</a></h3>

<p>54 votes and 9 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>How are all of you finding these directories?</strong><br>
</p><aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/10xyt3" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/10xyt3" target="_blank" rel="noopener nofollow ugc">r/opendirectories - How are all of you finding these directories?</a></h3>

<p>72 votes and 8 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>
<br>
/how_are_all_of_you_finding_these_directories/<p></p>
<p><strong>How do you search for open directories?</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/opendirectories/comments/cfxw3/how_do_you_search_for_open_directories/" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/opendirectories/comments/cfxw3/how_do_you_search_for_open_directories/" target="_blank" rel="noopener nofollow ugc">r/opendirectories - How do you search for open directories?</a></h3>

<p>44 votes and 11 comments so far on Reddit</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>The Google Open Directory Search Engine</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <a href="http://palined.com/search/" target="_blank" rel="noopener nofollow ugc">palined.com</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="http://palined.com/search/" target="_blank" rel="noopener nofollow ugc">Google Open Directory Search</a></h3>



  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>File Chef: Get Direct Download Links for almost anything.</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://www.filechef.com/favicon.ico" class="site-icon" width="16" height="16">
      <a href="https://www.filechef.com/" target="_blank" rel="noopener nofollow ugc">filechef.com</a>
  </header>
  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:690/360;"><img src="https://0x00sec.s3.amazonaws.com/optimized/2X/2/2dd8d155778bde10a03d59741b49d1c6b8c9dfd5_2_690x360.jpeg" class="thumbnail" width="690" height="360" srcset="https://0x00sec.s3.amazonaws.com/optimized/2X/2/2dd8d155778bde10a03d59741b49d1c6b8c9dfd5_2_690x360.jpeg, https://0x00sec.s3.amazonaws.com/optimized/2X/2/2dd8d155778bde10a03d59741b49d1c6b8c9dfd5_2_1035x540.jpeg 1.5x, https://0x00sec.s3.amazonaws.com/original/2X/2/2dd8d155778bde10a03d59741b49d1c6b8c9dfd5.jpeg 2x" data-small-upload="https://0x00sec.s3.amazonaws.com/optimized/2X/2/2dd8d155778bde10a03d59741b49d1c6b8c9dfd5_2_10x10.png"></div>

<h3><a href="https://www.filechef.com/" target="_blank" rel="noopener nofollow ugc">FileChef - Open Directory Search Engine</a></h3>

<p>Filechef is a niche search engine, specializing in file search. It indexes millions of files found on the web and provides efficient search over them with easy to use filters. It is the largest search engine of its kind with over 200M files indexed.</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p><strong>Another small sub-Reddit where the users have considerable skills/resources where getting the  data they want is concerned.</strong></p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://0x00sec.s3.amazonaws.com/original/2X/6/62964150c1fb11c88b0ae55773ef9be4517e055e.png" class="site-icon" width="" height="">
      <a href="https://www.reddit.com/r/DataHoarder" target="_blank" rel="noopener nofollow ugc">reddit</a>
  </header>
  <article class="onebox-body">
    <img src="" class="thumbnail" width="" height="">

<h3><a href="https://www.reddit.com/r/DataHoarder" target="_blank" rel="noopener nofollow ugc">r/DataHoarder</a></h3>



  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/my-personal-osint-techniques-volume-2-the-kitchen-sink/13198">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/my-personal-osint-techniques-volume-2-the-kitchen-sink/13198</link>
          <pubDate>Tue, 23 Apr 2019 14:07:37 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-13198</guid>
          <source url="https://0x00sec.org/t/my-personal-osint-techniques-volume-2-the-kitchen-sink/13198.rss">My Personal OSINT Techniques, Volume 2: The Kitchen Sink</source>
        </item>
        <item>
          <title>Essay - Images, Video &amp; Thoughts: Professional Hacker, 2011 to Present</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><em>Note: Multiple edits for typos (the ghost of a learning disability mostly overcome) and additional image upload occurred between 21:10 EST, 9/30/18 &amp; 22:23 EST 9/30/18</em></p>
<p>Last year I released the essay Shared thoughts after 6+ years in pentesting: (<a href="https://0x00sec.org/t/shared-thoughts-after-6-years-in-pentesting/2492/25" class="inline-onebox">Shared thoughts after 6+ years in Pentesting</a>).</p>
<p>I decided that every year I would release another essay, thereby allowing me to chronicle my growth in these arts, compare/contrast/re-orientate/better articulate my perceptions of years past and/or share some of the methodologies/techniques I have been using.</p>
<p>This essay includes images from engagements I have participated in (with all due redactions, permissions, etc.) so that I may better illustrate my thoughts.</p>
<p>We all work from atop the shoulders of titans; this allows me to give back to the community like so many before me.</p>
<p>Weld Pond tweeted my last essay in 2017; I am a son of Massachusetts, and it was a cable news story about The L0pht that stirred the embers in my mind that this was happening nearby.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/a/a45a7c664a2698f6cccebb1e978d55bbf28551d7.gif" alt="weldpondtweer" data-base62-sha1="nrWayVCiKErQ0iU7JV83kofriwT" width="690" height="342"></p>
<p>I could become a hacker…</p>
<p>More than that: along with martial arts, hacking has saved my life…</p>
<p>I grew up in a bad way in a bad place with every excuse to fail.</p>
<p>Hacking gave me the means to build something that is mine…so many of you have given your hard work to the world, providing me with the raw materials I forged into a vocation, purpose and place in a world I did not believe I belonged in.</p>
<p>If the kid I was could see the man I have become, I know he’d be psyched; I wish I could go back in time and tell him that everything would be alright (though he likely wouldn’t believe me that everything would turn out this awesome).</p>
<p>Better than alright…amazing.</p>
<p>So here goes nothing.</p>
<p>Let’s get weird. Let’s get dangerous.</p>
<p>maderas</p>
<hr>
<p><strong>Perception</strong></p>
<p>More then ever, I believe that penetrating and exploiting systems/networks has become a matter of perception.</p>
<p>The data an attacker perceives and the manner in which they act upon that data governs the probability of their success during any stage of an engagement; the same holds true for the amount/degree of advantage that an attacker can perceive in and/or leverage from the data they enumerate.</p>
<p>Where defending against an attack is concerned, many times a defender’s best defense is their perception of the ways in which a vulnerability could be leveraged relative to the resources that are native to the digital spaces they are employed in defending.</p>
<p>Many times, some manner of business need could impede a defender’s capacity to fix vulnerabilities* *or mount the best defense possible.</p>
<p>In these instances, the defender must perceive the ultimate cost their organization may pay for the presence of a given vulnerability.</p>
<p>The defender must also perceive the manner in which they may best relay/explain the possible/potential cost(s) to an organization.</p>
<p>The topography/composition of an engagement environment is almost always shaped by human perception; for example, perhaps a target organization’s cost-benefit analysis leads it to ignore patching vulnerabilities within its IP space that they perceive to be "minor”.</p>
<p>I believe that the degree of perception that matters most where the security posture of an organization is concerned are blind spots in that perception.</p>
<p>An organization that chooses to ignore a vulnerability yet recognizes that the vulnerability is present at least perceives some potential detriment that the vulnerability could pose to the resources making up the organization’s information infrastructure.</p>
<p>Hopefully the client/organization documents these vulnerabilities and develops contingencies to deal with the vulnerabilities in case they are further compounded by an incident such as a breach.</p>
<hr>
<p><strong>Real World Example: Looking around corners</strong></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/2/2e42179c1a1870792d4080f5d6fe4601c33c9540.png" alt="infra" data-base62-sha1="6Bdz45OtsWhMVnuT0Gf3kNrxubm" width="690" height="306"></p>
<p>The diagrams above are “a real-world example of a large refinery” from the Industrial Ethernet Book illustrating the topography of the <em>“defense in depth” strategies, structures,technologies and resources that in many ways define ISA-99/IEC-62443 standard IEC-62443-3-2 ("Standard addresses security risk assessment and system design for IACS"):</em></p>
<p>“ A large refinery example shows how ISA-99 zones and conduits design techniques were used to create a security architecture and protect operations. The refinery company follows the concepts of ANSI/ISA-95.00.01- 2000 and ANSI/ISA-99.01.01-2007, dividing its process operations into Levels 0 – 4." (<a href="http://www.iebmedia.com/index.php?id=8460&amp;parentid=74&amp;themeid=255&amp;hpid=2&amp;showdetail=true&amp;bb=1&amp;appsw=1" rel="noopener nofollow ugc">http://www.iebmedia.com/index.phpid=8460&amp;parentid=74&amp;themeid=255&amp;hpid=2&amp;showdetail=true&amp;bb=1&amp;appsw=1</a>)</p>
<p>I have engaged networks/targets in the Industrial/Energy sectors configured by ISA-99/ ISA/IEC-62443 zones/conduits, defense in depth design specifications; in a huge majority of cases, these were challenging solo engagements (especially facilities in the EU where government/governing body regulations, specifications and/or certification enforced/demanded strict specifications) where the scope/parameters afforded me a wide operational latitude in which to operate (the engagement methodologies landed somewhere between Red Team/external Black-box testing).</p>
<p>A gross over simplification of the defense in depth strategy as a topography: each network segment (“zone”) is isolated from the others via technologies such as firewalls/VPN…each zone maintains one (or two at maximum, illustrated by the red dots in the diagram above) network connections (“conduits”) to some zones while excluding connection(s) to others (thereby shielding the zones with the most critical infrastructure behind other zones they are isolated from).</p>
<p>Each zone/conduit is normally protected by some type of security/secured network appliance.</p>
<p>As an attacker, I do not like to play to the strengths of a target…</p>
<p>It is a situation not unlike a magician using their patter and physicality to distract you as they perform their trick: if you want to try and figure out the trick, don’t look at the magician…look at what is happening around the magician.</p>
<p>The strengths of ISA-99/ ISA/IEC-62443 is that it creates a crucible of InfoSec best practices: isolation of critical systems,network segmentation,encrypted/secure channels…attacking each zone individually risks detection, as each zone necessitates new periods of prolonged enumeration and can consumes a great deal of time…</p>
<p>During an engagement, the more actions an attacker is forced to take and the more time they are forced to spend in attaining their goal increases the probability they will be detected.</p>
<p>Also, from a professional perspective, it is unlikely that a real world/malicious actor is going to smash themselves up against the strong points of a client’s security…attacks normally follow the paths of least resistance (unfortunately, defensive quantities also follow this dynamic way too often).</p>
<p>Real world attackers are going to hit the soft spots (though ultimately, the client may want their infrastructure targeted zone by zone).</p>
<p>ISA-99/ ISA/IEC-62443 attempts to limit my reach to something like the image below, forcing me to take ground a zone at a time at great risk:</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/2/2ce9a3270c427da1e233e5370bd2ecaf30cc32c1.png" alt="DCS1" data-base62-sha1="6pjzBKK46fxYoMMR9ExujQFRVrH" width="655" height="500"></p>
<p>However, on more than one occasion, I have engaged targets where variables inherent to the environment (blind spots in the operational perception of an organization/client) allowed me to bypass the strengths of the zone and conduit, defense in depth configuration of ISA-99/ISA/IEC-62443, thereby allowing my reach to extend to targets throughout the engagement environment.</p>
<p><em><strong>Digital Pickpocketing</strong></em></p>
<p>The age of transferable, mobile digital media has led to widespread implementation of  UPnP/UPnP-like programs and services for easy, quick movement of media between devices.\</p>
<p>Most users do not understand these technologies fully…this leads to them leaving ports open and media available; sometimes the user does not shutdown a program correctly (leaving UPnP/UPnP-like services up and the port/media available) or the program is poorly designed (which can also leave UPnP/UPnP-like services up and the port/media open).</p>
<p>Many times, these protocols are allowed through firewalls/network appliances (thus they are utilized by malware, especially RATs pretty often) as many Network/System Administrators do not fully perceive the InfoSec implications of protocols like UPnP (along with similar protocols like DLNA and SSDP that are often incorporated into its stack) or perceive these protocols/services as a possible threat, thereby creating an exploitable blind spot.</p>
<p>During an internal engagement against a facility in the Industrial/Energy sector, I was allowed a restricted workstation (laptop) and low privilege user credentials.</p>
<p>I immediately ignored the Ethernet connected laptop and used the provided credentials to connect to the corporate/facility WiFi with a customized Nexus 7 2013 (all of this was within scope of the engagement) and immediately utilized an application called ControlDLNA…below is an example of what I found:</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/8/8310bb8f2fdca9c7add25d3b89c623fd2de419dd.png" alt="DLNA%20Nexus7%20Admin" data-base62-sha1="iHsoGzYzd08HApayBFi173oMW8B" width="690" height="226"></p>
<p>Browsing the Administrator’s folders (from image above, images below), I discovered itself a huge amount of actionable data…</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/c/cc6a7f2088f25db2d14d8d320772eb7cfe0017f0.gif" alt="FINALCROP1" data-base62-sha1="talzsf9CYw0p00deVbtLxRvoUjC" width="690" height="388"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/f/f5a02eb6f43503536d716d08728e86bee0037b19.gif" alt="CROPFINAL" data-base62-sha1="z2Uaw5GrnvcrHeNCyX78pkqAudX" width="690" height="388"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/e326d4b36cb30d138b4d0ff2326adfb6985d834d.gif" alt="FINALCROP3" data-base62-sha1="wptzZyYURxW7MXEmqvgll3zKFzf" width="690" height="388"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/73fbbd3e375e3332c754046445287283da1e5676.gif" alt="FINALCROP4" data-base62-sha1="gy2fZqxEhnApZDaqv734rOvKyVw" width="690" height="388"></p>
<p>These findings provided confirmation that an Administrator account of at least one network segment connected to the corporate/facility WiFi network.</p>
<p>Most of the users/accounts with the highest levels/degrees of user/account privilege connected to the corporate/facility WiFi connection during the engagement.</p>
<p>This led me to utilize ControlDLNA and other UPnP/IoT applications (examples: applications that allowed me to detect and/or interact with Bluetooth and HID appliances) regularly.</p>
<p><strong>Link Below:The link below is video displaying the contents of an Administrator’s folder that contained photos, located on their company Iphone during the engagement…</strong></p>
<p>Eventually, the Administrator connected to the facility WiFi with their compay Iphone when they were in a section of the facility that received a poor mobile signal.</p>
<p>I had access to media on this Administrator’s workstation and their company Iphone due to blind spots in how the organization perceived the threat posed by file sharing/IoT protocols.</p>
<p>This was not shadow IT as the application in question was loaded on every company Iphone after the organization/facility had chosen to phase out company Windows/Android phones/tablets due to security concerns.</p>
<p>          <p><a href="https://vimeo.com/292568638">https://vimeo.com/292568638</a></p>
</p>
<p>If I was a real world, malicious actor who had downloaded the gigabytes of material available to me on the Administrator’s workstation/lphone, that material could have (at the very least) directly led to successful social engineering against the Administrator and any number of employees.</p>
<p><strong>Below:</strong> This engagement allowed me to attack from any area that I could access via my temporary keycard with access similar to that conferred upon a visitor or new employee.</p>
<p>Thus I deployed this and similar attacks throughout the facility, which allowed me to access corporate media shares (below) that were full of materials that could have been used in social engineering attacks, as a source of recon or as a direct attack vector (example: encoding payloads into files downloaded from the accessed media shares and somehow presenting them to the owner or placing/leaving the encoded materials in any SMB based shares exploited/accessed later).</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/b/ba24948a5c9058020ec2925249dfaacfb8743b60.jpeg" alt="COMPANY" data-base62-sha1="qyHbiKLo2JMbFweqHbgMWgknJvy" width="690" height="284"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/d/d7b42f3959061afea7613f555f183d45f3858d16.jpeg" alt="upnpemploy1" data-base62-sha1="uMcHne149G2jqab6EHcf2q1olYG" width="690" height="238"></p>
<p><strong>Image above</strong>: Another facility media share and the laptop of a management employee accessible from an area any guest could attack from: a bathroom stall.</p>
<p>All of these attacks were accomplished with a Nexus 7 2013 with a bluetooth keyboard case and NO USB ATTACHMENT as to better resemble an attacker who did not want to draw attention to themselves; had I used an Alfa or TP-Link USB/wireless attachment, the potential damage/reach of these attacks may have been much greater.</p>
<p>Also of note: some targets used IM or other messaging services that used UPnP/UPnP like protocols that stored the discussions as media files on their company devices; I was able to access those files as well.</p>
<p>This Metadata taken from those materials also could have provided a real world malicious actor with other avenues for penetrating areas of the network:</p>
<p>Metadata could be stripped from these materials (via tools such like Exiftool or FOCA) thereby allowing a real world actor to gain personal/private data on the target(s)…for example: by stripping GPS/other geolocation data/tags from photos accessed, the attacker could find or narrow down the physical location of a target’s home address.</p>
<p>Locating a target’s home address via this metadata , a malicious actor could crack the employees WiFi or access their residence physically to exploit machines in their home that could be connected to systems/machines/networks within the facility.</p>
<p>Also, what if a real world attacker using this attack had found material on the Administrator’s/an employee’s device(s) that were sensitive, illegal, deeply personal, embarrassing or could cause their termination…what if an attacker used these materials to successfully blackmail the Administrator/employee into carrying out attacks via a USB or some other physical media at inaccessible areas within the facility?</p>
<p>Remember, the facility was within the Industrial/Energy sector; historically, these facilities have a high probability of gaining the attention of state actors with sufficient financial means, logistical resources and motivation to accomplish/attempt the aforementioned attacks.</p>
<p>By leveraging an attack vector that the Industrial/Energy sector facility was not able to contest, a real world malicious actor could have leveraged blind spots in the facilities perception of vulnerabilities/risk, thereby broadening their reach to extend throughout the entire engagement environment while ignoring the InfoSec architecture designed to defend it.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/6/64504c6b89b0a6b60e481a3d290a12a584d335f4.png" alt="DCS2" data-base62-sha1="ejpMIHkFNmWfBEu0poppROWfJaI" width="655" height="500"></p>
<hr>
<p><strong>Real World Example: Attacking the blindspot(s) of a target’s perception(s) on multiple levels</strong></p>
<p>          <p><a href="https://vimeo.com/292479524">https://vimeo.com/292479524</a></p>
</p>
<p>The link above is an example of my capitalizing on a blind spot in a target’s perception during a past solo engagement.</p>
<p>Conducting an external engagement against a now defunct facility conducting activities governed by PCI/HIPAA, I gained access to the internal network of the target from outside the building, thereby circumventing the expensive physical/digital security implementations the organization’s clients demanded through/via contractual obligations (example: to enter the target’s lobby a person had to enter a code in multiple numeric keypads and scan themselves in with a keycard).</p>
<p>Sitting in a parked car in the massive parking lot the target shared with dozens of other unrelated businesses, the video above shows how I accessed the internal network of the facility via my customized Nexus 7 2013 using a wireless adapter and a common application that comes installed with Nethunter (which anyone could also download from FDroid or the Play Store).</p>
<p>IT at the facility had used a residential Belkin wireless gateway as a temporary fix that remained in place for at least 6 months within the target facility/network and they had left WPS engaged.</p>
<p>The Belkin Gateway was attached to a host with time clock software installed (relevant image below) in the employee lounge…employees would sign into their shifts or on/off breaks from this machine; management was under scrutiny from corporate due to the facility being off its “adherence” metric…corporate expected employees to wait until they got to/back to their desk workstation to sign in/out of the timeclock software installed there.</p>
<p>Corporate did not approve, nor did they know about this host.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/d/d171f2cc7f13f963e11950a7bc9d8dae9ba9ecaa.png" alt="FINALTIMECLOCK" data-base62-sha1="tSPVkByyDqJVPIPsXSE0pAXKrCa" width="690" height="96"></p>
<p>Thus a proper gateway had never been bought/requested to serve this task…worse, the Belkin gateway had all of its default credentials still in play, the time clock host was an older machine that was rarely patched with AV/AM with a long out of date .DAT file…this host machine also had Belarc Advisor installed (a wonderful tool if you want to commit the sin of dropping a binary to disk as it renders a TON of data about the connected hosts/network).</p>
<p>This Belking gateway was connected to the main network by an Ethernet connection; this was necessary so the management could more easily export the data from the time clock software.</p>
<p>Images below: some examples of data gained from a native Belarc Advisor well into the engagement. Data in Red Squares represent Administrator user I created as an extra means of persistence and at organization’s/client’s request to test if IT would notice.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/e/ec974ece1ac201b8579a6389eedd850783eff7a8.png" alt="Belarc1PNG" data-base62-sha1="xKYRejjYTV0fRufmsBnmwS0e8Ig" width="690" height="411"></p>
<p><strong>Below, Belarc reveals other blind spots:</strong> in the red square, notice all of the accounts native to the host I had gained access to…accounts that functioned on one machine could log into any machine in the facility outside of those in the server room.</p>
<p>Most of the accounts native to this host belonged to employees who were no longer with the organization/client, yet none of their accounts had been closed yet as IT waited until a certain number needed to be suspended and then did so.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/a/a0450bec1bbd0e52f252be00005bf7e397bbeee0.jpeg" alt="PNG" data-base62-sha1="mROkgu1XLWMpn6CzCVOBiqOJJMk" width="690" height="433"></p>
<p>Also, IT wasn’t assuring that employees weren’t reusing credentials for the time clock software, their workstations, VPN access, etc…thus, attacking the time clock host with Metasploit from my Nexus 7 allowed me to gain credentials that worked though out the wider network.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/9/9a73a74d41084676a17c283d10dc3402bce0c34a.gif" alt="4!Bel" data-base62-sha1="m2ljEsQ0ehPNnFhK1ExEYk0UKQW" width="690" height="306"></p>
<p>All of the workstations had access to a panel that would allow Remote Desktop access to any other host on any segment except the server room; all that was needed was the credentials necessary to access the host in question (all DCs were directly reachable from any host as they were located in a seperate closet on the top floor).</p>
<p>IT had implemented the Remote Desktop panel with a star network topography so that they and management could access/remote into “any workstation from any workstation” to ensure maximum uptime of/for each employee (business driving IT and creating blind spots).</p>
<p>Since the facility was also a sprawling multi-floor affair, management/IT grew tired of having to travel all over the building to help employees with tech issues ).</p>
<p>All of these aforementioned blind spots (which also include the use of some questionable software to run business dependent programs, top most red square above) maimed the vendor solutions the organization/client had invested in (also highlighted within lower red square in image above) which included a remediation layer that isolated hosts when malware/dangerous configurations were detected.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/7/77d0eb16bbf2e2bc098fc7de43d8f71199a1ebd6.png" alt="Belkin3" data-base62-sha1="h5WqjqSiwI7Wnb4liDtWAxuJ4Ts" width="690" height="457"></p>
<p>Worse of all: after gaining access to a manager’s desktop, I found an Excel sheet (image below) with every credential for every employee in the company (including international employees) that listed every current/past  set of credentials for all of the different billing systems utilized for PCI/HIPAA governed activities.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/8/82e420b14274a24a94e6e796de29f9acb11bb5dc.gif" alt="lootfinal" data-base62-sha1="iFUPCaQy6GP8HIxwJyKdPIckVcM" width="690" height="387"></p>
<p>The Excel sheet was labled “PasswordsDoNotDelete”; you can see the condition of the passwords…the employees would be assigned something like TShirt10, and they would usually make small changes to the password every 90 days (TShirt11, TShirt12, etc.)…other data on the sheet also included IT tickets.</p>
<p>Speed of the leader, speed of the crew: the account highlighted in Red belonged to the Supervisor of IT who had the equivalent of Domain Administrator access/status…they had only one password for all of their accounts: Autumn04 and it had not been modified (changed) since they had assigned it to their self (finding this sheet allowed me to establish multiple methods of persistence within every network made available by the scopes/parameters of the engagement).</p>
<hr>
<p><strong>Engagements causing me to ponder/perceive deeper realities</strong></p>
<p><a href="http://Attrition.org" rel="noopener nofollow ugc">Attrition.org</a> has always had a huge place in my heart, right alongside The L0pht, CDC, 2600, Phrack, CCC, Defcon, Computer H.O.P.E, netbooks, Thinkpads == to or &gt; then the x230 , Macbooks from before 2012, Neuromancer, Blade Runner…</p>
<p>These are all technology based things that shaped my sensibilities and who I am…</p>
<p>I get <a href="http://Attrition.org" rel="noopener nofollow ugc">Attrition.org</a> because I hate seeing the advantaged take from the disadvantaged forcibly…as someone who has engaged in professional prizefights to shed some of their aggression, I better understand  <a href="http://Attrition.org" rel="noopener nofollow ugc">Attrition.org</a>’s approach: sometimes you need to do more than just talk to a complete asshole.</p>
<p><a href="http://Attrition.org" rel="noopener nofollow ugc">Attrition.org</a> represents an institution whose approach has instilled a type of moral fear in me…I think sometimes you need that to be a good man…for some it is religion, for some others it is the law…I am not really an authority loving kind of guy generally, but our community polices its own pretty well I think, so I submit part of my psyche to it’s authority.</p>
<p>During the engagement detailed above, I realized that if I were an identity thief or if I had no moral/professional center (especially with it being a solo engagement), that this breach could have produced a good chunk of change…this engagement taught me the high financial stakes this game can have, which opened my eyes to the motivation this game has for someone in some economically depressed part of the world living on less than $5 USD a day…</p>
<p>Right now the First World keeps shipping its electronic waste to Third World countries where young people sacrifice their health and their environment to turn these electronics into scrap…</p>
<p>With the rapid advances/increased availability of computer technology and the inevitabilities that Moore’s Law dictates, how long before these  Third World countries realize that they are receiving more and more powerful machines better capable of simple attacks like password cracking…</p>
<p>How long before they start searching those computers for identity data, forgotten/lost/accidentally discarded crypto currency…I can see a shack full of discarded machines being turned on another scrapped machine to crack some password…</p>
<p>How long before they stop breaking these machines for scrap and start using them to break passwords or teach themselves to mount all other types of attacks…passwords may lose some importance in InfoSec in the future, but they are likely to be a gap somewhere in the world for a long while yet…</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/c/c0b7b6c90fc040e23ba79d9fd4c1d74a4f8cbf9a.jpeg" alt="HanisaWaste" data-base62-sha1="ruRhlqsjOxe4zvYuUQkzpbui9nQ" width="690" height="445"></p>
<p>I find the self righteous whitehat “good guy/bad guy” shit childish, but this engagement reaffirmed my belief that you do not get, nor deserve a cookie for doing the right thing, but not being an asshole is a reward in itself.</p>
<p>A solid reputation is also a reward; it represents the trust others have in you amidst a world where it is tough to trust things.</p>
<p>As Roland says, I remember the face of my father…but I also remember <a href="http://Attrition.org" rel="noopener nofollow ugc">Attrition.org</a>.</p>
<hr>
<p><strong>Perception is often about Presentation</strong></p>
<p>Hopefully, if/when a breach occurs, the victim has sharp employees, solid documentation detailing any vulnerabilities they have decided to except and an action plan in place.</p>
<p>Tightening the attack surfaces around/eliminating these vulnerabilities (especially where vulns like priv escalations are concerned) as early as possible following a breach can go a long way toward ensuring that persistence is truly abated.</p>
<p>In this vocation, the specifics concerning solutions are generally more important to an organization/client than the specifics concerning a problem (risk, exploited vulnerabilities, etc.); I want to lead them to the best solution possible, and showing them the blood/guts surrounding an issue is almost always the best way toward persuading an organization/client to make improvements.</p>
<p>On the OffSec side of things, I find that an organization/client better understands the benefits of patching a vulnerability after I show them video from the engagement. This video usually begins at an exploited vulnerability and carries on to the most final conclusion (post-exploitation, lateral movement, persistence, etc) that may be represented in the time/ situation available.</p>
<p>Ultimately, the video represents what the organization/client stands to lose/the potential damages the they could incur.</p>
<p>If you can exploit vulnerabilities through very mundane means (like a Nexus 7 and some stock applications), it can help drive the point home even more.</p>
<p>An organization invests in InfoSec to help ensure profitability/prosperity; to remedy an issue, you often have to present a vulnerability in a manner that allows the powers that be to easily perceive the potential cost(s)/potential value.</p>
<p>Sometimes a demo video must take the place of actual engagement footage…the demo environment where the demo takes place should match the organization’s/client’s environment with all possible exactness, with security turned up to 11 whenever possible.</p>
<p>Environment exactness/added security helps address excuses/justifications for poor security practices in the real environment pre-emptively…you do not want to hear “well we have a firewall here” or “we have AV/AM there”…the path of attackers and defenders often follow the path of least resistance where InfoSec is concerned, and excuses for weak InfoSec practices (even if the excuses have no merit) can harm the maximum effectiveness of the help you try to render unless you are prepared.</p>
<p>Perception is often defined by presentation…I like to show an organization/client how they can help themselves rather than just telling them how.</p>
<hr>
<p><strong>How do I become a hacker/penetration tester, learn to hack/learn penetration testing skills, (etc.)</strong></p>
<p>This is likely the question I see posted/asked the most online concerning my vocation.</p>
<p>When I first started out, there was a strong stance against “spoon feeding” knowledge; meaning that if you asked a question of a hacking/InfoSec community, you’d better of damn well exhausted every possible resource in finding an answer prior to asking (or scorn given an edge by some strong wit was forthcoming).</p>
<p>My reaction is somewhere in the middle concerning newbie questions; my gut tells me that if you are asking how to  become a hacker, than you may lack many of the requisite traits necessary to walk your version of this path…</p>
<p>This path is about finding and questioning knowledge through action.</p>
<p>Myself, I have a compulsive need to find the answers to the questions myself; I love research. I love how research snowballs, how one question/answer leads to another question/answer, leading to a slow amassing of knowledge until that never ends.</p>
<p>That feeling when you’ve followed a question from night into day, when the search for an answer evaporates hours as if they were minutes…</p>
<p>Those times when life finally demands that you turn your attention elsewhere, but you spend one more moment to marvel at how a single question at point A can end up mutated into something unrecognizable at point Z due to the blur of questions and answers that made up point B through X.</p>
<p>Often, knowledge is amassed in new and unusual ways…during research, a wrong turn there leads to a new revelation here…sometimes you realize you are asking yourself the wrong questions and thereby find your way far closer to an answer.</p>
<p>Today, knowledge or the path to an knowledge are almost always within your reach; knowledge or the path to knowledge has never been closer or more accessible than they are now.</p>
<p>I believe that the compulsive search for your own answers is what develops the faculties/capacities needed to be truly useful in this work.</p>
<p>This is a discipline based upon high level problem solving; how will you become good at solving problems unless you are solving problems?</p>
<p>Finally, I will tell you what helped me the most starting out (and I started out when there were far less sources available to a newbie):</p>
<p>Early in your development in these arts, I believe that asking your peers to part with knowledge that they worked and sacrificed so much for is disrespectful to them unless you have exhausted every other option at your disposal or you are constantly putting in more than you take out knowledge wise.</p>
<p>Information exchange through communication is not what I am talking about; equivalent exchange of knowledge in this manner, such as that which can occur with follow employees over coffee whil e you talking shop has been fundamental to my growth.</p>
<p>I believe that being lazy and just asking for answers is also disrespectful to those who have been kind enough to share that knowledge elsewhere; in this present age, it is very unlikely that the knowledge you seek isn’t online or on a printed page.</p>
<p>I have not asked a single question in a forum or community concerning a technical question unless that question was a means of clarifying another’s comments, questions or  an issue they raised concerning my own work/research.</p>
<p>There has yet to be a problem I have faced that I could not answer myself with some work; I believe this not only allowed me to build knowledge, but also build my own confidence in my faculties for solving a problem.</p>
<p>For about all of my career I have sought out the hidden places where blackhats operate (and I do not mean super secret darknet forums) to  examine their work; this meant finding their infrastructure to examine their work without the luxury of asking questions (amongst blackhats, operational knowledge is a commodity as is a paranoia).</p>
<p>This means a willingness to go out into the jungle rather than just learning from what others have written about the jungle.</p>
<p>This doesn’t mean joining the natives and it doesn’t mean lying to the natives and/or trying to burn their hut down while they sleep…this is a good way for you machine to catch malaria, or worse…</p>
<p>I believe that this is the reason  why my career  has consisted of positions far closer to the Red Teaming spectrum; I let my interests dictate an eventual career path…thus, my my vocation has been 99.8% manual engagement of targets (the stuff I love) .2% running Nessus/Qualys or some other automated vulnerability scanner (this stuff I don’t love).</p>
<p>You must except that if you want this, than you are responsible for getting it for yourself…I have been willing to search for the knowledge I wanted and was willing to absorb it from any source I thought passed the sniff test.</p>
<hr>
<p><em>The Burning House Principle</em></p>
<p>I strongly believe in the value of Passive Reconnaissance…Passive reconnaissance equates to asymmetrical intelligence gathering in a manner that does not directly interact with target resources (my next project will cover my methods for this is detail)*</p>
<p>Given the rapid application of AI/Machine Learning toward defensive solutions (AV, AM, etc.) targeted to the IT Security, the decreasing expense of running systems with advanced processors that are dedicated toward threat intelligence, increased sharing of threat intelligence throughout the IT Security Sectors and society’s ever growing reliance on digital networks to sustain its infrastructures, it is my belief that Passive Recon and obfuscation will gain greater and greater importance for most actors (minus those with a specific socio-political background/advantage such as actors in China).</p>
<p>I perceive the value of Passive Reconnaissance through a principle I call the Burning Building Principle.</p>
<p>Basically, you are only likely to enter a burning building if there is something of immense value inside (for this metaphor, the valuables are the objectives of an engagement with the burning building being the engagement environment itself).</p>
<p>The further away from the burning building you are, the further away from harm (detection, failing to meet engagement objectives) you are, but also the further away you are from the valuables that you can only retrieve through entering the unpredictable inferno inside (establishing some manner of session within an engagement/target environment).</p>
<p>The closer you are/further inside  the burning building you are, the greater the chance of catastrophic failure</p>
<p>For instance, you don’t enter the burning building (the engagement environment), but the fire hits a gas line and it explodes (metaphorically, so let us say you were detected by the target after visiting a webpage per your IP which had not yet been obfuscated) harming you, though the probability of this happening at a distance was far less than if you had entered the buildng.</p>
<p>And once inside, the longer you are in there without meeting the objectives that compelled you to enter and the more actions you are forced to take once inside, the higher the probability of catastrophic failure…and eventually the building is going to collapse (engagement duration ends, persistence is detected, general detection before persistence, target leaves the environment or loses value, etc.).</p>
<p>If you have not entered the building and met your objectives or you are trapped inside during the collapse without meeting these directives, you have suffered catastrophic failure (though it could be a win for the organization you engaged, which is a win for you in many circumstances, but still).</p>
<p>Before you enter the building, you want to gain as much as possible with the minimal chance of incurring harm (hurting your chances of meeting the objectives of the engagement)…until you engage the target’s IP space in some way, the probability of being burned is zero…ideally, you want to enter the burning with as much data as possible…you want to have a plan, utilizing an economy action balanced by decisive, effective action (running up and down multiple floors, in and out of the burning building to meet every objective may not be the best plan).</p>
<p>Why scout the burning building from no cover on the law when you could scout it from a safer distance or from behind cover (i.e., using traffic obfuscation methods. using 2nd party data sources from sites like Shodan, or Hurricane Electric’s BGP Kit, google dorking with Pagoda through HTTP randiomization//Agent spoofing libraries, etc.).</p>
<p>Once you gain ingress or directly touch a target’s IP space, the probability of detection never falls to zero…why not lower that probability as much as possible?</p>
<hr>
<p><strong>Social Engineering tactics taken from telemarketing/customer service</strong></p>
<p>Before I became a penetration tester/Red Teamer, I worked for years as a Closer in a telemarketing and customer service call room; my job was to feed lines to reps or get on the phone myself (getting on the line and taking over a rep’s phone) in order to convince a prospective customer to open their home/schedule to meet with a sales representative.</p>
<p>I also needed to ensure that the environment the sales rep would enter was as conducive to a possible sale (then or in the future) as our statistics defined possible; the company I worked for sold high end home improvement products with a minimum sale of $6k and average sale of $30k.</p>
<p>This meant ensuring all homeowners/decision makers were home for the duration of the sales rep’s demo, ensuring that the homeowners/decision makers had an open ended amount of time (at least 3 to 4 hours) in which to meet with the sales rep, inquiring about specifics concerning the construction of the home, etc.</p>
<p>Ultimately, my capacity to perform well in my position came down to four distinct skills that were interlinked: active listening, relief of obligation, empathy and anticipating/pre-emptive dealing with objections to what I had to offer.</p>
<p>Active listening (say, “the enumeration phase” of each phone call to or from a prospective customer) allowed me the mental material to reflect an objection back to the potential customer, thereby showing them that I was listening to their concerns.</p>
<p>Really listening to the person on the other end of the line (careful analysis of the data gained in the “enumeration phases” of each call, with the speed/understanding of potential applications of data coming by practice/experience ) allowed me to anticipate what objections would/could follow be forthcoming early in the call and allowed me to offer rebuttals that showed them the value in what I had to offer while I alleviated their concerns about having a sales person out to their home (thereby relieveing their obligations while creating greater value in what I had to offer).</p>
<p>Most importantly, listening closely and getting a feel for each person on the phone allowed me to identify an “in”, a way of offering the person on the phone a concept in a manner that overcame their reluctance while enriching the value of the offer itself.</p>
<p><strong>Customer:</strong> “ I am not planning on doing any work to the home now….maybe in the Spring…”</p>
<p><strong>Me:</strong> “Well it is winter time, I think it’d be crazy to punch holes in your home during a New England Winter…and the holidays are around the corner…I bet that with two kids you have better things to spend your money on in the next few months…”</p>
<p>“There aren’t many people looking to do work on their homes now; you’ve made it abundantly clear that includes you and Mrs. Smith…We have employees that need to be paid anyway…we as a company know that if we show enough people what we have and leave them with an exact price guaranteed for a year, that folks are going to call us back eventually…we guarantee to beat our competitions price on a comparable product with this price we are providing now…”</p>
<p>“You stated you are thinking about doing the work in Spring anyway, so why not find out what you will be looking at and getting a price you can hold against the competition for the next 12 months even if you don’t decide to go with us….if you are both home Saturday anyway, and my guy is in your town seeing some other folks, than what could spending a bit of time with them hurt?.”</p>
<p>By anticipating the customer’s objections and dealing with them in a preemptive manner, the call became a conversation rather than an annoyance; it basically came down to making sense to the customer without insulting their intelligence and putting down what I had to offer at their feet while instilling what the value would be to them if they decided to pick the offer up themselves.</p>
<p>There is little success in trying to stuff concepts/social engineering attacks down the customer’s/target’s throat; if they do not decide themselves, they will spit out what you offer/not trip the trap or contact IT concerning your attack.</p>
<p>The dialogue I provided above (between an imagined customer and myself) is the ghost of a marketing approach that I designed myself in 2007 when I was promoted to Marketing Manager by the company I worked for (a move that was mostly a nothing to lose, desperate last gasp by the ownership).</p>
<p>This approach/these communication dynamics allowed the company I worked for to survive the 2008 financial collapse without a incurring a single lay off while also allowing the company to take over the entirety of the Northeast territory through acquiring our closed/floundering competition.</p>
<p>Social engineering is not very different in execution at the emotional/intellectual level where a target is concerned; both demand that the target perceive authenticity in your approach, both demand that you provide an abundance of data that overwhelms the target;s inclinations toward suspiscion, both demand that you motivate a target to act in manner that is not detrimental to, or directly aligned against, your own motivations…</p>
<p>In my mind, the best social engineering campaign identifies a method that is going to cause the target to ignore that corporate training they undertook….it creates an instinctive/reactive action within them that moves them toward executing the trap (akin to the customer above dropping their objectives to consider what I have offered).</p>
<p>For me, the best social engineering attacks creates a sort of violent, instinctive reaction within a target that creates a gap in, or clouds the target’s logic for maybe a few seconds. “Active listening” in the context of a social engineering attack is the capacity to perceive the data that may be used to effectively and/or perceive the manner in which enumerated data may be used to effectively, bait and hook the target(s).</p>
<p>This burst of curiosity (or whatever the emotional/intellectual trigger may be) is compounded through the creation of a temporary, situational reality that is conducive to the reaction(s) necessary for the target to click that link or open that PDF attached to the e-mail (such as an attacker using the account of a trusted confidant to execute attacks against other targets).</p>
<p>From there, it is about making the target except the decision they have made, thereby making them an unwitting accomplice; “active listening” in this case is the creative use of the data an attacker has enumerated, the attacker’s capacity to perceive enumerated data that can be leveraged to move the target through the necessary actions, the attacker’s ability to enumerate/make actionable the data that best serves as bait the target will not spit out on a hook so sharp they barely notice it set.</p>
<p>This piece could be the attacker’s technical capacity that makes the target feel comfortable/safe with their decision; the attacker fashions an attack that does not trip AV/AM or create a buggy reaction that jars the target’s immersion in the ruse, causing a target to have second thoughts and contact IT.</p>
<p>This piece could be the promise of a tantalizing payoff or the lead up/build up to the payoff could appear so authentic that should a technical glitch occur (such as a popup that implores the target to change the security configuration of their OS or take any further steps necessary to execute a macro based drive by exploit) the target ignores, does not think about or forgets the potential harm their actions could cause.</p>
<p>This piece could be a situational/logistical reality that an attacker creates which forces the target into culpability, whether overtly or unknowingly.</p>
<p>For instance, one of the most successful social engineering attacks that I have executed was against an organization that was being examined for a buyout by a much larger corporation.</p>
<p>It is a game of motivation vs inhibition; in the age of social media/business organizations humanizing themselves within the digital spaces, deducing motivation is easier in individual cases rather than blanket cases.</p>
<p>This is why I prefer spearphishing/focused social engineering attacks if a client requests social engineering during a prolonged engagement (especially those demanding some period of persistence); otherwise, even if social engineering is on the table per the scope, I tend to avoid it until the latter stages of an engagement (depending on what the preliminary enumeration of the target tells me/us about their security posture of an organization and what I/we deduce to be of the most value to them).</p>
<p>I will enumerate these concepts further in a future project.</p>
<hr>
<p><em><strong>The enumeration/reconnaissance phase</strong></em></p>
<p>I believe that during an engagement, an attacker should always be in a state of enumeration/reconnaissance as to constantly establish, re-establish, examine and re-examine* <em>the</em> *state of their situational awareness.</p>
<p>I believe that due to the way the human mind works (we may only pay real attention to one thing at a time, though we may shift that attention between multiple priorities) that certain points of an engagement may be more heavily invested in a certain type of action (enumeration/recon, overt offensive action, obfuscation of* current position, misdirecting the blue team/purple team,etc.); however, I believe that an attacker should always be in a state of enumerating the environments,situations and circumstances in which they find themselves.</p>
<p>Especially now, where target organizations seem to invest much more heavily in an ever growing boutique of vendor solutions rather then a greater degree of secure configuration/adherence to basic InfoSec best practices such as privilege siloing (which I believe will always be folly), an attacker is well served by striking a balance between definitive, direct action(s) and re-evaluating their position.</p>
<p>Enumeration itself can be a method of offensive action; for instance, during most phases on an engagement (unless I detect/sense that running such a tool could mean my detection), I like to run some manner of traffic analysis to help maintain an awareness of what fish are swimming about in the digital in which I am immersed.</p>
<p>Much like a shark is said to be capable of sensing electrical anomalies in the environments in which they are immersed, I like to have multiple methods deployed that may make me aware of any changes occurring in the nature/condition of the engagement environment (especially those changes I may create, as I prefer to have the traffic I create blend in with the natural biorhythms of the environment I am engaging).</p>
<p>I sense that a balanced attack posture is something like what I see when watching footage of small/medium size sharks hunting; they are always on the hunt for a meal, but they are also always adjusting between levels of aggression/awareness to ensure another shark/sea creature doesn’t make a meal of them.</p>
<p>Exploitation is about detecting and acting upon actionable data (as well as perceiving what data is actionable, how it is actionable or how it can be made actionable); actionable data can be uncovered at any time during an engagement and/or can undergo changes/be effected by changes to the surrounding environment that effects the nature in which it may become/can become/is actionable.</p>
<hr>
<p>My definition of hacking vs. penetration testing/Red Teaming in this post</p>
<p>I use the word hacking to describe an art composed of many disciplines that I may utilize in my vocation as a Red Teamer/Penetration Tester.</p>
<p>I apply tools/techniques/methodologies during work, play and practice that mirror the same tools/techniques/methodologies I apply in my vocation as a Red Team operator and/or penetration tester.</p>
<p>However: personally, my application of these tools/techniques/methodologies and the reactions others have to the manner in which I apply my art have become a means of expression that aid me in developing a deeper understanding of myself and the world around me.</p>
<p>The importance of what a tool can or cannot do is much lessened; now, they (and code in general) are a means of expressing myself within the framework of a scope/parameters that are much less restrictions or rules, but are more the realities governing the medium on which I display my art.</p>
<p>Recognizing this. I see this art as ultimately an art of strategy, creativity and perception where almost anything can be leveraged toward meeting the objectives of an engagement.</p>
<hr>
<p><strong>In fact, I know hacking to be a martial art</strong></p>
<p>Last year when Shared thoughts after 6+ years in Pentesting was released, there was a comment on HackerNews to the effect that the poster could not stand fellow InfoSec employees who looked at their vocation as if they were some manner of Zen monk/cyber warrior.</p>
<p>I can agree that someone who constantly espouses any personal philosophy and tries to push that on others can be insufferable; myself, I am an exceptionally quiet, introverted person who would never deign to tell others how they should think.</p>
<p>When I express myself in this way, I do so in order to give back to a community that I feel I owe a great debt too; I offer ideas in the hope that someone may find something useful amongst the experiences/ideas I relay.</p>
<p>And my own experiences paint my conception of things…I have been a martial artist since at least the age of five; I began fighting professionally in my mid 20s (muay thai. MMA, K-1 rules kickboxing and kyokushin); thus, I see everything through the eyes of a martial artist.</p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/a/ae731944d35884dadc78c7ea20ef0cc407fea9bc.jpeg" alt="kixk" data-base62-sha1="oTfG14JZ7GcBDe2IApCoBR50IWg" width="378" height="499"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/0/049118cfd6aa9db48ca56b05376c5ad93ddf739e.jpeg" alt="puncjh" data-base62-sha1="EoMgWGmzwbKrm0aKxDnG4xxfIO" width="510" height="500"></p>
<p><img src="https://0x00sec.s3.amazonaws.com/original/2X/1/1ec9c8b06085f0c5a4afaa358b1a68dcd818332a.png" alt="Picture%203" data-base62-sha1="4omDWmczrRcZKZJspr6a29I41d0" width="690" height="457"></p>
<p>I see hacking as a martial art and I believe it is the most potent martial art to ever exist.</p>
<p>The martial arts comprise disciplines where the knowledge acquired by a practitioner allows them to better utilize their mental faculties toward an expression of physicality that creates change in the physical realities of an opponent.</p>
<p>Through the use of knowledge acquired through regular practice, a hacker’s mind manipulates some implement with their physical body (their fingers striking a keyboard perhaps) that changes some physical reality of an opponent (such as embedding foreign code within the network infrastructure of a target).</p>
<p>Except hacking now has the potential to do some anime/manga levels of damage (look at the damage the Triton malware could have wrought) to people via attacks against critical infrastructure across great distances.</p>
<p>Though I wish to examine my views concerning the relationship between martial arts and hacking in a separate project, I can say that engagements have guided my hacking as fighting has guided my martial arts training…</p>
<p>They both show me where my strengths/weaknesses really lay by allowing me to test/push my limitations, creating a cycle of training/testing that gives me purpose through building skills I can use to help make the world a better place.</p>
<p>Like sparring/fighting an opponent eventually became, I have come to see an engagement as less about challenging a target’s defense with my own offense and more about  challenging myself.</p>
<p>It is more a contest that allows me  to learn the truth about myself; to find, establish, define and overcome my own limitations so that I can make myself a better, more useful piece of this world.</p>
<hr>
<p><strong>And finally…</strong></p>
<p>In Buddhism (especially Japanese Buddhism in particular) the beings who are charged with protecting the Buddha ( <strong>Niō</strong> (仁王) or <strong>Kongōrikishi</strong> (金剛力士)) resemble devils, not angels.</p>
<p>“Within the <a href="https://en.wikipedia.org/wiki/Ahimsa" rel="noopener nofollow ugc">generally pacifist tradition</a> of Buddhism, stories of dharmapalas justified the use of physical force to protect cherished values and beliefs against evil.” <a href="https://en.wikipedia.org/wiki/Nio" rel="noopener nofollow ugc">https://en.wikipedia.org/wiki/Nio</a></p>
<p>I maintain that the baud is Buddha; both can convey messages that open our eyes to both wisdom and absurdity concerning our existence.</p>
<p>We may choose to learn what we will from that which they convey, or we may only have it show us what we wish to see.</p>
<p>Like the philosophical/theological concept of the Buddha, the baud represents many manifestations of a largely invisible world that human civilization now depends upon.</p>
<p>But we all must protect it…especially those of us that may resemble devils (yet are not) and have the skills necessary to protect the world’s digital spaces against all manners of threat. (political, financial, InfoSec and otherwise).</p>
            <p><small>20 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/essay-images-video-thoughts-professional-hacker-2011-to-present/8782">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/essay-images-video-thoughts-professional-hacker-2011-to-present/8782</link>
          <pubDate>Sun, 30 Sep 2018 15:22:44 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-8782</guid>
          <source url="https://0x00sec.org/t/essay-images-video-thoughts-professional-hacker-2011-to-present/8782.rss">Essay - Images, Video &amp; Thoughts: Professional Hacker, 2011 to Present</source>
        </item>
        <item>
          <title>Intro to Digital Forensics [Part 3 - The course of the Evidence]</title>
          <dc:creator><![CDATA[n3xUs]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><strong>[+] THE COURSE OF THE EVIDENCE</strong></p>
<p>From the actual incident / crime to the probative presentation, digital evidence is subject to various phases, as defined in the context of digital forensics.</p>
<p>To summarize:</p>
<p><strong>Course 1:</strong> the digital evidence is directly identified (by the system it’s stored in, for example)</p>
<p><strong>Course 2:</strong> the evidence is not directly accessible ( &lt;- this is a major situation, which we’ll cover later) and as such requires authorization to be handled. After said authorization, we proceed to the triage of the evidence and subsequent identification.</p>
<p><strong>Course 3:</strong> the location of the evidence is unknown and there’s no authorization to handle the evidence. In this case, we proceed directly to it’s preservation.</p>
<p>This first 3 courses occur in the first response phase to the incident (the first people on-site to review the crime scene and collect the evidence). After any of these courses, we proceed to the acquisition and validation phases. Contrary to the first 3 courses, stage 4 doesn’t occur on-site. Instead, it is done in laboratory, where we begin data recovery and analysis process.</p>
<p>Below you can see a flowchart that I recreated from a book I’ve been reading. It generically identifies the various courses evidence can take:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/5/52f2dc3a932e79c06dff98715731456dcaf6127f.png" alt="de_course(5)" data-base62-sha1="bPNtEAZqxZyfS48YJ2TWFMpFEyr" width="682" height="500"></p>
<p>As you can see, there are a few steps that a first response team must follow. As we previously covered, the first response team must take extreme care when dealing with this evidence, to ensure its preservation and integrity. There are many manuals and books that cover good-practices and procedures, namely the international standards ISO/IEC 27032 and 27037, that deal directly with cybersecurity and digital evidence.</p>
<p>Some courts are quite skeptical of digital evidence due to uncertainties about chain of custody, validity and integrity of the information obtained from devices. Overcoming these challenges requires rigorous documentation of data such as <strong>when</strong> the evidence was collected, <strong>where</strong> it was collected from, <strong>who owned</strong> the device, <strong>who</strong> had access to it and <strong>how</strong> the evidence was collected. Finally, chain of custody involves documenting how the evidence was stored, who has handled the evidence, and who had access.</p>
<p>As such, one of the most (if not the most) imporant steps is the documentation of the whole process. <strong>I can’t stress this enough</strong>. Every single aspect of the investigation must be properly identified <strong>and</strong> justified. From the arrival at the crime scene, to the identification, acquisition, recovery, transport, etc… You get the idea. Again, these steps must not only be identified and registered but also justified. An expert must explain and justify why he did what did. Doing this allows others experts or entities to verify and achieve the same results, thus adding credibility and integrity to the case.</p>
<p>Now, we’ll cover with more detail the processes of <strong>Identification</strong>, <strong>Preservation</strong>, <strong>Acquisition</strong> and <strong>Transport/Packaging/Storage</strong>.</p>
<hr>
<p><strong>// Identification and Origin of Digital Evidence</strong></p>
<p>Before the actual process of seizure and identification, it’s extremely important to note that before collecting evidence at a crime scene, first responders should ensure that [1]:</p>
<ul>
<li>
<p>Legal authority exists to seize evidence.</p>
</li>
<li>
<p>The scene has been secured and documented.</p>
</li>
<li>
<p>Appropriate personal protective equipment is used.</p>
</li>
</ul>
<p>First responders without the proper training and skills should not attempt to explore the contents of or to recover information from a computer or other electronic device other than to<br>
record what is visible on the display screen. They shouldn’t press any keys or click the mouse.</p>
<p>The identification consists in locating both the physical and logical sources of the data that may be the evidence. There are many, many devices and systems where data may be stored:</p>
<ul>
<li>
<p>Local or Remote devices, acessible through the local network or through the Internet;</p>
</li>
<li>
<p>Dedicated storage systems, such as those in data centers;</p>
</li>
<li>
<p>Computer Systems;</p>
</li>
</ul>
<p>There are 3 main types of data available in these devices:</p>
<ul>
<li>
<p>Simple and human-readable (i.e photos, documents, videos);</p>
</li>
<li>
<p>Complex or structured (i.e OS files);</p>
</li>
<li>
<p>Raw data;</p>
</li>
</ul>
<p>The following images represent various types of digital storage media, where we might find some evidence (images obtained from  [1]):</p>
<ul>
<li><strong>(External) Hard Drives, Removable Media, Thumb Drives and Memory Cards</strong></li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/8/8497e51df871ae0822515e685bcea9ebfed068a2.JPG" alt="devices1" data-base62-sha1="iUYsuKgj3Kvd4SnywF6J0tiYmSm" width="498" height="480"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/7/7cfcf3b3d0c0cd0502fe92f330e4b20a14be999c.JPG" alt="devices2" data-base62-sha1="hPH9vJjtmtl5tgLE9Puqy7t4w3i" width="498" height="480"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/5/5cdb1c54c05cd0ab33da441bf2da4d3c244f209a.JPG" alt="devices3" data-base62-sha1="dfrmVdjItAIL50YQ6no8vDC30yS" width="498" height="218"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/f/f87d4f173f36dbce421628e8f6d60d8911fbfb04.JPG" alt="devices4" data-base62-sha1="zseSVe7dJl321EdGAEd6OIO9hRi" width="498" height="400"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/d/d1e01e7b246a881926c41e24f4fb3715b78dd612.JPG" alt="devices5" data-base62-sha1="tWDXMq4yZZqFmyOUzVarq7a2wsq" width="498" height="500"></p>
<p><em><strong>Potential Evidence</strong></em>: may contain information such as e-mail messages, Internet browsing history, Internet chat logs and contacts, photographs, image files, databases, financial records, and event logs that can be valuable evidence in an investigation or prosecution.</p>
<ul>
<li><strong>Handheld Devices</strong></li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c4449e60c6328661754a777af95ce399e663651a.JPG" alt="devices6" data-base62-sha1="s0gB8CKrtynGq7dEJ38gJ2tsr7c" width="369" height="499"></p>
<p><em><strong>Potential Evidence</strong></em>: handheld devices such as mobile phones, smart phones, PDAs, digital multimedia (audio and video) devices, pagers, digital cameras, and global positioning system (GPS) receivers may contain software applications, data, and information such as documents, e-mail messages, Internet browsing history, Internet chat logs and buddy lists, photographs, image files, databases, and financial records that are valuable evidence in an investigation or prosecution.</p>
<ul>
<li><strong>Peripheral Devices</strong></li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/a/a7648ff17f2e920dfc923dd8dc5f736c426db685.JPG" alt="devices7" data-base62-sha1="nSPbRb37Gd44tR8m5bqSzKiDrhj" width="369" height="198"></p>
<p><em>Potential Evidence</em>: the devices themselves and the functions they perform or facilitate are all potential evidence. Information stored on the device regarding its use also is evidence, such as incoming and outgoing phone and fax numbers; recently scanned, faxed, or printed documents; and<br>
information about the purpose for or use of the device. In addition, these devices can be sources of fingerprints, DNA, and other identifiers.</p>
<ul>
<li><strong>Network Devices</strong></li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/e/e4339eae923b4febcbb0b812b35e008713957439.JPG" alt="devices10" data-base62-sha1="wyLspDOJiuyWm62lvrkiXhmmbbj" width="333" height="467"></p>
<p><em><strong>Potential Evidence</strong></em>: may include software, documents, photos, image files, e-mail messages and attachments, databases, financial information, Internet browsing history, log files, event and chat logs, buddy lists, and data stored on external devices. The device functions, capabilities, and any identifying information associated with the computer system; components and connections, including Internet protocol (IP) and local area network (LAN) addresses associated with the<br>
computers and devices; broadcast settings; and media access card (MAC) or network interface card (NIC) addresses may all be useful as evidence.</p>
<ul>
<li><strong>Other Potential Sources of Digital Evidence</strong></li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/4/469175844611ae0b72b5cf7f3767b961396568b1.JPG" alt="devices8" data-base62-sha1="a4h4bv1aBCHp6roy2ugFxgEKh2x" width="395" height="366"><img src="//0x00sec.s3.amazonaws.com/original/2X/5/55e1b9c815827eeb761ef43c3b438efb6cf59ba4.JPG" alt="devices9" data-base62-sha1="cfKcp91NJe3mjM9g101Lc09qd92" width="395" height="500"></p>
<p><em><strong>Potential Evidence</strong></em>: The device or item itself, its intended or actual use, its functions or capabilities, and any settings or other information it may contain is potential evidence.</p>
<hr>
<p><strong>// Preservation of the Digital Evidence</strong></p>
<p>When a first responder arrives on scene, he must perform a series of actions to preserve the original state of the evidence, allowing an integral and certified collection of the evidence.</p>
<p>After securing the scene and all persons at the scene, the first responder should visually identify all potential evidence and ensure that the integrity of both the digital and traditional evidence is preserved. First responders should document, photograph, and secure digital evidence as soon as possible at the scene. When securing and evaluating the scene, the first responder should [1]:</p>
<ul>
<li>
<p>Follow departmental / jurisdictional policy for securing crime scenes.</p>
</li>
<li>
<p>Immediately secure all electronic devices, including personal or portable devices.</p>
</li>
<li>
<p>Ensure that no unauthorized person has access to any electronic devices at the crime scene.</p>
</li>
<li>
<p>Refuse offers of help or technical assistance from any unauthorized persons.</p>
</li>
<li>
<p>Remove all persons from the crime scene or the immediate area from which evidence is to be collected.</p>
</li>
<li>
<p>Ensure that the condition of any electronic device is not altered.</p>
</li>
<li>
<p>Leave a computer or electronic device off if it is already turned off</p>
</li>
</ul>
<p>If the jurisdiction of the first responders allows, they should perform some preliminary interviews and obtain the most information possible from all suspects on scene, if any. Some critical information a first responder should look for while interviewing:</p>
<ul>
<li>
<p>Names of all users of the computers and devices and respective user accounts/login information;</p>
</li>
<li>
<p>All computer and Internet user information.</p>
</li>
<li>
<p>Purpose and uses of each computer and device on scene.</p>
</li>
<li>
<p>All passwords.</p>
</li>
<li>
<p>Type of Internet access.</p>
</li>
<li>
<p>Any offsite storage.</p>
</li>
<li>
<p>Internet service provider.</p>
</li>
<li>
<p>All (web) e-mail/social networks/ accounts.</p>
</li>
</ul>
<ul>
<li>Security provisions in use.</li>
</ul>
<ul>
<li>
<p>Data access restrictions in place.</p>
</li>
<li>
<p>All instant message screen names.</p>
</li>
</ul>
<p>The information with probative value may be in four different states:</p>
<ul>
<li>
<p><strong>Stored:</strong> persistently stored in a digital storage media, such as a hard drive;</p>
</li>
<li>
<p><strong>In transmission:</strong> it’s being sent over a communications network to a receiving device;</p>
</li>
<li>
<p><strong>In reception:</strong> it’s being received by a device, but it’s not yet available to a user;</p>
</li>
<li>
<p><strong>In creation:</strong> it’s being locally produced and is only parcially available to a user.</p>
</li>
</ul>
<p>So the actions taken should be previously planned and organized taking to account these possible states and other factors (just like hacking, proper “recon and footprinting” is important before a digital forensic op).</p>
<hr>
<p><strong>// Acquisition and Validation of data</strong></p>
<p>The first responder must have proper authority to search for and collect evidence at any electronic crime scene. The first responder must be able to identify and verify the authority under which he or she may seize evidence and should follow his organization guidelines, consult a superior, or contact a prosecutor if a question of appropriate authority arises.[1]</p>
<p>The acquisition of data can be done on-site or it can be postponed and performed on a lab environment. The choice to do either depends on several factors:</p>
<ul>
<li>
<p>Personnel on-site: sometimes, the personnel on site may not be equipped or have sufficient knowledge to correctly perform the acquisition;</p>
</li>
<li>
<p>Time: some Ops may be time sensitive or on a tight schedule, so it’s beneficial to perform the acquisition on-site, to speed up the process;</p>
</li>
<li>
<p>Type of data: some information may be more sensitive and therefore shoulf be handled with more care or in a more controlled environment</p>
</li>
<li>
<p>State of data: as previously mentioned, data can be found in 4 mains states: <em>stored</em>, <em>in transmission</em>, <em>in reception</em> and <em>in creation</em>. When an expert encounter data in one of the last two states, it’s wise to postpone the acquisition, allowing experts to have the full data instead of parcial information.</p>
</li>
</ul>
<p>When performing the acquisition an expert must take into account all the type of devices listed in the Identification phase. It is also of the utmost importance for an expert to have a dedicated “forensic station”, that is, a dedicated computer(s) that is specifically designed (both in hardware and software) to handle all the nuances of a forensic op.</p>
<p>Below is a list of some hardware, software and other equipment an expert is expected to use:</p>
<ul>
<li>Write Blockers - devices that allow acquisition of information on a drive (read command) while  intercepting and blocking write commands, thus blocking any modification to the disk[5]. They can be either hardware based (see below) or software based (software write blockers are installed on a forensic computer workstation). There are two types of hardware write blockers, Native and Tailgate. A Native device uses the same interface on for both in and out, for example a IDE to IDE write block. A Tailgate device uses one interface for one side and a different one for the other, for example a SCSI to IDE write block. [4]</li>
</ul>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/bc6d181c66358400127db5881d2a85ca6ff8c56d.JPG" alt="Portable_forensic_tableau" data-base62-sha1="qSTuQYWwPb5V0Voh4FFX2SQs9jf" width="440" height="323"><br>
<em>Portable Hardware Write Blocker (HWB)</em></p>
<ul>
<li>
<p>Various imaging software - applications that perform a low level copy of the contents of a target drive to an external storage device (i.e EnCase, FTK Imager, Tableu Software Imager). Most of these applications emit/produce a certification or digital summery of the whole process.</p>
</li>
<li>
<p>A bootable disk/USB drive - should contain a bootable image of an autonomous, certified OS that blocks write commands (some Open Source Forensic OS’s include: CAINE; Helix, SANS SIFT, Sumuri Paladin)</p>
</li>
<li>
<p>A USB drive - should contain various forensic portable apps, that allow selective data recovery that avoid leaving traces in the target machine.</p>
</li>
<li>
<p>Portable forensic station - usually a high-end, high-performance laptop. Oftentimes this laptops are custom built or purchased from companies that specialize in building and configuring such machines (see <a href="https://digitalintelligence.com/products/fred_l" rel="noopener nofollow ugc">Digital Intelligence</a> for examples).</p>
</li>
<li>
<p>External RAID system - allow high storage capacity and should support various connection interfaces (USB, IDE, eSATA, Firewire, etc)</p>
</li>
</ul>
<p>If you want to see detailed instructions on how to proceed with the acquisition and collection of data as well as methodical flowchart, see <a href="https://www.ncjrs.gov/pdffiles1/nij/219941.pdf" rel="noopener nofollow ugc">Electronic Crime Scene Investigation: A Guide for First Responders</a>, page 33 to 41.</p>
<hr>
<p><strong>// Transport, Packaging and Storage</strong></p>
<p>Like all the previous phases, this one must also respect a few rules and good practices. Like any electronic device, digital evidence (and the digital media it is stored in) is quite fragile  and sensitive to high temperatures, humidity, physical shock, static electricity and magnetic fields. [1]</p>
<p><strong>Packaging Procedures</strong></p>
<p>First of all, all devices that constitute the digital evidence must be properly documented, labeled and invetoried before being packaged. An important observation is that these devices may contain more traditional types of evidence, such as fingerprints, for example. Forensic imaging should be done before any kind of procedure is done on these types of evidence [1].</p>
<p>When packaging the devices, one must only use antistatic packaging. This means only cardboard boxes, paper bags and <a href="http://antistaticsupplies.com/media/catalog/category/Open-Top-Anti-Static-Bags_1.jpg" rel="noopener nofollow ugc">antistatic containers</a> should be used. All plastic containers should be avoided since plastic materials have a tendecy to produce static electricity and allow condesation to take place, potentially damaging the device [1].</p>
<p>If an expert is dealing with mobile devices, these should be packaged in a signal-blocking material, such as a <a href="http://ecx.images-amazon.com/images/I/411-yawZl8L.jpg" rel="noopener nofollow ugc">faraday isolation bags</a>, a radfio frequency shielding/blocker material (even wrapping them in aluminum foil) to prevent the phones from receiving a call, text message, or other communications signal that may alter the evidence. [1]</p>
<p><strong>Transporting Procedures</strong></p>
<p>Regarding transportation, the devices should not be stacked, straped or packaged in any manner that may cause deformation.</p>
<p>During transport, the devices should be clear of any (electro)magnetic sources, such as radio transmitters, subwoofers and speakers, for example. In fact, a team of researchers recently revealed a study on an acoustic attack to hard drives, proving to be an effective DoS attack.</p>
<blockquote>
<p>Adversaries without special purpose equipment can cause errors in the hard disk drive using either audible or ultrasonic acoustic  waves.  Audible  waves  vibrate  the  read/write  head<br>
and platters; ultrasonic waves alter the output of the HDD’s shock  sensor,  intentionally  causing  the  head  to  park. <a href="https://spqr.eecs.umich.edu/papers/bolton-blue-note-IEEESSP-2018.pdf" rel="noopener nofollow ugc">[6]</a></p>
</blockquote>
<p>When being transported by a vehicle, the evidence should also be clear of any sources of heat and humidity, like a heating system, and avoid being directly exposed to sunlight.</p>
<p><strong>Storage</strong></p>
<p>The devices should be properly stored and inventoried according to the organizations policies and standards. The storage environment must be climate-controlled (regarding temperature, humidity, dust, magnetic fields, etc). Another important aspect is that this storage area must be properly secured. There should be strict Access Control Policies in place and the area should have safety measures regarding catastrophes and other hazards, such as a fire or a flood.</p>
<hr>
<p>This bring us to the end of this article. I know this was quite a bit longer that the previous two, however, it is much more in depth and interesting I believe. So kudos if you made to the end.</p>
<p>Next up, we’ll cover the “Data Recovery and Analysis”, which might just be longer than the current article. As always, any suggestions or feedback is welcomed.</p>
<hr>
<p><strong>Sources:</strong></p>
<p>[1] <a href="https://www.ncjrs.gov/pdffiles1/nij/219941.pdf" rel="noopener nofollow ugc">Electronic Crime Scene Investigation: A Guide for First Responders, 2nd Edition (April 2008, NCJ 219941)</a><br>
[2] <a href="http://www.iacpcybercenter.org/investigators/digital-evidence/understanding-digital-evidence/" rel="noopener nofollow ugc">http://www.iacpcybercenter.org/investigators/digital-evidence/understanding-digital-evidence/</a><br>
[3] <a href="https://www.amazon.com/Introdu%C3%A7%C3%A3o-Ciberseguran%C3%A7a-Internet-Aspetos-Portuguese/dp/9727228615/?tag=0x00sec03-20" rel="noopener nofollow ugc">Antunes, Mário, and Baltazar Rodrigues. Introdução à Cibersegurança. FCA, 2018.</a><br>
[4] <a href="https://www.forensicswiki.org/wiki/Write_Blockers" rel="noopener nofollow ugc">https://www.forensicswiki.org/wiki/Write_Blockers</a><br>
[5] <a href="https://www.nist.gov/sites/default/files/documents/2017/05/09/hwb-v2-post-19-may-04.pdf" rel="noopener nofollow ugc">Hardware Write Blocker Device (HWB) Specification, Version 2.0 (May 19 2004, NIST)</a><br>
[6] <a href="https://spqr.eecs.umich.edu/papers/bolton-blue-note-IEEESSP-2018.pdf" rel="noopener nofollow ugc">Blue Note: How Intentional Acoustic Interference Damages Availability and Integrity in Hard Disk Drives and Operating Systems</a></p>
            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/intro-to-digital-forensics-part-3-the-course-of-the-evidence/7194">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/intro-to-digital-forensics-part-3-the-course-of-the-evidence/7194</link>
          <pubDate>Thu, 21 Jun 2018 15:00:10 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-7194</guid>
          <source url="https://0x00sec.org/t/intro-to-digital-forensics-part-3-the-course-of-the-evidence/7194.rss">Intro to Digital Forensics [Part 3 - The course of the Evidence]</source>
        </item>
        <item>
          <title>Intro to Digital Forensics [Part 2 - Methodology and Process Models]</title>
          <dc:creator><![CDATA[n3xUs]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><strong>[+] METHODOLOGY AND PROCESS MODEL</strong></p>
<p>Today’s digital world is perpetually evolving, becoming an intrinsic part of our lives, reaching almost every aspect of our society. Criminal Investigations are no exception. However, having technical knowledge and using tools alone is not enough to fully and properly investigate a digital crime. As such, Digital forensic examiners must follow a well-defined process that goes beyond the technical aspect. Considering the legal aspect of a Digital Forensic Operation, the analysis and investigation must be performed methodically and with expertise, resulting in a detailed technical report, where <strong>every aspect</strong> of the operation must properly documented.</p>
<p>Any probative evidence, whether physical or digital, answers at least one of the tipical questions regarding an investigation: <strong>who</strong>, <strong>what</strong>, <strong>when</strong>, <strong>where</strong>, <strong>how</strong> and <strong>why</strong>.</p>
<p>The most commonly followed process regarding a digital forensic op consists of four steps: <strong>seizure</strong>, <strong>aquisition</strong>, <strong>analysis</strong> and <strong>reporting</strong>.</p>
<p><strong>&gt; Seizure</strong> - prior to the actual process of investigation, the digital media must be confiscated. As I previously mentioned, when dealing with a criminal investigation, this step is usually carried out by trained technicians of law enforcement. It’s in step that we differentiate two types of personnel:</p>
<ul>
<li>
<p>Digital Forensic Technician - these are the people that handle the seizure of evidence and are trained in good practices and correct handling of evidence and tech.</p>
</li>
<li>
<p>Digital Forensic Examiner - these are the people that handle the actual analysis of evidence. They have a broad knowledge over the subject or, as previously stated, they specialize in sub-field of analysis (i.e hardware).</p>
</li>
</ul>
<p>Analysing this data is in most cases quite time-consuming, so its often recommended to produce a mirror of the systems and analyse the images in the lab instead of on site. There a few questions first responders take into consideration:</p>
<ul>
<li>Is the computer running?</li>
<li>Is the computer networked?</li>
<li>Do you want to preserve volatile data?</li>
<li>Is there full-disk encryption applied?</li>
<li>Is the console unlocked?</li>
</ul>
<p><strong>&gt; Acquisition</strong> - consists in extracting the storage data in the system to examined. This step handles the recording of the physical scene and duplicate digital evidence using standardized, documented and accepted procedures, to guarantee evidence preservation and subsequent pobative validation. Like it’s stated in the previous step, an expert should always mirror the data, not handle it directly.</p>
<p><strong>&gt; Analysis</strong> - involves determination  of  the  significance and relevance,  reconstructing of  data and drawing conclusions based on the data recovered in the previous step.</p>
<p><strong>&gt; Presentation</strong> - refers to the production and presentation of the technical reports of the operation and their respective conclusion. The goal of this step is to demonstrate the probative value  of the incidents under investigation.</p>
<p>The above is a generalised process model. There are many established models out there, some that build upon this and each other. We will not go through them, as there is no universally accepted model, and there are new models appearing every now and then.</p>
<p>Some commonly discussed models are Abstract Digital Forenscics Model (ADFM), DFRWS and Integrated Digital Investigation Process (IDIP).</p>
<p><strong>EVIDENCE HANDLING</strong></p>
<p>In this section, we cover the principles of handling digital evidence.</p>
<p>First and foremost, <strong>actions taken to secure and collect digital evidence should not affect the integrity of that evidence</strong>. Failing to do this could lead to the inadmissabilty and invalidation of the evidence in court.</p>
<p>Second, only in special and stricly necessary occasions it is allowed to access the data directly.</p>
<p>Third, the examiner must create and routinely update the techincal report, where he documents his actions, why he did them and what where the outcomes (how it influenced the system). They should be documented in cronological order, thus establishing a Chain of Custody for the digital evidence. This way, this document should also allow another expert to run a “counter-forensic op” by following the same actions reported, confirming their outcomes.</p>
<p>Fourth, while handling and interacting with the evidence, the examiner must respect the current legislation, especially regarding the personal and private data protection laws. Of course, this will vary from country to country.</p>
<hr>
<p><strong>Sources:</strong></p>
<p>[1] <a href="https://www.researchgate.net/publication/228410430_Systematic_Digital_Forensic_Investigation_Model" rel="nofollow noopener">The Systematic Digital Forensic Investigation Model (SRDFIM) (Agarwal, et al., 2011)</a><br>
[2] <a href="https://www.amazon.com/Introdu%C3%A7%C3%A3o-Ciberseguran%C3%A7a-Internet-Aspetos-Portuguese/dp/9727228615/ref=sr_1_1?tag=0x00sec03-20" rel="nofollow noopener">Antunes, Mário, and Baltazar Rodrigues. Introdução à Cibersegurança. FCA, 2018.</a><br>
[3] <a href="https://resources.infosecinstitute.com/digital-forensics-models/" rel="nofollow noopener">https://resources.infosecinstitute.com/digital-forensics-models/</a><br>
[4] <a href="https://www.ncjrs.gov/pdffiles1/nij/199408.pdf" rel="nofollow noopener">Forensic Examination of Digital Evidence: A Guide for Law Enforcement (April 2004, NCJ 199408)</a><br>
[5] <a href="https://www.enisa.europa.eu/publications/electronic-evidence-a-basic-guide-for-first-responders" rel="nofollow noopener">Electronic evidence - a basic guide for First Responders (March 2015, ENISA)</a></p>
<hr>
<p>This covers <strong>Part 2 - Methodology and Process Models</strong>. I vividly recommend you check the sources listed in the articles (if you’re interested, of course), as they offer much more detailed and developed information. With these topics I’m trying to condense it a bit and making it more accesible.</p>
<p>Part 3 will cover “The course of the evidence”. We’ll talk about the course of the evidence, from the practiced crime to the presentation.</p>
            <p><small>4 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/intro-to-digital-forensics-part-2-methodology-and-process-models/7122">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/intro-to-digital-forensics-part-2-methodology-and-process-models/7122</link>
          <pubDate>Fri, 15 Jun 2018 14:07:20 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-7122</guid>
          <source url="https://0x00sec.org/t/intro-to-digital-forensics-part-2-methodology-and-process-models/7122.rss">Intro to Digital Forensics [Part 2 - Methodology and Process Models]</source>
        </item>
        <item>
          <title>Intro to Digital Forensics [Part 1 - Digital Evidence]</title>
          <dc:creator><![CDATA[n3xUs]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Hello again! The results of the poll from my last post are very clear, so I’ve decided to go forward with the “<strong>Intro to Digital Forensics</strong>” topic</p>
<p>Like I previously mentioned, this post will cover various topics regarding Digital Forensics, hopefully serving as a good introduction to the field. I’m not an expert in the matter, meaning this post might contain a few errors and misconceptions as it will be based on my limited knowledge. That being said, we are all still learning, so if you see something that isn’t right, dont’ be afraid to say so in the comments and help us all learn.</p>
<p>Midway through writing this, I decided to separate the topic into various parts, as to not overwhelm the readers.</p>
<p>Let’s get to it then!</p>
<hr>
<pre><code>INTRO TO DIGITAL FORENSICS
</code></pre>
<p><strong>Digital Forensics</strong> (or Computer Forensics) is one the most recent branches of the Forensic Sciences, focusing on the <strong>recovery</strong> and subsequent <strong>analysis</strong> / investigation of digital data as a means to produce digital evidence with <strong>probationary validity</strong> in court. What I mean is, you can’t simply present something in court and call it evidence.</p>
<p>As such, it becomes necessary to ensure the preservation of digital evidence through its appropriate seizure, acquisition, analysis, identification, validation, interpretation, documentation and, finally, presentation.</p>
<p>As you can see, this is a very long and complex process. Given it’s complexity, a Digital Forensics Operation quite often requires a specialized and multidisciplinary team. Some may specialize in Network Forensics, others in Mobile Forensics. Some Ops might even need experts in various computer related fields (i.e hardware, databases, telecommunications, etc).</p>
<p>Through out this article I will focus on the more Legal / Court related aspect of Digital Forensics, as opposed to the Private Investigations side of it, even though they are quite the same, technically.</p>
<p><strong>[+] DIGITAL EVIDENCE</strong></p>
<p>The word <strong>evidence</strong> refers to the body of facts that prove whether a given proposition is true or valid. However, the concept of <strong>Digital Evidence</strong> is a bit more specific. As such, it can be defined by any type of probative information stored in any digital/electronic storage media, or transmitted through public or private computer/communications networks. Simplifying, it’s any (probative) data/information stored or transmitted in digital/binary form.</p>
<p>More and more often, we produce astounding amounts of data, meaning that it is becoming quite ubiquitous. So, even though digital evidence is usually associated with Computer and e-crime, it is now being used to prosecute all sorts of crimes (for example, a recovered email may reveal an intent or motive to commit a crime, maybe even a whereabout on a missing person).</p>
<p>When comparing both traditional and digital evidence, we’ll see that they share a few similarities:</p>
<ul>
<li>
<p>They are both fragile and can be easily manipulated, damaged or destroyed;</p>
</li>
<li>
<p>They can easily cross geographical and jurisdictional borders , either physically or through the Internet;</p>
</li>
<li>
<p>Their value frequently depends on the exact date/time and location they are produced (they are time sensitive);</p>
</li>
</ul>
<p>Some problems we face when dealing with Digital Evidence are:</p>
<ul>
<li>
<p>Its tangibilty (or lack thereof). As oposed to traditional evidence, which is physical, digital eveidence is usually untangible;</p>
</li>
<li>
<p>The ubiquity of data. Given the world wide spread of the Internet and its services and the sheer quantity and diversity of information that can be produced, altered, transmitted and deleted in such a short amount of time, makes it quite difficult to handle and control (whether physical or logical). Not to mention the use of Cloud services, which are more and more often taking data away from our hands;</p>
</li>
</ul>
<p><strong>Principle of Evidence</strong></p>
<p>Returning to the comparison of the the traditional and digital evidence, we see that both must rely on and respect the same fundamentals:</p>
<ul>
<li>
<p><strong>Admissability</strong> - must be in accordance with the current legislation. How it is seized, acquired, analysed, etc, must respect the law in effect;</p>
</li>
<li>
<p><strong>Authentication</strong> - the evidence must be legitimate and untampered with;</p>
</li>
<li>
<p><strong>Complete</strong> - to prove its integrity, the full evidence must be presented, not just the “convenient” bits;</p>
</li>
<li>
<p><strong>Realiable</strong> - the forensic expert must be able to describe and explain all the actions taken regarding the evidence;</p>
</li>
<li>
<p><strong>Believable</strong> - the evidence must be comprehensible;</p>
</li>
</ul>
<p>To respect these principles, we’ll highlight two main requirements.</p>
<ol>
<li>
<p>The evidence <strong>must</strong> be legally admissable regarding its seizure (<em>theoretically</em>, any evidence that is illegally obtained, is discarded and unadmissable in court). This should only be done by trained technicians (of law enforcement, in criminal cases) to ensure the preservation of evidence;</p>
</li>
<li>
<p>The evidence <strong>must</strong> be technically undeniable regarding its origin (the source of the information must be verifiable and irrefutable) and its integrity;</p>
</li>
</ol>
<p><strong>Acquiring Digital Evidence</strong></p>
<p>When acquiring digital evidence, one must take caution to minimize and mitigate the impact in a given system, accessing it in the least destructive way possible, as to avoid altering the data within.</p>
<p>However, this is quite hard to attain, considering that a computer system is usually in a state of continous changes. In fact, when dealing with a live system (that is, when you need to operate in system that is powered on), there’s always a change of state, due to opening a file, a program or even altering RAM content. As such, this risk must be consciously accepted and taken to account by the forensic team. Any forensic expert must be extremely aware of how his actions are influencing and impacting the system in question.</p>
<p>One of the ways to mitigate this risk is to consider component volatility. You should begin extraction  from the most volatile components (i.e RAM) to the least volatile ones (i.e HDD). Below is an example of a possible extraction scenario:</p>
<ol>
<li>When the computer is powered on, list and identify the contents of the RAM;</li>
<li>Identification of Network Interfaces;</li>
<li>Identification of running processes and their respective state;</li>
<li>List the active TCP/UDP ports;</li>
<li>List and identify the registered and active user accounts;</li>
<li>List and identify the contents of page files and swap areas;</li>
<li>List and identify the contents of the file system, considering the volumes and partitions present on the disk;</li>
<li>List and identify the various hardware devices connected to the system;</li>
</ol>
<hr>
<p><strong>Sources:</strong></p>
<p>[1] <a href="https://en.wikipedia.org/wiki/Digital_forensic_process" rel="nofollow noopener">https://en.wikipedia.org/wiki/Digital_forensic_process</a><br>
[2] <a href="https://en.wikipedia.org/wiki/Digital_forensics" rel="nofollow noopener">https://en.wikipedia.org/wiki/Digital_forensics</a><br>
[3] <a href="https://www.nij.gov/topics/forensics/evidence/digital/Pages/welcome.aspx" rel="nofollow noopener">https://www.nij.gov/topics/forensics/evidence/digital/Pages/welcome.aspx</a><br>
[4] <a href="http://www.iacpcybercenter.org/topics/digital-evidence/" rel="nofollow noopener">http://www.iacpcybercenter.org/topics/digital-evidence/</a><br>
[5] <a href="https://www.amazon.com/Introdu%C3%A7%C3%A3o-Ciberseguran%C3%A7a-Internet-Aspetos-Portuguese/dp/9727228615/ref=sr_1_1?tag=0x00sec03-20" rel="nofollow noopener">Antunes, Mário, and Baltazar Rodrigues. Introdução à Cibersegurança. FCA, 2018.</a></p>
<hr>
<p>This marks the end of <strong>Intro to Digital Forensics [Part 1 - Digital Evidence]</strong>. I hope you enjoyed and learned something by reading this article. The next entry will cover <strong>Methodology and Procedures</strong>. Please don’t hesitate to ask any questions or to correct anything you think is wrong in the comments.</p>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/intro-to-digital-forensics-part-1-digital-evidence/7119">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/intro-to-digital-forensics-part-1-digital-evidence/7119</link>
          <pubDate>Fri, 15 Jun 2018 09:49:33 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-7119</guid>
          <source url="https://0x00sec.org/t/intro-to-digital-forensics-part-1-digital-evidence/7119.rss">Intro to Digital Forensics [Part 1 - Digital Evidence]</source>
        </item>
        <item>
          <title>Tyrannosaurus reproduced fast and died young: A malicious host/IP/C&amp;C from China, 2016 to present</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>A portion of the title of this post refers to an idea put forth by Gregory S. Paul in the book “Tyrannosaurus: Tyrant King”; as both a (probable) scavenger and predator living during dangerous times, the T.Rex does not seemed to have had an exceptionally long life span.</p>
<p>I find this a fitting metaphor for the host machines (and its IP) utilized for offensive/malicious purposes by many types of actors: I have the feeling many reproduce relatively quickly (through RATs, backdoor shells, created slave nodes, creds created and/or harvested by bruteforcing/spidering/dorking/scraping, etc.) and  have short lives in the wilds of the Internet (when utilized for pure offense purposes/illegal commerce) relative to the uptime of similar, less aggressive machines/IP: whether hunted down by researchers, shutdown by authorities or hosting providers, abandoned by those who established them, etc…</p>
<p>Many of the host/IP utilized in this way will be both scavenger and predator: constant port scanning looking for instances of default/hardcoded credentials to exploit looks like a digital buzzard circling the sky to my mind’s eye…</p>
<p>In my work as a Penetration Tester/Red Teamer, it has been important for me to follow the goings on of Black Hats in the wild first hand.</p>
<p>In general, during most engagements I believe it is important to realistically create the methodology/tactics currently utilized by real world actors.</p>
<p>At the very least,  being as close as possible to this bleeding edge<br>
helps me to`better analyze/relate/put into context the results of an engagement and/or best assess the client’s security posture in relation to the results of an engagement.</p>
<p>In doing this, there are many “resources” I seek out and  keep an eye on in their native environments; think more watching the wildlife of the African Sahara in real time rather than waiting for a documentary to complete production after 6 months of post production (many of those metaphorical zebras will be eaten by the metaphorical lions by the time you watch it).</p>
<p>One of my views on the predatory wildlife of the Internet has been my watching and charting a host/IP from China that has been active from 2016 to present day, and has been pretty noisy/blatant during that time.</p>
<p>This post will look at periods in the existence of a host machine/IP that has continually been utilized in offensive/malicious activity from at least June of 2016 to present day.</p>
<p>The IP/host in question is 183.129.160.229, a China based host/IP active in malicious/offensive activities from at least 6/2016 to present day (references will be cited during or at the end of this  post).</p>
<p>PLEASE NOTE: Well into my watching this IP (which started with my investigating the IP for a client), the host machine had a completely different configuration on Shodan (an SSH port on standard 22, the remainder of ports being a dozen or so instances of NTP); this has since changed to a single SSH port while the NTP ports have been closed or (tunneling through or Denial of Service by) use of NTP/UDP services/protocols through these ports suspended.</p>
<p>Also, a great number of paleontologists now theorize the Tyrannosaurus looked like this (protofeathers provide Chicken-tarrasque with AC 2 and force a saving throw vs. fear or player suffers the effects of Tasha’s Hideous Laughter for 1d4 rounds):</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/e/ec991821fbdc259ac56a0e458ecd2913e77404c2.png" alt="trex" data-base62-sha1="xL2GwV6oHG289QAL0FdxNGiFG7g" width="690" height="287"></p>
<hr>
<p><strong><em>183.129.160.229: Basic Data, Rise and Stabilization</em></strong></p>
<p><strong>Who is Data of 183.129.160.229 (from <a href="https://whois.domaintools.com" rel="noopener nofollow ugc">https://whois.domaintools.com</a></strong>):</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/b588e4f4358c284fd87b1ec3d27a381fe06f4b49.png" alt="229" data-base62-sha1="pTVIrWoeTgnvTVxuLu73qMWUOQ9" width="317" height="500"></p>
<p><strong>Geographical location of host/IP location (from <a href="https://whatismyipaddress.com" rel="noopener nofollow ugc">https://whatismyipaddress.com</a> and OpenStreetMap):</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/0/040c4cfcb650894aa36a04017639963f37c10154.png" alt="map" data-base62-sha1="zOgn6QuheohxH2xo8ENhfSRbmY" width="401" height="402"></p>
<p><strong>Month by Month Activity Graphs and accompanying data for 183.129.160.229  from X-Force Exchange IBM with Server Logs Reporting Abuse (Multiple Sources):</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/8/8f800ff71cbfe91cf980d9705e185bba54674a0f.png" alt="ibmdata" data-base62-sha1="ktsEl02t1PMjMDP0nMSp4IIAAZp" width="690" height="434"></p>
<p><strong>X-Force IBM begins to detect/chart the activity of the IP in June2016, this represents the full graph to present (directly below)</strong>:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/7/7e7f0a74fdd3db90c85a80a2d1ab06b8c70d4725.jpeg" alt="IBMFUllgraph" data-base62-sha1="i32lok479Dbxw4r696RBOKhUgXb" width="690" height="206"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/6/61803332dc9d28034063413b485637ebac292a74.png" alt="g1" data-base62-sha1="dUwYSfIs7As2V2zCxUdsQRDzMFe" width="640" height="220"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/f/fb5475085dadc3ad0ae0032aff0e02e5deb037c0.png" alt="2" data-base62-sha1="zRmNd1AsCzxd3au4PBblUctuURG" width="643" height="218"></p>
<p><strong>X-Force IBM data of 183.129.160.229 for July 2016 ); further commentary picks up in August 2016:</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/b/b47cac50882acc523d2643e5e8ac47bc81784518.png" alt="3" data-base62-sha1="pKF3rCO1VgckjZXmT65GoDI5jBu" width="640" height="223"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/2/2234ae8d67ee2ee866eaabcb94d2f93ef832a9c7.png" alt="4" data-base62-sha1="4SB6t2hUm2oQoOD45ZtRo3E7qVF" width="638" height="221"></p>
<p><strong>X-Force IBM data of 183.129.160.229 for August 2016:</strong><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/0/0ec8a7f39b2c00025a5d444c3f9b1109ea3b37ef.png" alt="5" data-base62-sha1="26MAt5SgqynYdmgAOqtTHAo5Glp" width="640" height="219"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/f/f914d6c39a308705fd5cf3c481265e2d86a57a81.png" alt="6" data-base62-sha1="zxtxjtYFgBuGPf1Xd4Dl43J4Lkt" width="641" height="223"></p>
<p>In August 2016 the wider internet begins to notice the activity:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/4/4adc9cfa5fe588ff968bdc219bb6f8405249a61d.png" alt="awslogs8_16" data-base62-sha1="aGfZEurayGDgfHvoN2FCZLNaGKN" width="666" height="500"></p>
<p><strong>PLEASE NOTICE THE USER AGENT MAKING THE REQUESTS IN THE IMAGE ABOVE!!!</strong><br>
<strong>Even though this IP is acting through the Great Firewall to reach foreign sites, and even though China’s officials have shown great skill/use of resources in defeating/exploiting multiple means of encapsulation/encryption utilized by its citizens in attempting to circumvent the Great Firewall, the user agent associated with this IP (Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0) rarely ever shows any variation during the almost two years covered in this post.</strong></p>
<p><strong>In 8/2016, reports of abuse start to be reported to the Black Hat Directory (<a href="https://blackhat.directory/ip/183.129.160.229/31#comments" rel="noopener nofollow ugc">https://blackhat.directory/ip/183.129.160.229/31#comments</a>):</strong></p>
<p>Anonymous Port scan 2016-08-29 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-08-30 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-08-29 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Similar Activity throughout September and October 2016:</strong><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/a/aa5c135cbab4d55be7a0439a5592982094b14040.png" alt="7" data-base62-sha1="oj4rlDgPd0tb1CKXJ9cmXaZx5ss" width="639" height="223"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/6/65bc1b263279a0bbbe0003a566acfbfd80fd5545.png" alt="8" data-base62-sha1="evZeS4ghZMefCDkF30m0i4JA2eF" width="641" height="221"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/e/e673b2018f57ac591c51cae246af37bedf3c889f.png" alt="9" data-base62-sha1="wSFH2XrNYG899AveDsF9QwfgmhV" width="642" height="223"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/8/8c793bef58b9cbe50b676de222bafed15123de54.png" alt="10" data-base62-sha1="k2GAve7Qglk9sZGW7RIRLY2GF8M" width="641" height="223"></p>
<p><strong>As illustrated through the X-Force IBM generated activity graphs above, throughout the later quarter of 2016, the host/IP established an intensive port scanning (or perhaps periods of a denial of service campaign utilizing port scanning/port scanning like traffic, those this seems less likely) campaign that continues to this day:</strong></p>
<p><strong>Corresponding data found in Black Hat Directory Abuse logs:</strong></p>
<p>Anonymous Port scan 2016-09-30 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-09-29 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-09-03 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-09-02 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-09-01 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-04 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-03 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-02 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-01 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-05 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-15 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-14 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-13 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-12 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-11 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-10 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-09 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-07 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-06 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-27 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-26 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-2 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-24 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-22 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-21 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-20 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-19 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-18 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-10-28 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>And the IP caught in other logs with the same user agent</strong>:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/3/372432c606a9d83c9f7757dba4c2a2a235dc4978.png" alt="webappslog" data-base62-sha1="7RNOyA4iDcnUdhk1gqqLMChSXig" width="666" height="500"></p>
<p><strong>November 2016 sees port scanning activity recover from the Dive at the end of October 2016 while Bot activity remains erratic and not yet stabilized:</strong></p>
<p>Anonymous Port scan 2016-11-23 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-22 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-20 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-19 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-18 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-17 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-16 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-15 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-13 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-12 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>At this point, 183.129.160.229 is like a new born predator: it is just getting used to its predatory senses (port scanning is shaky but shows periods of stability), it is beginning to stand and maneuver but occasionally falls (short periods of activity spiking/outage of port scanning/bot activity)…</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/a/ae3b4ed1f84b24838a3e709ba5a2667c245851dd.png" alt="11" data-base62-sha1="oRk94Se6aqzgKTUaeCdqj67Xg8l" width="641" height="223"></p>
<p><strong>However, it actively picks up the tempo of its predation in late November into December 2016 and onward.</strong></p>
<p><strong>We have a couple of gentleman at <a href="https://amcrest.com/forum/technical-discussion-f3/weird-alarm-event-illegal-access-local-storage-fro-t1887.html" rel="noopener nofollow ugc">https://amcrest.com/forum/technical-discussion-f3/weird-alarm-event-illegal-access-local-storage-fro-t1887.html</a> communicating about the IP/host in question exploiting residential cams:</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/6/6775fde19a88ec0e02909c45387a3392dcfdc809.png" alt="Hackedwebcam1" data-base62-sha1="eLfYu2Si8y9K1fV6sjMmNgFXmIh" width="666" height="500"><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/c/c5a578d4e58b964542e15b399396ec7e37c47c2d.png" alt="Hackedwebcam2" data-base62-sha1="scsAc7XvBkAehfQetKRR9e0ZS57" width="666" height="500"></p>
<p><strong>By December 2016, it appears that 183.129.160.229 was scanning for and targeting HP printer JetAdmin vulnerabilities (such as HP Web 6.5 Server Arbitrary Command Execution) though it does not appear to have been targeting the SNMP HP JetAdmin Password variation of the vulnerability yet (logs detailing Nmap/port scans have been TCP based Syn and Connect scans so far).</strong></p>
<p><strong>Examples from logs from Black Hat Database <a href="https://blackhat.directory/ip/183.129.160.229/26#comments" rel="noopener nofollow ugc">https://blackhat.directory/ip/183.129.160.229/26#comments</a>):</strong></p>
<p><strong>Anonymous Port scan 2016-11-30 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</strong></p>
<p>Anonymous Port scan 2016-11-30 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-29 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-27 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-26 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-11-25 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2016-12-04 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</strong></p>
<p>Anonymous Port scan 2016-12-04 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2016-12-03 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</strong></p>
<p>Anonymous Port scan 2016-12-03 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-09 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-07 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-06 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-05 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2016-12-12 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</strong></p>
<p>Anonymous Port scan 2016-12-12 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-09 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-14 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-13 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2016-12-16 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>X-Force IBM then reports a nose dive in activity at the end of December 2016/beginning of January 2017, and the logs at Black Hat Directory also do not report abuse until 1/11/2017; this could be due to factors in relation to countries that celebtate a holiday season in late December/early January.</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/0/01f73a4af1b6371f04f5d5c26d04f0be8cb457c3.png" alt="13" data-base62-sha1="ho9WwU6RgSfynb6uG6OOj0XYPN" width="639" height="223"></p>
<p><strong>However, before the second week of January 2017 183.129.160.229 is back in action(may be inline with the commencement of business in countries that celebrate late December/early January holidays. as abuse reports at Black Hat Directory begin again on January 11th 2017, <a href="https://blackhat.directory/ip/183.129.160.229/25#comments" rel="noopener nofollow ugc">https://blackhat.directory/ip/183.129.160.229/25#comments</a>. inline with X-Force IBM detected activity)</strong></p>
<p><strong>183.129.160.229 appears to have  evolved in order detect opportunities for SNMP based JetAdmin password vulns (NMap -sU/UDP scan abuse begins to be reported to Black Hat Directory, <a href="https://blackhat.directory/ip/183.129.160.229/24#comments" rel="noopener nofollow ugc">https://blackhat.directory/ip/183.129.160.229/24#comments</a>) and abuse against SNMP will begin to be reported to Black Hat Directory.</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/0/0e27baa77879036985f4d23e40b932708370fefe.png" alt="14" data-base62-sha1="21dNPUUHZdcXnovMhWqrd4yNR1k" width="641" height="220"></p>
<p>Anonymous Port scan 2017-01-11 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2017-01-11 Nmap ( -sU scan): port scan detected</strong></p>
<p>Anonymous Port scan 2017-01-16 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-01-16 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2017-01-18 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>AnonymousPort scan 2017-01-17 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2017-01-16 Nmap ( -sU scan): port scan detected</strong></p>
<p>Anonymous Port scan 2017-01-21 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2017-01-22 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-01-20 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<pre><code>____________________________________________________
</code></pre>
<p><strong><em>183.129.160.229 opens its eyes, studies its environment and than attacks new prey</em></strong></p>
<p><strong>We skip looking at Black Hat Directory’s logs until mid February thru March of 2017. Though the host/IP was detected scanning/attacking the targets covered earlier, mid February 2017 and onward shows evidence of 183.129.160.229 beginning to attack (and presumably scan for) multiple other vulnerabilities, including what was likely to have been instances of SQL Databases with default creds or versions with known vulnerabilities (as reported to Black Hat Directory, <a href="https://blackhat.directory/ip/183.129.160.229/22#comments" rel="noopener nofollow ugc">https://blackhat.directory/ip/183.129.160.229/22#comments</a>).</strong></p>
<p><strong>As the attacks on the MySQL Servers are being reported as a port scan, it is possible the host/IP is attacking through a means such as NMap NSE scripts which may detect and attack a target through means such as bruteforcing.</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/7/7d82afe0898774782e4b9aff305e9d981ec79fb6.png" alt="15" data-base62-sha1="hUjG7P91dQSoGGnFkldmeQNCZbU" width="641" height="219"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/a/a376f3394e308e7149666a1c7c578be24ecb8729.png" alt="16" data-base62-sha1="nk4FYHHElELQAfK8oAkXlYyVO3f" width="641" height="227"></p>
<p>Anonymous Port scan 2017-02-17Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2017-02-18 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2017-02-21 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2017-02-21 src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</strong></p>
<p>Anonymous Port scan 2017-02-22 src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-02-22 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p><strong>Anonymous Port scan 2017-02-23 src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</strong></p>
<p>Anonymous Port scan 2017-02-23 Nmap (Nmap -sT or -sS scan): port scan detected</p>
<p>Anonymous Port scan 2017-03-01 Port scan detected by psad: Nmap (Nmap -sT or -sS scan):</p>
<p><strong>Anonymous Port scan 2017-03-01 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</strong></p>
<p><strong>Perhaps the attacks were successful thanks to the widening target variation, as X-Force IBM detects a unstable resurgence in Bot activity soon after.</strong><br>
<img src="//0x00sec.s3.amazonaws.com/original/2X/6/6dca4ec7700f9fa76717f4259a0a296ebc33cdff.png" alt="17" data-base62-sha1="fFfuasIliXGspLHKXOm8roqJNCf" width="644" height="223"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/5/5d9902174fba6796a563cefdbf7699dfd4e7ce91.png" alt="18" data-base62-sha1="dm0dQ8p2SxjOyzrjpRBBVcoak7v" width="641" height="223"></p>
<p><strong>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</strong></p>
<p><strong>Below, this sample of  Black Hat Directory abuse logs show that 183.129.160.229 is also scanning for/attacking a new target in “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9000"</strong></p>
<p><strong>This may be an attempt at the Raw/App Sock protocol of this printer which sometimes also resides at Port 9100.</strong></p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9000</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: Nmap (Nmap -sT or -sS scan):</p>
<p>Anonymous Port scan 2017-04-09 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-04-09 Port scan detected by psad: Nmap (Nmap -sT or -sS scan):</p>
<p>Anonymous Port scan 2017-04-08 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</p>
<p>Anonymous Port scan 2017-04-07 Port scan detected by psad: src: 183.129.160.229 signature match: “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9000</p>
<p>Anonymous Port scan 2017-04-06 Port scan detected by psad: Nmap ( -sU scan):</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9000</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-04-18 Port scan detected by psad: Nmap (Nmap -sT or -sS scan):</p>
<p>Anonymous Port scan 2017-04-09 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>Anonymous Port scan 2017-04-09 Port scan detected by psad: Nmap (Nmap -sT or -sS scan):</p>
<p><strong>Anonymous Port scan 2017-04-08 Port scan detected by psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</strong></p>
<p><strong>Anonymous Port scan 2017-04-07 Port scan detected by psad: src: 183.129.160.229 signature match: “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9000</strong></p>
<p>Anonymous Port scan 2017-04-06 Port scan detected by psad: Nmap ( -sU scan)</p>
<hr>
<p><em>**183.129.160.229 During the Height of the ShadowBroker’s and Wannacry Period/Petya/NotPetya/Why the hell is SMB/Samba still facing the outside world? Period **</em></p>
<p><strong>As later logs will show, DoublePulsar/EternalBlue/Eternal Romance (and the other NSA exploits/exploit kits released by ShadowBrokers in mid April 2017) use has persisted from 183.129.160.229 well into 2018.</strong></p>
<p><strong>This is not surprising, as the exploits still seem to serve me well as a valuable option for exploitation while within a LAN post ingress during penetration testing/Red Team engagements (reminiscent to how NetAPI exploitation of WIndows XP/Server 2003 served me well within LANs a bit short of a decade or so ago).</strong></p>
<p><strong>While many networks may have hardened their perimeter machines against these tools, the hosts within target intranets tend to be (at least) a bit more vulnerable to these tools (though there is always the noise of surrounding defensive technologies to consider).</strong></p>
<p><strong>For these purposes we will date this period from mid April 2017 thru until July 1st 2017,and since similar topics have been dropkicked to death elsewhere, we will only briefly look at the X-Force IBM based logs for this section.</strong></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/5/5d9902174fba6796a563cefdbf7699dfd4e7ce91.png" alt="18" data-base62-sha1="dm0dQ8p2SxjOyzrjpRBBVcoak7v" width="641" height="223"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/1/148f5da5b0bf824d9937c46a9ae09e07777d70d1.png" alt="19" data-base62-sha1="2VSHYjyGgywChqGm3HTVMsgfKvf" width="640" height="222"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/4/42c6c88e7e18d1647f858df6382b3bc4dd1800b2.png" alt="20" data-base62-sha1="9wJp5aOOhdRDaNpLtIA2VXYi6eC" width="633" height="220"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/f/fa4f884933bf33bf41879d4d5a06559df7104f4c.png" alt="23" data-base62-sha1="zIlLqmu1f859k2IgxIQGc5nXJ6I" width="641" height="224"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c53377967ab16d618db0df4f8cdff78abb2ec2b2.png" alt="24" data-base62-sha1="s8wkqF9wMVVdJdMqHNc9JLmFCFQ" width="633" height="228"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/9/901ec2427cfa2f45544ac3520b8e852752a7cc6f.png" alt="26" data-base62-sha1="kyWEGxqa3oJ7WuS8SftVavnDMCz" width="631" height="223"></p>
<hr>
<p><strong>Interesting entries from the Abuse IPDB for  183.129.160.229 from 2017 to Present:</strong></p>
<p>Beginning from earliest report on <a href="https://www.abuseipdb.com/check/183.129.160.229?page=132#report:" rel="noopener nofollow ugc">https://www.abuseipdb.com/check/183.129.160.229?page=132#report:</a></p>
<blockquote>
<p>“This IP was reported 1337 times. Confidence of Abuse is 67%”</p>
</blockquote>
<p><strong>By December 2017, the quantity of attacks/targets originating from this IP/Host have truly diversified, while user-agents caught from 183.129.160.229 only seem to utilize 1 of 2 user-agents:</strong></p>
<p>02 Dec 2017 	[portscan] tcp/1433 [MsSQL]<br>
02 Dec 2017 	[portscan] tcp/1433 [MsSQL]<br>
02 Dec 2017 	[portscan] tcp/1433 [MsSQL]</p>
<p>02 Dec 2017 	[SMTPD] RECEIVED: EHLO [183.129.160.229] in <a href="http://blocklist.de" rel="noopener nofollow ugc">blocklist.de</a>:“listed [mail]” in DroneBL:“listed [SOCKS Proxy]”<br>
Email Spam  JCB 02 Dec 2017 183.129.160.229 - - [10/Nov/2017:02:33:20 +0200] “GET /ws_utc HTTP/1.1” 404 204 “-” “Mozilla/5.0 (WET /ws_utc HTTP/1.1” 404 204 “-” “Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0” 183.129.160.229 - - [10/Nov/2017:02:33:21 +0200] “\x16\x03\x01” 400 226 “-” “-”</p>
<p><strong>Notice in the entry above from <a href="https://www.abuseipdb.com/check/183.129.160.229?page=131#report" rel="noopener nofollow ugc">https://www.abuseipdb.com/check/183.129.160.229?page=131#report</a> we have a similar user agent making the HTTP request as mentioned earlier, except we have a Windows 7 machine making the request.</strong></p>
<p><strong>This machine likely serves as a SOCKS proxy for some manner or type of the offensive/malicious traffic leaving the host.</strong></p>
<p>02 Dec 2017 	[portscan] tcp/21 [FTP]<br>
02 Dec 2017 	FTP fake admin login</p>
<p><strong>Entries below mark the beginning of reports of attacks against web applications, usually through GET or curl requests that target sensitive files/directories.</strong></p>
<p>02 Dec 2017 [httpReq only by ip - not DomainName] [multiweb: req 2 domains(hosts/ip)] “GET /ws_utc” [random UserAgent: 2]:<br>
UA:empty. UA:"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0"in <a href="http://blocklist.de" rel="noopener nofollow ugc">blocklist.de</a>:“listed [sasl]”<br>
in DroneBL:“listed [SOCKS Proxy]”</p>
<p>02 Dec 2017 	<br>
] [!] [Thu Nov 09 2017 22:26:49] (183.129.160.229) (/ws_utc) - ({“host”:“host.ip:80”,“user-agent”:“Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0”,“accept”:“text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8”,“accept-language”:“zh,en-US;q=0.7,en;q=0.3”,“dht”:“1”,“upgrade-insecure-requests”:“1”,“accept-encoding”:“gzip”})<br>
] [!] [Thu Nov 09 2017 22:58:41] (183.129.160.229) (/ws_utc) - ({“host”:“host.ip:443”,“user-agent”:“Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0”,“accept”:“text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8”,“accept-language”:“zh,en-US;q=0.7,en;q=0.3”,“dht”:“1”,“upgrade-insecure-requests”:“1”,“accept-encoding”:“gzip”})</p>
<p><strong>Below, we are back to the same user agent as we first mentioned utilizing a a OSX 10.11 OS for what looks like a SOCKS proxy request to the victim machine:</strong></p>
<p>02 Dec 2017 	<br>
[httpReq only by ip - not DomainName]<br>
UA:“Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0”<br>
in DroneBL:“listed [SOCKS Proxy]”</p>
<p>02 Dec 2017 Trusted domain error. 183.129.160.229 tried to access</p>
<p><strong>Below, still targeting HP Printers over a year later:</strong></p>
<p>02 Dec 2017 Nov 3 08:21:51 psad: src: 183.129.160.229 signature match: “POLICY HP JetDirect LCD communication attempt” (sid: 510) tcp port: 9001</p>
<p>02 Dec 2017 	Attempt to access invalid virtual host name (###.###.###.##<span class="hashtag">#:80</span>). Typically used to access “internal” resources improperly exposed externally and “protected” only by a lack of external DNS resolution.183.129.160.229 - - [02/Nov/2017:05:40:54 +0000] “GET /wls_utc HTTP/1.1” 403 169 “-” “Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0” “-”</p>
<p>02 Dec 2017 	[ThuNov0208:24:51.2896232017][:error][pid8058][client183.129.160.229]ModSecurity:Accessdeniedwithcode403(phase1).RBLlookupof229.160.129.183.xbl.spamhaus.orgsucceededatREMOTE_ADDR(Illegal3rdpartyexploits).[file"/usr/local/apache/conf/modsec_rules/00_asl_rbl.conf"][line"51"][id"350000"][rev"2"][msg"GlobalRBLMatch:IPisonthexbl.spamhaus.orgBlacklist(<a href="http://ReportFalsePositivestowww.spamhaus.org" rel="noopener nofollow ugc">ReportFalsePositivestowww.spamhaus.org</a>)"][severity"ERROR"][hostname"creativedigital.ch"][uri"/"][unique_id"WfrIQ1ERGeYAAB96XeQAAAAB"][ThuNov0208:24:52.9081182017][:error][pid5410 [client183.129.160.229]ModSecurity:Accessdeniedwithcode403(phase1).RBLlookupof229.160.129.183.xbl.spamhaus.orgsucceededatREMOTE_ADDR(Illegal3rdpartyexploits).[file"/usr/local/apache/conf/modsec_rules/00_asl_rbl.conf"][line"51"][id"350000"][rev"2"][msg"GlobalRBLMatch:IPisonthexbl.spamhaus.orgBlacklist(<a href="http://ReportFalsePositivestowww.spamhaus.org" rel="noopener nofollow ugc">ReportFalsePositivestowww.spamhaus.org</a>)"][severity"ERROR"][hostname"81.17.25.236"][uri"/wls_utc"][unique_id"WfrIRFERGeYAABUi54wAAAAQ"][ThuNov0208:2</p>
<p>02 Dec 2017 TCP src-port=50757 abuseat-org zen-spamhaus eatingmonkey 184</p>
<p>02 Dec 2017 	[portscan] tcp/1433 [MsSQL] [portscan] tcp/22 [SSH]<br>
[scan/connect: 2 time(s)]</p>
<p>02 Dec 2017 Sep 19 04:17:46 psad: src: 183.129.160.229 signature match: “MISC MS Terminal Server communication attempt” (sid: 100077) tcp port: 3389</p>
<p>02 Dec 2017 FTP/21 MH Probe, Scan, BF, Hack -<br>
02 Dec 2017 	[portscan] tcp/1433 [MsSQL]</p>
<p>02 Dec 2017 Sep 17 22:43:41 psad: src: 183.129.160.229 signature match: “MISC Microsoft SQL Server communication attempt” (sid: 100205) tcp port: 1433</p>
<p>02 Dec 2017 Sep 18 00:16:30 psad: src: 183.129.160.229 signature match: “MISC Microsoft PPTP communication attempt” (sid: 100082) tcp port: 1723</p>
<p><strong>Below, we have our promised attacks against SNMP, which has remained and grown in importance as a target for recon and exploitation given the rise of SCADA/PLC and IoT facing internet devices.</strong></p>
<p><strong>It is possible the SNMP bruteforcing in question is against such targets as default community strings or HP Printer JetAdmin Password vulns:</strong></p>
<p>02 Dec 2017 SNMP/161 MH Probe, BF -Brute-Force<br>
smel</p>
<p>02 Dec 2017 SNMP/161 MH Probe, BF -Brute-Force<br>
smel</p>
<p>02 Dec 2017 SNMP/161 MH Probe, BF -</p>
<p>02 Dec 2017 SNMP/161 Probe, BF, Hack -</p>
<p>02 Dec 2017 Sep1807:35:43server2sshd[30423]:refusedconnectfrom183.129.160.229(183.129.160.229)Sep1807:39:52server2sshd[30617]:refusedconnectfrom183.129.160.229(183.129.160.229)Sep1807:44:07server2sshd[31259]:refusedconnectfrom183.129.160.229(183.129.160.229)Sep1807:44:18server2sshd[31275]:refusedconnectfrom183.129.160.229(183.129.160.229)Sep1807:44:57server2sshd[31342]:refusedconnectfrom183.129.160.229(183.129.160.229)</p>
<p>02 Dec 2017 unauthorized ssh connection attempt</p>
<p>02 Dec 2017 Firewall-block on port: 1701</p>
<p>02 Dec 2017 SNMP/161 MH Probe, BF -</p>
<p>02 Dec 2017 port scan and connect, tcp 4899 (radmin)</p>
<p>03 Dec 2017 	MH/MP Probe, Scan -</p>
<p>03 Dec 2017 	[portscan] tcp/102 [TSAP]</p>
<p>03 Dec 2017 	Firewall-block on port: 502</p>
<p>03 Dec 2017 	Sep 14 07:50:31 psad: src: 183.129.160.229 signature match: “MISC VNC communication attempt” (sid: 100202) tcp port: 5900</p>
<p>03 Dec 2017 Sep 13 06:36:59 psad: src: 183.129.160.229 signature match: “MISC HP Web JetAdmin communication attempt” (sid: 100084) tcp port: 8000</p>
<p>03 Dec 2017 	SNMP/161 Probe, BF, Hack -</p>
<p><strong>As I mentioned before, around mid to late December 2017 this hosts ports as shown in SHodan consisted of one SSH port and just short of a dozen NTP/UDP ports; below is a logged unauthorize attempt at port scanning NTP:</strong></p>
<p>03 Dec 2017 	port scan and connect, tcp 25 (smtp)</p>
<p>03 Dec 2017 	[portscan] udp/123 [NTP]</p>
<p>03 Dec 2017 port scan and connect, tcp 4899 (radmin)</p>
<p><strong>Now I will only list more unique examples taken from these logs:</strong></p>
<p>Dec 2017 Attempted to connect 3 times to port 1433 TCP</p>
<p>03 Dec 2017 UA:“Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0” in DroneBL:“listed [SOCKS Proxy]”</p>
<p>03 Dec 2017 [portscan] tcp/1433 [MsSQL] [scan/connect: 5 time(s)]</p>
<p>03 Dec 2017 Jul 5 11:47:21 h2177944 sshd[28021]: Invalid user admin from 183.129.160.229<br>
Jul 5 11:47:23 h2177944 sshd[28021]: Failed password for invalid user admin from 183.129.160.229 port 57304 ssh2<br>
Jul 5 11:47:27 h2177944 sshd[28023]: Failed password for root from 183.129.160.229 port 40700 ssh2<br>
Jul 5 11:47:28 h2177944 sshd[28025]: Invalid user admin from 183.129.160.229</p>
<p>03 Dec 2017 [portscan] udp/123 [NTP]</p>
<p>03 Dec 2017 port scan and connect, tcp 8080 (http-proxy)</p>
<p><strong>When I first became aware of this IP on behalf of a client, the MAC address associated to it was 00:a0:c5:67:71:ca with the user-agent UA:“Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0” for all of the many, many, many instances in the client’s logs.</strong></p>
<p><strong>This user-agent is connected to maybe 98% of the activity for 183.129.160.229 when a user-agent is logged/provided.</strong></p>
<p><strong>If you search the MAC in 00:a0:c5:67:71:ca ond many instances of abuse reported similar to what is logged below solely for  183.129.160.229:</strong></p>
<p>03 Dec 2017 	<br>
Jun 13 13:49:24 MikroTik htcd.gov.by RDC/VNC input: in:BelPak out:(none), src-mac 00:a0:c5:67:71:ca, proto TCP (SYN), 183.129.160.229*15134-&gt;192.168.226.1:3389, len 40<br>
Jun 14 03:05:53 MikroTik RDC/VNC connection input: in:pByFly out:(none), proto TCP (SYN), 183.129.160.229:36617-&gt;93.84.93.101:3389, len 40<br>
Jun 14 03:08:03 MikroTik RDC/VNC connection input: in:pByFly out:(none), proto TCP (SYN), 183.129.160.229:36617-&gt;93.84.93.101:3389, len 40</p>
<p>03 Dec 2017 Jun 8 18:02:10 psad: src: 183.129.160.229 signature match: “MISC MS Terminal Server communication attempt” (sid: 100077) tcp port: 3389</p>
<p><strong>I think you get the idea; in less than one year our Tyrannosaurus has matured and is dining upon all types of carrion and prey on the Internet.</strong></p>
<hr>
<p><strong><em>183.129.160.229 and RATs in the present</em></strong></p>
<p>In May of 2018, 183.129.160.229 is alive and well. As well as keeping on with all of the attack/scanning variations it enjoyed before, it has become quite the dispensory for RATs, especially Gh0stRAT and Win32/Win64 trojans (likely Meterpreter or Empire variations).</p>
<p>More contemporary X-Force IBM graphed activity from March 2018 onward:</p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/7/730edd607b927e72270a16a9f79b0e565892e049.png" alt="44" data-base62-sha1="gpQKUIbCtb5DA5WXdFgKyiUwUf7" width="643" height="228"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/e/ec0f618e1c77007992a1b81d57d967cdddb50dc9.png" alt="45" data-base62-sha1="xGhDtXAL58SDev4fOVrSmr2L1sR" width="644" height="224"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/5/524f3f560ebb48577155edee4bf40c6580fd9042.png" alt="46" data-base62-sha1="bK8WeUvErz5woObWX4HeFbU2hI6" width="644" height="231"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/9/930f2b51dd1f7a96f82d1a35094390fc53acc671.png" alt="47" data-base62-sha1="kYWGESSBDwM4forMhgF5gYuBQc1" width="641" height="230"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/c/c469beb1aedc7c003e9cc133dae419a85ee5fddd.png" alt="48" data-base62-sha1="s1y8Mljg4GnTxnA2fpskfguwO1T" width="638" height="221"></p>
<p><img src="//0x00sec.s3.amazonaws.com/original/2X/8/891750588fc964606b324b251e6b0b97aa7ceea4.png" alt="49" data-base62-sha1="jyLmvWfP529Ov9M0hbKPPbbCm3O" width="630" height="228"></p>
<p><strong>And some current RAT related logs from IPDB starting from <a href="https://www.abuseipdb.com/check/183.129.160.229?page=1#report" rel="noopener nofollow ugc">https://www.abuseipdb.com/check/183.129.160.229?page=1#report</a></strong></p>
<p>03 May 2018 	<br>
TCP_IN 2018-05-02 14:09:08 ["<em>02"]<br>
TCP_IN 2018-04-09 18:51:13 ["**4"]<br>
TCP_IN 2018-04-07 13:47:56 ["<em>02","*<em>00"]<br>
TCP_IN 2018-03-24 16:57:31 {“0”:"8</em>",“2”:"**4"}<br>
TCP_IN 2018-03-23 20:47:40 {“0”:“<em><em>4",“2”:"8</em>"}<br>
TCP_IN 2018-03-14 10:51:59 [“8080”]<br>
TCP_IN 2018-03-12 19:01:25 [“8080”]<br>
TCP_IN 2018-03-10 18:52:29 {“0”:“6666”,“2”:“8088”}<br>
TCP_IN 2018-03-09 09:38:32 ["<em>2</em>4</em>”,“<em>604"]<br>
TCP_IN 2018-03-08 04:19:46 ["8</em>”,“8000”]<br>
TCP_IN 2018-03-07 07:41:32 [“<em>460","<em>2</em>4</em>”]<br>
TCP_IN 2018-03-07 04:05:14 * p</em>ck</em>t to tcp(<em>2</em>4*)<br>
TCP_IN 2018-03-07 00:40:29 ["<em><em><em>0"]<br>
TCP_IN 2018-03-06 23:53:21 * p</em>ck</em>t to tcp(*<em>2</em>)<br>
TCP_IN 2018-03-06 22:08:59 * p</em>ck<em>t to tcp(<em>2</em>4</em>)<br>
TCP_IN 2018-03-06 22:03:06 * p<em>ck</em>t to tcp(2000)<br>
TCP_IN 2018-03-06 14:54:21 * p<em>ck</em>t to tcp(<em>2</em>4*)<br>
TCP_IN 2018-03-06 14:28:42 * p<em>ck</em>t to tcp(<em>2</em>4*)<br>
TCP_IN 2018-03-06 14:23:12 * p<em>ck</em>t to tcp(<em>2</em>4*)<br>
TCP_IN 2018-03-06 14:18:26 * p<em>ck</em>t to tcp(<em>2</em>4*)</p>
<p><strong>Notice that the user-agent used in the huge majority of abuse reports hasn’t changed from June 2016 to now:</strong></p>
<p>19 Apr 2018  [httpReq only by ip - not DomainName]<br>
UA:“Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0”</p>
<p>09 Apr 2018 [Aegis] @ 2018-04-10 01:31:01 0100 -&gt; Attempted Administrator Privilege Gain: ET SCAN LibSSH Based Frequent SSH Connections Likely BruteForce Attack</p>
<p>21 Mar 2018 seeing malware CNC</p>
<p>20 Mar 2018  UTM reports 3 instances of Backdoor.Win32.Zegost.L</p>
<p>17 Mar 2018 [DoS Attack: SYN/ACK Scan] from source: 183.129.160.229, port 2323, Friday, March 16, 2018 22:57:50</p>
<p>15 Mar 2018 	[DoS Attack: SYN/ACK Scan] from source: 183.129.160.229, port 2323, Thursday, March 15, 2018 12:51:49</p>
<p>15 Mar 2018 Gh0stRAT infection source</p>
<p>13 Mar 2018 Malicious brute force vulnerability hacking attacks</p>
<p>13 Mar 2018 botnet</p>
<p>12 Mar 2018 Attempt to access invalid virtual host name (###.###.###.##<span class="hashtag">#:80</span>). Typically used to access “internal” resources improperly exposed externally and “protected” only by a lack of external DNS resolution.</p>
<p>12 Mar 2018 Feb 28 23:09:33 xxx 1,2018/02/28 23:09:32,010401000781,THREAT,spyware,1,2018/02/28 23:09:32,183.129.160.229,xxx,0.0.0.0,0.0.0.0,xxx,unknown-tcp,vsys1,Untrust,DMZ,ethernet1/1,ethernet1/4,xxx,2018/02/28 23:09:32,186916,1,48280,443,0,0,0x80002000,tcp,alert,"",Gh0st.Gen Command and Control Traffic(13264),any,critical,client-to-server,692726,0x8000000000000000,China,United States,0,1203833382790760460,0,0,16,0,0,0,xxx,0,0,N/A,spyware,AppThreat-785-4551,0x0</p>
<p>11 Mar 2018 [infected host:Gh0stRat]in DroneBL:“listed [SOCKS Proxy]”</p>
<p>10 Mar 2018 83.129.160.229 - - [10/Mar/2018:11:49:15 +0200] “Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS``\x98\xC3\xC0\xC0\xC0\x06\xC4\x8C@\xBCQ\x182\x94\xF6\xB000\xAC\xA8rc\x00\x01\x11\xA0\x82\x1F\x5C<code>&amp;\x83\xC7K7\x86\x19\xE5n\x0C9\x95n\x0C;\x84\x0F3\xAC\xE8sch\xA8^\xCF4'J\x97\xA9\x82\xE30\xC3\x91h]&amp;\x90\xF8\xCE\x97S\xCBA4L?2=\xE1\xC4\x92\x86\x0B@\xF5</code>\x0CT\x1F\xAE\xAF]” 400 166 “-” “-” “-”</p>
<p>09 Mar 2018 [infected host:Gh0stRat] in DroneBL:“listed [SOCKS Proxy]”</p>
<p>08 Mar 2018 Gh0st.Gen Command and Control traffic from (Attacker) 183.129.160.229</p>
<p>08 Mar 2018 Gh0st.Gen Command and Control traffic from (Attacker) 183.129.160.229</p>
<p>08 Mar 2018 Gh0st.Gen Command and Control Traffic 08 Mar 2018 	<br>
[SID: 25912] System Infected: Ghostnet Backdoor Activity detected.</p>
<p>08 Mar 2018 	Date: 2018-03-07 11:20:19<br>
Affected host:<br>
Detection name: APT - GHOSTRAT - TCP<br>
Protocol: TCP<br>
Traffic direction: Inbound<br>
Related host name:<br>
Source<br>
IP address: 183.129.160.229(183.129.160.229)<br>
Port: 55014<br>
MAC address: 38-10-D5-22-51-55</p>
<p>07 Mar 2018 	Bad Request: “Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS<code>\x98\xC3\xC0\xC0\xC0\x06\xC4\x8C@\xBCQ\x96\x81\x81\x09H\x07\xA7\x16\x95e&lt;amp&gt;\xA7*\x04$&lt;amp&gt;g \x182\x94\xF6\xB000\xAC\xA8rc\x00\x01\x11\xA0\x82\x1F\x5C`&lt;amp&gt;\x83\xC7K7\x86\x19\xE5n\x0C9\x95n\x0C;\x84\x0F3\xAC\xE8sch\xA8^\xCF4'J\x97\xA9\x82\xE30\xC3\x91h]&lt;amp&gt;\x90\xF8\xCE\x97S\xCBA4L?2=\xE1\xC4\x92\x86\x0B@\xF5`\x0CT\x1F\xAE\xAF]" Bad Request: "Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS</code>\x98\xC3\xC0\xC0\xC7K\x80B\xF6\xD4V\x9E\xB3A\xA3 \x96|x0\xC8\xDC\x19%\xDA\x5C\x8B\x1B\xA6H\x15\xA29\xE8M~\xBF9\x98\xB5\xCD\xC2O\x9D\xF2@\x80\xAF\xC2$\x95e\x970\x10\x89~\xB8\xD5\xCA5\xCE\xB1\xEE\xDAI\xC7\x02*\xCF\xCF\xEE\xB1\x17XP\x9E\xE7x\xDC`\xD1\xE7\xA5\x22?\xC3\xE3o\x89\x946=\xE4\x1F(=\x1Db” Bad Request: "Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS``\x98\xC3\xC0\xC0\xC7K\x80B\xF6\xD4V\x9E\xB3A\xA3 \x96|x0\xC8\xDC\x19%\xDA\x5C\x8B\x1B\xA6H\x15\xA29\xE8M~\xBF9\x98\xB5\xCD\xC2O\x9D\xF2@\x80\xAF\xC2$\x95e\x970\x10\x89~\xB8\xD5\xCA5\xCE\xB1\xEE\xDAI\xC7\x02<br>
06 Mar 2018 	Win.Trojan.ZeroAccess inbound connection</p>
<p>06 Mar 2018 	183.129.160.229<br>
Found bot activity<br>
Critical<br>
Backdoor.Win32.Zegost.L<br>
March 6th, 2018</p>
<p>06 Mar 2018 	This IP tries to install the gh0st RAT multiple times per day"Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS</p>
<p>06 Mar 2018 	Bad Request: “\x16\x00\x00\x00AZWAZ\x01\x00\x00\x00x\x9CK\x05\x00\x00f\x00f”</p>
<p>05 Mar 2018 183.129.160.229 - - [05/Mar/2018:12:00:02 +0100] “Gh0st\xad” 400 311</p>
<p>05 Mar 2018 This signature detects Gh0st.Gen Command and Control Traffic</p>
<p>03 Mar 2018 	Bad Request: “Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS<code>\x98\xC3\xC0\xC0\xC7K\x80B\xF6\xD4V\x9E\xB3A\xA3 \x96|&lt;amp&gt;x0\xC8\xDC\x19%\xDA\x5C\x8B\x1B\xA6H\x15\xA29\xE8M~\xBF9\x98\xB5\xCD\xC2O\x9D\xF2@\x80\xAF\xC2$\x95e\x970\x10\x89~\xB8\xD5\xCA5\xCE\xB1\xEE\xDAI\xC7\x02*\xCF\xCF\xEE\xB1\x17XP\x9E\xE7x\xDC`\xD1\xE7\xA5\x22?\xC3\xE3o\x89\x946=\xE4\x1F(=\x1Db" Bad Request: "Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS</code>\x98\xC3\xC0\xC0\xC0\x06\xC4\x8C@\xBCQ\x96\x81\x81\x09H\x07\xA7\x16\x95e\xA7*\x04$g \x182\x94\xF6\xB000\xAC\xA8rc\x00\x01\x11\xA0\x82\x1F\x5C<code>&lt;amp&gt;\x83\xC7K7\x86\x19\xE5n\x0C9\x95n\x0C;\x84\x0F3\xAC\xE8sch\xA8^\xCF4'J\x97\xA9\x82\xE30\xC3\x91h]&lt;amp&gt;\x90\xF8\xCE\x97S\xCBA4L?2=\xE1\xC4\x92\x86\x0B@\xF5</code>\x0CT\x1F\xAE\xAF]” Bad Request: "Gh0st\xAD\x00\x00\x00\xE0\x00\x00\x00x\x9CKS``\x98\xC3\xC0\xC0\xC7K\x80B\xF6\xD4V\x9E\xB3A\xA3 \x96|x0\xC8\xDC\x19%\xDA\x5C\x8B\x1B\xA6H\x15\xA29\xE8M~\xBF9\x98\xB5\xCD\xC2O\x9D\xF2@\x80\xAF\xC2$\x95e\x970\x10\x89~\xB8\xD5\xCA5\xCE\xB1\xEE\xDAI\xC7\x02</p>
<p>02 Mar 2018 MALWARE-CNC Win.Trojan.ZeroAccess inbound connection</p>
<p>01 Mar 2018 cs1=Backdoor.APT.Gh0stRat rt=Mar 01 2018 06:05:38 UTC src=183.129.160.229 cn3Label=cncPort cn3=443 cn2Label=sid cn2=33337710 proto=tcp spt=56716 cs5Label=cncHost cn1Label=vlan cn1=0 dpt=443 cs4Label=link cs6Label=channel cs6=Gh0st</p>
<p><strong>I think you get the idea…</strong></p>
<hr>
<p>Conclusion:</p>
<p>I do not like to offer conclusions or definitive ideas; in this art anything goes and crazy things happen. I personally like to draw my own conclusions and use similar data that is presented for what I may.</p>
<p>However:</p>
<ol>
<li>The user-agent Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0 appears in 99.99999% of the User-agents logged for this IP except a couple of instances where a similar User-agent is logged/reported using a similar agent but with Windows 7 OS; I think this and other factors eliminates the activity just being created through the host being utilized as a SOCKS proxy.</li>
</ol>
<p>I imagine skiddies doing so would slip up occasionally and have other identifying data logged.</p>
<ol start="2">
<li>For clients and customers of yours: Security through obscurity is dead; if your systems face the internet they will be tested…there are no ifs and or buts about it…there are hosts scanning the internet constantly looking for a multitude of vulns at once.</li>
</ol>
<p>One log stated this host exploited a Heartbleed Bug in 2018; they are hitting everything and anything not tied down.</p>
<ol start="3">
<li>Adversaries are just a difference in circumstance and perspective. I do not consider Black Hats “the bad guys”.</li>
</ol>
<p>As someone who has competed as a professional fighter, I consider Black Hats just another opponent I may face. I will learn from them and admire their work, taking from it whatever is useful without any Satyrday morning cartoon Good Guy vs. Bad Guy mentality.</p>
<p>I state this as an idea to younger folks starting out in this field…I try to be a hacker with ethics, not an ethical hacker or any other type of figment of marketing or hubris.</p>
<p>Learn what you can from any source without preconceived notions or snap judgements.</p>
<ol start="4">
<li>“State Actor” tends to be the call made by organizations with shit security  who need a scapegoat; yes, they developed custom firmware exploits, but  why was their a VNC server with default creds facing the internet to let them in?</li>
</ol>
<p>I do not understand the business or political makeup of China, though I have been studying the difficulties citizens have with circumventing the Great Firewall.</p>
<p>The lack of user-agent/IP variation over two years and the amount of traffic reaching out to foreign targets directly makes me feel something is up here…there was reports of a gang of hackers operating from this telecoms servers who were arrested in China, but the traffic from here has not ceased in the wake of that arrest in late 2017, early 2018.</p>
<p>And thanks to RickSanchez for the help this morning.</p>
<p>There are no sacred cows here…only cows and BBQ if I’m wrong in any instance…thank you.</p>
<p>-maderas</p>
            <p><small>8 posts - 3 participants</small></p>
            <p><a href="https://0x00sec.org/t/tyrannosaurus-reproduced-fast-and-died-young-a-malicious-host-ip-c-c-from-china-2016-to-present/6691">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/tyrannosaurus-reproduced-fast-and-died-young-a-malicious-host-ip-c-c-from-china-2016-to-present/6691</link>
          <pubDate>Tue, 15 May 2018 14:28:53 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-6691</guid>
          <source url="https://0x00sec.org/t/tyrannosaurus-reproduced-fast-and-died-young-a-malicious-host-ip-c-c-from-china-2016-to-present/6691.rss">Tyrannosaurus reproduced fast and died young: A malicious host/IP/C&amp;C from China, 2016 to present</source>
        </item>
        <item>
          <title>Cyberpunk Atari &amp; The Midnight Eye: Hacking and Cybersecurity can save the world</title>
          <dc:creator><![CDATA[maderas]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <ul>
<li>The contents and ideas within this essay are my own and do not reflect the views of this site or my employer…<br>
** Edits may take place for grammatical issues or lines missed  due to author’s learning disability, but any factual issues that are ever deleted will be noted at the bottom of text</li>
</ul>
<p>Atari is a term used in Go for a situation where a stone or chain of stones has only one liberty,and may be captured on the next move if not given one or more additional liberties.(<a href="https://en.wikipedia.org/wiki/List_of_Go_terms#Atari" class="inline-onebox" rel="noopener nofollow ugc">List of Go terms - Wikipedia</a>)</p>
<p>I believe this is an apt definition for the position we find ourselves in.</p>
<p>We are The Midnight Eye; unlike Goku’s Midnight Eye, we may not control every computer terminal on Earth, but we control more than enough terminals to do what must be done,</p>
<p>Cyberpunk is by definition, low life and high tech.</p>
<p>If allowances for common human decency and freedoms on the part of the majority of Earth’s corporate, financial, religious or political authorities are any indicator, than a huge majority of Earth’s population are low life.</p>
<p>Many of the unjust authorities in our present age (and past ages) originate from the interests of religious, corporate and political institutions; the interests of these institutions most often place a premium on money, power and influence rather than humans, common freedoms and our planet.</p>
<p>These interests are most often representative of financial equity that dwarf our own: in comparing the financial/material resources of a great percentage of Earth’s population to the corporate/political/religious factions ruining this world, the great majority of us are low life.</p>
<p>However, the unjust authorities of our world must live, act, plot, scheme and hoard their wealth in a high tech, highly digitized world that hacking, cybersecurity and computer science can rule, contest, change or pervade.</p>
<p>Technologies such as wireless internet. 3G/4G, IoT devices and Bluetooth mean the computerized world has (and continues to) spread. Almost anywhere you go, from the trivial to the critical, the machinery that supports human civilization grows ever more dependent on the resources of an every growing, digital phantom space.</p>
<p>Right now, knowledge is paramount to manipulating this digital phantom space that the world (and ruinous authorities) depend on.</p>
<p>Thanks to the Internet, the means to understand, and thus, mend, bend, break and create within this space are readily available. You may become adept regardless of who or what you are, and many of the contemporary masters of this space rose from the outcasts, the poor and the disenfranchised.</p>
<p>On so many levels that will be discussed in greater detail, skill in digital disciplines (especially hacking, programming and cybersecurity) is now a form of liberation and the great equalizer of the common majority.</p>
<p>Those of us living low life high tech have an advantage that no community amongst the common populace is likely to have ever had. If necessary, we can force positive change and awareness for the benefit of the great majority, as the ability to manipulate the digital spaces are largely a labor of interest and passion leading to skillfulness.</p>
<p>Imagine if even 10% of the attendance of any recent CCC decided to pick one target doing the world grievous harm an act upon it within the digital spaces.</p>
<p>Even if this percentage did not coordinate their operations, as long as they chose one target, they could make a statement for the ages, one that an apathetic populace could not ignore.</p>
<p>Hacking is one of the most transformative and potent arts of our (or any age. Regardless of anyone’s opinions of who was involved or why, America’s 2016 Presidential Elections make it difficult to doubt that hacking can change the course of human history.</p>
<p>This is what those who write the checks for the US Intelligence agencies fear, and that is why they inflate their victories over the hacker community. This is why they spread paranoia as to their real capacity to stop us; they need to keep us fractured, because there is little they could do if we worked together.</p>
<p>Current day, intelligence agencies enforce the interests of unjust authority through unethical, illegal means that are hugely ineffective at “defeating terror”, but are fantastic at terrorizing the populace.</p>
<p>For this they mangle the constitunional principals they are sworn to protect to pieces, ravaging the basic freedoms of the citizens they are sworn to protect.</p>
<p>Yet the US intelligence machine is a continual failure in stopping the mass shootings becoming ever more commonplace; however, it is incredibly effective where social/political critics, dissidents, activists, Muslims or journalists are concerned.</p>
<p>It is a shame that the EFF or ACLU does not have the wallet or influence of the NRA.</p>
<p>If these surveillance technologies existed in the mid to late 18th century, the British would be attempting to set implants in the systems of Benjamin Franklin, Thomas Jefferson, George Washington and Thomas Paine.</p>
<p>If corporations like Google existed, they would play the part of Benedict Arnold, turning over the data of our founding fathers with little defiance, all part of a mutually beneficial business arrangement.</p>
<p>And while Intelligence agencies may have some elite personal (though they quickly lose them to the private sector), only their wallets could ever compete as a whole against any percentage of the hacker/cybersecurity community.</p>
<p>This is why they stopped targeting hackers with their exploits; does the hacker community really have to fear an intelligence machine whose members break OpSec through posting on LinkedIn?</p><p><a href="https://www.youtube.com/watch?v=BwGsr3SzCZc">Black Hat USA 2013 - OPSEC failures of spies</a></p>

<p>Every person who gains competence in a digital discipline now has the potential to become a means to improve the world.</p>
<p>While they should never be spoon fed, encouragement and aid could be an investment in bettering your own world.</p>
<p>Whereas elitist attitudes may have been common in places that are the confines of these disciplines, this snobbery is bullshit we and the wider world can no longer afford.</p>
<p><strong>Corporate/government domination of the Internet could lead to disaster</strong></p>
<p>It seems that despite protests and the petitions, Net Neutrality is destined to die; yet again, the detriment of the great majority serves to benefit the few who already know abundance onto greed.</p>
<p>Right now, the low life high tech have an advantage that can change things, as the ability to manipulate the digital spaces are largely a labor of interest and passion leading to skillfulness.</p>
<p>How long before wealth can purchase or manufacture the means to dominate this space beyond our individual or combined abilities?</p>
<p>Current day, intelligence agencies enforce the interests of unjust authority through unethical, illegal means that are hugely ineffective at “defeating terror”, but are fantastic at terrorizing the populace.</p>
<p>But how long before these authorities can wield some automated terror that nullifies one of the few remaining advantages of the populace?</p>
<p>We have seen the fumbling, bumbling madness, shortsightedness and outright stupidity of government a bit too much lately; what happens if these fools with no true understanding of the Internet (except maybe how to profit from exploiting it) more fully dominate the Internet ( which so many gears of human civilization now depend) and do some damage to it that has an unforeseen, catastrophic effect on some facet of the Industrial or Energy Sector?</p>
<p>After all, recent world events have seen some pretty epic fails on behalf of influential people/entities allied with the current Republican authority in control of the US.</p>
<p>And these epic fails were within spheres they are supposed to be experts on: in the political sphere you have the invasion of Iraq, resulting in (by the measure of estimates that meet a global consensus of reliability) approx. 460,000 deaths, of which (by measure of the independent US/UK Iraq Body Count project between 2003-2011) 116,277 were civilian casualties (<a href="https://en.wikipedia.org/wiki/Casualties_of_the_Iraq_War" class="inline-onebox" rel="noopener nofollow ugc">Casualties of the Iraq War - Wikipedia</a>).</p>
<p>Some of the politicians who benefited from the corpses of American and Iraqi alike also voted against Net Neutrality; for example Republican Representative Jon Carter of Texas made between $1,000,001 and  $5 million off of Defense Contracts during the Iraq War. (<a href="https://www.organicconsumers.org/news/some-members-congress-profit-iraq-war-contractor-stockso-wonder-we-cant-end-war" rel="noopener nofollow ugc">https://www.organicconsumers.org/news/some-members-congress-profit-iraq-war-contractor-stockso-wonder-we-cant-end-war</a>, <a href="https://www.techdirt.com/articles/20111126/15435216901/hypocrites-congress-who-voted-against-net-neutrality-sopapipa.shtml" class="inline-onebox" rel="noopener nofollow ugc">The Hypocrites Of Congress: Who Voted Against Net Neutrality, But For SOPA/PIPA | Techdirt</a>)</p>
<p>When our most ancient ancestors left their trees for the for the resources of the grasslands, their struggle to survive yielded knowledge that grew their minds, spurring an evolution toward the human species.</p>
<p>Millennia later (around 70,000 BC), an ecological cataclysm brought a sudden ice age that reduced our species to between 2k and 10k individuals total; the groups that improvised upon their skills and learned others were very likely the only survivors and saviors of our species.(<a href="https://www.npr.org/sections/krulwich/2012/10/22/163397584/how-human-beings-almost-vanished-from-earth-in-70-000-b-c" class="inline-onebox" rel="noopener nofollow ugc">How Human Beings Almost Vanished From Earth In 70,000 B.C. : Krulwich Wonders... : NPR</a>)</p>
<p>Knowledge has carried our species through the ages; cooperation and communication have served as a multiplier that potentiates knowledge, hastening the growth of understanding and new knowledge.</p>
<p>In this way, in our more recent history, the baud is Buddha: a great teacher of nigh incomprehensible depth that we may meet at the Sangha (The Internet, our digital Library of the Ages). There he may lead us toward glimpsing enlightenment among the flashes of reason, absurdity, clarity and illusion cast like shadows by the vastness of our species collective knowledge.</p>
<p>The byproducts of the progress/innovation made possible by our species perpetual expansion of knowledge (war, greed, overpopulation and inequality amongst dwindling natural resources, an ecological cost that has amassed greatly since  The Industrial Revolution)threaten to damn us , our planet and the innocent denizens with whom we share this Earth.</p>
<p>The institutional authorities who have benefited most by our dominance of this planet seem unwilling to meet these challenges while there is profit at hand. Look no further than the Republican led US (historically, the world’s socio-political course setters) , who since Trump’s election have gutted the EPA and environmental science agencies, gave business a free pass to pollute our ailing home, and have ranks teaming with climate deniers/fossil fuel profiteers.</p>
<p>Many of the wealthy, influential Republicans profiting from the ruining of our children’s natural inheritance appear to be well past middle age; they have already enjoyed a quality of past (free of seawalls, global water shortages, mass extinctions, a dying, jellyfish and plastic dominated ocean) that they would deny later generations any semblance of.</p>
<p>An evolution of knowledge spurred by freedoms of cooperation and communication among the great majority of this planet must meet the challenges of tomorrow if we are to save ourselves, our planet and the future the the youngest of our number deserve</p>
<p>An infrastructure that allows fast, free cooperation, communication and transfer of knowledge from all corners of our world must be protected, supported, improved and encouraged if we are to survive, let alone thrive.</p>
<p>Currently, the Internet is the paramount conductor of these processes.</p>
<p>Whether through more traditional use of its resources (such as HTTPS/HTTP) or through projects such as  Tor, I2P and Tahoe Lafs (or any future privacy/anonymity projects that may evolve from them), the Internet represents a communications infrastructure with a incredible degree of pliable, programmable resources already in place.</p>
<p>And these resources can allow an oppressed population to hold congress in any manner of ways, thus allowing a system of communication to be unpredictable with a minimum of development time/preparation.</p>
<p>Also, while the Internet has become a staple resource of the public at large, a huge percentage of the general populace are not fully aware of the extent in which their freedoms are at risk.</p>
<p>Regardless of any groups best wishes for common majority, any movement against an oppressive authority must also fight a war against that authority for the minds and hearts of the general populace.</p>
<p>The empathy, outrage and awareness of the general population (and a tyrannical institution’s fear of losing control of the general population) is often the best means to curtail outright and blatant trespasses of an unjust authority.</p>
<p>The effectiveness of Breitbart’s dispersal of online propaganda during the 2016 US Presidential Campaign is just an omen of how the populace could be controlled and divided.</p>
<p>How much worse will it be if those of us those with the best capacity to fight for a free and neutral Internet fail to do so, therefore allowing the Breitbart’s of the world to (for all practical purposes) own the Internet and control the hearts and minds of population?</p>
<p>If the baud is Buddha, then we who are low life, high tech must become like his Nio protectors: enlightened devils whom out of compassion, bring wrath and ruin upon the enemies of sentient life.</p>
<p>The baud is Buddha and must be protected; The Library of Ages must not become The Breitbart Civil Auditorium.</p>
<p>A Cyberpunk movement could change the world, and it has in the past; many defining events in the history of computer science involve the classical elements of Cyberpunk: individuals with minimal financial/material resources utilize their wits and innovations in the technology of their aget to effect change in defiance of, or with little regard for, authority.:<br>
•	Stallman’s (love him or hate him) password hijinks at MIT’s LCS in 1977<br>
•	Alan Turing’s life, work and legacy; Alan’s personal life shared parallels with the Cyberpunk concepts of low life in ways that are tragic and insidious; may England should forever wear his death as a scarlet letter<br>
•	The founding philosophies and events leading to licenses/organizations such as the Free Software Foundation, GNU Project/GNU Public License, Open Source, The MIT License<br>
•	Initiatives such as Bruce Perens’ succesful No Code International.<br>
•	The history of the Homebrew Computer and the histories of many of its legendary members<br>
•	Linus creating (Freax) Linux out of frustration of Minix/Unix licensing issues/requirements</p>
<p>Then there are The Crypto Wars of the 1990s and The Cypherpunks…</p>
<p>Throughout the Crypto Wars of the 1990s, The Cypherpunk movement clashed with the United States government in what has come to be called The Crypto Wars.</p>
<p>Among the issues the Cypherpunk Movement had with the United States government were federal interests/attempts to weaken and restrict strong cryptographic/encryption technologies.</p>
<p>Then there was the Clipper Chip: An NSA built, backdoored communications chipset that would have allowed federal employees to eavesdrop on telephone communications via key escrow.</p>
<p>The United States government had meant for the Clipper Chip to be ubiquitous in the  telecommunications industry by giving the chip the capacity to encode (and decode) communications…</p>
<p>By 1995 the Cypherpunks were on their way to winning the most decisive battle of The Crypto Wars: in Bernstein v. United States,  legal representation provided by the EFF aided one of the Cryptopunks  own (djb, also known as Daniel J. Bernstein)in suing  The United States  over federal laws governing cryptography.</p>
<p>In 1995, Bernstein (djb) had wanted to release a research paper and source code associated with his Shuffle encryption system. At that time, US federal law placed cryptography on The United States Munitions List (alongside grenades, mortars and flamethrowers) which also made exporting crypto outside of the country (or releasing the source code of cryptographic programs) illegal without an export license from the US State Department (as a munition, management of crypto was the State Department’s responsibility).</p>
<p>In 1999 the Ninth Circuit Court of Appeals had heard the case and ruled that software source code was speech protected by the First Amendment; US regulations preventing its publication were unconstitutional,forcing the United States to gradually relax laws governing crypto until they finally met the legal standards of today in 2003.</p>
<p>For fighting and winning the battle for the freedoms of cryptography, the world owes the  Cypherpunks (especially the founding fathers of the movement: Eric Hughes, Timothy C. May and John Gilmore) of the 1990s a huge debt.</p>
<p>The Cypherpunk have already designed the strategies for successful dissidence; they include acts of civil disobedience (example: Vince Cate’s international arms dealer webpage), widespread discussion (John Gilmore’s <a href="http://toad.com" rel="noopener nofollow ugc">toad.com</a> and mailing lists across numerous specialized mail servers) and innovation.</p>
<p>Innovation may have been the most important part of that dissidence; many privacy/anonymity, encryption and cryptography technologies were created or had their start with The Cypherpunks during The Crypto Wars.</p>
<p>As Jon Gimore stated: “We are literally in a race between our ability to build and deploy technology, and their ability to build and deploy laws and treaties. Neither side is likely to back down or wise up until it has definitively lost the race."</p>
<p>And Eric Hughes: “Privacy is necessary for an open society in the electronic age. … We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy … We must defend our own privacy if we expect to have any. … Cypherpunks write code. We know that someone has to write software to defend privacy, and … we’re going to write it.”</p>
<p>While techno-activism is huge in countering unjust authority and should be a huge part of a Cyberpunk Movement, there shouldn’t be any one path toward improving the lives of the populace. Cyberpunk is about being lowlife and using high tech to create positive change; it is a movement about saving the little guy and fucking up the gears that have sent everything to shit.</p>
<p>A movement provides an individual with the resources to teach themselves a skill such as Network Security or a programming language. Their joy of this skill leads them to proficiency, which eventually yields for them the means to break the grasp of abject poverty that held them and prior generations of their family, than this an example of the Cyberpunk Movement.</p>
<p><a href="https://www.youtube.com/watch?v=k57XIgZiPOM">The Eleventh HOPE (2016): "Privacy, Anonymity, and Individuality - The Final Battle Begins"</a></p>

<p>The individual citizen should be empowered to defend their own digital existence. Even a non-technical person can learn enough about cryptography, cybersecurity and privacy/anonymity programs to much improve their resistance against corporate/government spying/data collection online.</p>
<p>For the citizen concerned with self-defense/self-preservation, learning/applying cybersecurity basics are now just as relevant as training with the fists or firearm; a company like LifeLock will not protect the common citizen as effectively as they can themselves with a bit of knowledge.</p>
<p>In 2015, LifeLock was ordered to pay $100 million to settle Federal Trade Commission contempt charges. The Federal Trade Commission charged LifeLock for failing to protect consumer information and deceptive advertising, resulting in the largest monetary award obtained by the Commission for an enforcement action. (<a href="https://www.ftc.gov/news-events/press-releases/2015/12/lifelock-pay-100-million-consumers-settle-ftc-charges-it-violated" rel="noopener nofollow ugc">https://www.ftc.gov/news-events/press-releases/2015/12/lifelock-pay-100-million-consumers-settle-ftc-charges-it-violated</a>)</p>
<p>The company is deceptive as well; LifeLock has focused recent advertising campaigns on the 9/17 Equifax breach, using scare tactics in an attempt to sell subscriptions to those effected.</p>
<p>What they are not telling consumers is that Equifax provides LifeLock’s credit reporting and monitoring service. (<a href="http://www.latimes.com/business/hiltzik/la-fi-hiltzik-lifelock-equifax-20170918-story.html" class="inline-onebox" rel="noopener nofollow ugc">Column: LifeLock offers to protect you from the Equifax breach — by selling you services provided by Equifax</a>)</p>
<p>And even after Equifax was breached, it recently signed a deal with the IRS worth at least $7million taxpayer dollars “to verify taxpayer identities and help prevent fraud”, (<a href="http://www.cbs46.com/story/36522073/irs-chooses-equifax-for-725-million-contract-to-help-against-identity-theft" rel="noopener nofollow ugc">http://www.cbs46.com/story/36522073/irs-chooses-equifax-for-725-million-contract-to-help-against-identity-theft</a>)</p>
<p>If an operation gives the populace a means to keep their digital existence safer, or better guard their privacy from exploitation by nations, an ISP or phishing, than that is techno-activismin in the tradition of Cyberpunk as a movement; it deprives the enemy of resources by depriving them of data (which many entities find quite lucrative).</p>
<p>If an operation aids someone in becoming a bit more informed about the boons of cryptography or cybersecurity, or if they learn something of the real costs of metadata or privatization/corporate overlording of the internet, then this is Cyberpunk techno-activism.</p>
<p>Volunteering time to secure the networks of a non-profit (who likely cannot afford regular cybersecurity services) serving the poor, civil rights, privacy or any other facet of the populace’s interest is also an example of Cyberpunk techno-activism.</p>
<p>Surfing Shodan and finding examples of insecure services/processes running on the network(s) of an organization serving the public trust and making them aware of the issue is another.</p>
<p>Even if an operation does not directly target an authority abusing power or influence, if the operation  is effective in creating or changing a single person’s awareness, than that is a blow against all unjust authority.</p>
<p><strong>The power of Cyberpunk myth on the real world</strong></p>
<p>In the Cyberpunk movement there is always a place for Cyberpunk media of all type(literature, movies, anime, manga, etc.); these resources are the fables, realities, prophecies and mythology of this community.<br>
Science fiction has had an incredible effect on the course of Science, especially rigid disciplines such as the various branches of Physics.</p>
<p>Cyberpunk has had the same effect on many facets of computer science (especially hacking and cybersecurity)in a similar way.</p>
<p>Even the basic application of cybersecurity skillsets involved in the defacing of a website in defiance of some unethical corporate entity shares a parallel with many themes found in Cyberpunk fiction.</p>
<p>Cyberpunk media helps us confront the human and socio-political/socio-economic/inherent ethical issues at the heart of our interactions with technology, especially the possible implications on our individual and collective humanity.</p>
<p>Artists like Bradbury, Asimov, Clarke, Kubrick and Lucas had an effect on generations of scientists, many of whom have been among the greatest thinkers of our species.</p>
<p>Scientists have advanced our civilization by introducing us to miracles and horrors; in their methods and experimentation, many have drawn from the creativity and humanity of the science fiction they loved.</p>
<p>Disciplines such as mathematics and physics can be the hammer and anvil that forge and shape their  pursuits, but science fiction is the art that brought many to the forge and hinted at the shape.</p>
<p>HG Wells is considered the “Father of Science fiction”, and his works have been cited as a pivotal inspiration inthe development of many technologies.</p>
<p>In 1914, HG Wells booik “The World Set Free” was released; in the book, HG Wells imagined a world in which scientists had unlocked the power of atomic energy and used it \as a weapon of war.</p>
<p>In 1932, the physicist Leo Szilard read The World Set Free and became Wells inspired by by Well’s vision of atomic power.</p>
<p>By 1933 Hitler had come to power and Szilard, a Jewish Hungarian fled to London, England; that same year, the immigrant physicist had an epiphany while waiting at a traffic light: Szilard conceived the  nuclear chain reaction, thus realizing the manner in which humankind could tap and unleash the  immense power of the atomic nucleus.</p>
<p>By the end of 1933, he and Enrico Fermi (an italian-American physicist who would win The Nobel Prize in 1938, called “The architect of the Nuclear Age” and “The Architect of the Atomic Bomb”) would patent the idea of a nuclear reactor that same year.</p>
<p>Bythe end of 1939, Leon  Szilard drafted the Einstein-Szilard Letter (signed by his friend Albert Einstein) warning US President Franklin Roosevelt of the potential for atomic weapons, which resulted in the Manhattan Project.</p>
<p>Cyberpunk has sometimes been described as an aesthetic; while aesthetics have their place, Cyberpunk being defined by an idea of aesthetic components is a disservice to the importance it could play in today’s society.</p>
<p>Given the realities/scope of state surveillance, any established aesthetic could also be dangerous, as it could  become a means of control or quantification , while defined aesthetic is by itself unnecessary to illicit the change this world may need.</p>
<p>This is not Cyberpunk 2020 where everything should look cool over all else; this is Earth 2017, and if the little guy (low life) doesn’t start using technology to even the odds and build awareness (high tech) then we are likely fucked.</p>
<p>Wearing bomber jackets and sunglasses at night amongst rain, billowing steam and gothic, neon-drenched cityscapes won’t be enough to save the world.</p>
<p>Cyberpunk is now. History has its eyes on you…</p>
<p>Authors website for related resources: OuterHeaven  <a href="http://i2g3vsckj67dnjvb.onion" rel="noopener nofollow ugc">i2g3vsckj67dnjvb.onion</a></p>
            <p><small>2 posts - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/cyberpunk-atari-the-midnight-eye-hacking-and-cybersecurity-can-save-the-world/4329">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/cyberpunk-atari-the-midnight-eye-hacking-and-cybersecurity-can-save-the-world/4329</link>
          <pubDate>Tue, 14 Nov 2017 10:46:52 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-4329</guid>
          <source url="https://0x00sec.org/t/cyberpunk-atari-the-midnight-eye-hacking-and-cybersecurity-can-save-the-world/4329.rss">Cyberpunk Atari &amp; The Midnight Eye: Hacking and Cybersecurity can save the world</source>
        </item>
        <item>
          <title>Shameless self-promotion: Ops tools for hackers</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Hello fellow 0x00sec-ers!</p>
<p>I just had a good talk with <a class="mention" href="https://0x00sec.org/u/pry0cc">@pry0cc</a> about doing some posts within my specialty, operations. I firmly believe that a strong foundation in operations is essential for any aspiring hacker, as you need to understand the systems you’re breaking. To that end, I will be cross-posting articles I write on my own blog here with a special focus on using ops tools for evil.</p>
<p>This first article (in what <em>might</em> be a series) is less evil, still fun. I used our very own pet chatbot, MissMoneyPenney, to demonstrate two really cool tools, Consul and consul-template. Check it out, let me know your thoughts, and tell me how you might want to use something like Consul and consul-template for bad things.</p>
<p><a href="http://blog.fraq.io/tech/consul-template/" class="onebox" target="_blank" rel="nofollow noopener">http://blog.fraq.io/tech/consul-template/</a></p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/shameless-self-promotion-ops-tools-for-hackers/2187">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/shameless-self-promotion-ops-tools-for-hackers/2187</link>
          <pubDate>Mon, 05 Jun 2017 15:04:21 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2187</guid>
          <source url="https://0x00sec.org/t/shameless-self-promotion-ops-tools-for-hackers/2187.rss">Shameless self-promotion: Ops tools for hackers</source>
        </item>
        <item>
          <title>APT write up collection</title>
          <dc:creator><![CDATA[ricksanchez]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <h1>Preface</h1>
<p>Okay guys we’re not talking <strong>apt-get</strong> here.<br>
It’s about <strong>advanced persistent threats</strong>.<br>
Didn’t find anything about it here after using the search.</p>
<h2>What is it in short?</h2>
<blockquote>
<p>An advanced persistent threat (APT) is a network attack in which an unauthorized person gains access to a network and stays there undetected for a long period of time. The intention of an APT attack is to steal data rather than to cause damage to the network or organization. APT attacks target organizations in sectors with high-value information, such as national defense, manufacturing and the financial industry <a href="http://searchsecurity.techtarget.com/definition/advanced-persistent-threat-APT">[1]</a>.</p>
</blockquote>
<h2>Why do a lot of APT campaigns get to the public  so late?</h2>
<p>It’s connected to the average life expectancy.</p>
<blockquote>
<p>Zero-days have an average life expectancy of nearly seven years, with a quarter surviving over nine years. The median amount of time it takes to create an exploit for a known vulnerability is 22 days <a href="https://www.wired.com/2017/03/security-news-week-everything-know-zero-day-exploits/">[2]</a></p>
</blockquote>
<h2>Interesting links</h2>
<p>If you want to read up on the aftermath of different APT’s, their motivation, detection and how cleaning up afterwards works check the links below.</p>
<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/kbandla/APTnotes" target="_blank" rel="noopener">GitHub</a>
  </header>
  <article class="onebox-body">
    <img src="https://0x00sec.s3.amazonaws.com/original/2X/d/de888ba4bb3aa9f420919ce9809a3de6721f1290.png" class="thumbnail" width="" height="">

<h3><a href="https://github.com/kbandla/APTnotes" target="_blank" rel="noopener">kbandla/APTnotes</a></h3>

<p>Various public documents, whitepapers and articles about APT campaigns - kbandla/APTnotes</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/aptnotes/data" target="_blank" rel="noopener">GitHub</a>
  </header>
  <article class="onebox-body">
    <img src="https://0x00sec.s3.amazonaws.com/original/2X/8/8495a4b358716ab0a7ba04dc6d42fac890d5b5a7.jpeg" class="thumbnail" width="" height="">

<h3><a href="https://github.com/aptnotes/data" target="_blank" rel="noopener">aptnotes/data</a></h3>

<p>APTnotes data. Contribute to aptnotes/data development by creating an account on GitHub.</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections" target="_blank" rel="noopener">GitHub</a>
  </header>
  <article class="onebox-body">
    <img src="https://0x00sec.s3.amazonaws.com/original/2X/9/94b7a939259c027e79c1ad72946e6d7caf584e94.png" class="thumbnail" width="" height="">

<h3><a href="https://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections" target="_blank" rel="noopener">CyberMonitor/APT_CyberCriminal_Campagin_Collections</a></h3>

<p>APT &amp; CyberCriminal Campaign Collection. Contribute to CyberMonitor/APT_CyberCriminal_Campagin_Collections development by creating an account on GitHub.</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<aside class="onebox allowlistedgeneric">
  <header class="source">
      <img src="https://github.githubassets.com/favicons/favicon.svg" class="site-icon" width="32" height="32">
      <a href="https://github.com/nccgroup/Royal_APT" target="_blank" rel="noopener">GitHub</a>
  </header>
  <article class="onebox-body">
    <img src="https://0x00sec.s3.amazonaws.com/original/2X/a/a46d8b892ec83affcf84f12e9b48f4e99c3e3ce5.png" class="thumbnail" width="" height="">

<h3><a href="https://github.com/nccgroup/Royal_APT" target="_blank" rel="noopener">nccgroup/Royal_APT</a></h3>

<p>Royal APT - APT15 - Related Information from NCC Group Cyber Defense Operations Research - nccgroup/Royal_APT</p>


  </article>
  <div class="onebox-metadata">
    
    
  </div>
  <div style="clear: both"></div>
</aside>

<p>Peace out</p>
            <p><small>5 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/apt-write-up-collection/2144">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/apt-write-up-collection/2144</link>
          <pubDate>Thu, 01 Jun 2017 07:52:18 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2144</guid>
          <source url="https://0x00sec.org/t/apt-write-up-collection/2144.rss">APT write up collection</source>
        </item>
        <item>
          <title>Overlooked tools of the infosec trade: Packer</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>We spend a lot of time talking about the obvious infosec tools like fuzzers, VPNs, key loggers, and the “sexy” things. However, there are quite a few useful tools out there that can be used to maintain your lab, help your research, and help you get stuff done faster.</p>
<h2>Packer</h2>
<p><a href="https://www.packer.io/" rel="nofollow noopener">Packer by Hasicorp</a> is for building machine images that you can deploy on most any cloud or virtualization platform (Digitalocean, AWS, Hyper-V, VMware, you name it). Why does this matter?</p>
<p>Instead of the tedious process of maintaining a fleet of golden images that quickly go out of date and can be hard to pack for a series of different environment or maintaining storage for a bunch of said images (which can get costly if they’re large or numerous), you simply use a packer script to build it shortly before you want to deploy it. Packer also allows you to build the same image suitable for a variety of virtualization environments. Have a packer script that you use for DO but want to use it in a VMware lab? Simple: Just change 2-3 lines and run it again.</p>
<h3>Speed matters</h3>
<p>Let’s say you don’t want to pay the money to keep an SSH proxy, SFTP, or some other service running full time. Or maybe it was a pain in the butt to configure. Or maybe you have already automated the configuration through the world’s most complex Cloud-init script ever, but don’t want to wait 30 minutes for it to deploy. You want it NOW! If you’re using a pre-baked image that you built with packer, your deployment and configuration time is only limited by how fast the platform and deploy a machine. For Digitalocean or Amazon, that’s under a minute.</p>
<h3>Repeatability matters</h3>
<p>I have bad news for you: You’re probably human. I’m sorry. And if you’re human, you make mistakes (very sorry). Even in a process you’ve done a hundred times before (very very sorry). Therefore, we do our best to do it right once and then automate the process thereafter.</p>
<p>Packer also allows us to use our favorite tools like Ansible, Puppet, Chef, or terrible shell scripts to build the machines. Complicated tasks get boiled down to a couple lines of code!</p>
<h3>Sharing is caring</h3>
<p>Have a packer build that you like? Have one that someone else wants? Put it in git, let them clone it down. Much easier than trying to share a VM image.</p>
<hr>
<h2>Your first packer build</h2>
<p>We’re going to build our first Digitalocean image and <a href="https://www.packer.io/intro/getting-started/build-image.html" rel="nofollow noopener">rip instructions straight from Packer’s website to do it</a>. One small difference: Their guide uses AWS. We’ll use DO instead.</p>
<p>I’m going to assume you can read instructions and figure out how to install it from <a href="https://www.packer.io/intro/getting-started/install.html" rel="nofollow noopener">their guide</a>. If you’re on MacOS, it’s just <code>brew install packer</code>.</p>
<p>Now, let’s create a directory for our packer config. This can be within an existing project if you like. For example, you may have an application you want to deploy and frequently want to spin up virtual machines that are configured to use it. You can add a <code>packer/</code> directory that builds your application in an image and spits something out that’s ready to use. Nifty, huh?</p>
<p>Before we write the config, it’s probably best to obtain your API creds. Log into DigitalOcean and get creds here: <a href="https://cloud.digitalocean.com/settings/api/tokens" rel="nofollow noopener">https://cloud.digitalocean.com/settings/api/tokens</a> (or click your profile pic in top right &gt; settings  &gt; API. Tokens is default pane). Stash those creds somewhere safe for a moment, we’ll need them soon.</p>
<p>Drop the following config in a file named something like <code>my_super_awesome_packer_image.json</code>:</p>
<pre><code class="lang-json">{
  "builders": [{
	  "type": "digitalocean",
	  "api_token": "aaaabbbbccccdddd1111222233334444",
	  "image": "ubuntu-16-04-x64",
	  "region": "nyc2",
	  "size": "512mb",
	  "ssh_username":"root",
	  "snapshot_name": "baseline-{{timestamp}}"
  }],
  "provisioners":[{
	  "type":"shell",
	  "script":"./scripts/base.sh"
  }]
}
</code></pre>
<p>Let’s breakdown what we’re looking at. First, notice the whole thing is in JSON. Not much to explain there.</p>
<p>Next, notice that there are two top-level keys: <code>builders</code> and <code>provisioners</code>. Those two are the basis of the whole packer config: <code>builders</code> is an array of configs for each platform you want to build against. If you want to build the same config at the same time against AWS and DO, just add two builder fields after the builder key. The other is <code>provisioners</code>. Provisioners are what do the work of configuring the machine, and they run in order, first to last. You can use shell scripts, ansible, puppet, chef, or in-line shell commands. Notice here that I used a shell script.</p>
<p>Now run <code>packer build my_super_awesome_packer_image.json</code> (assuming you have a script in <code>scripts/base.sh</code>. If not, just remove that provisioner block) and let packer create the image for you!</p>
<p>From here, you can go do the DO control panel, select the “Images” and you’ll see your packer build available as a snapshot, ready to deploy.</p>
            <p><small>11 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/overlooked-tools-of-the-infosec-trade-packer/2045">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/overlooked-tools-of-the-infosec-trade-packer/2045</link>
          <pubDate>Tue, 16 May 2017 14:43:17 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2045</guid>
          <source url="https://0x00sec.org/t/overlooked-tools-of-the-infosec-trade-packer/2045.rss">Overlooked tools of the infosec trade: Packer</source>
        </item>
        <item>
          <title>Why %CPU is a misleading metric</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Your friendly neighborhood ops troll is back!</p>
<p>Here’s a good article on why looking at %CPU (CPU utilization) is a misleading metric when using tools such as top. The normal inclination is to thing that a 90% utilization report means the CPU actually means it’s being used 90% of the time, right? You already know from the title I’m gonna tell you that’s wrong.</p>
<p>The tl;dr is that there is a bottleneck accessing main memory, which results in a lot of cycles that applications spend waiting on memory, falsely reporting that the CPU is “utilized”.</p>
<p>IPC (instructions per cycle) is a more accurate measurement of utilization and this article points to a few good examples of how to check that and tune apps that might be CPU-bound or memory-bound.</p>
<p><a href="http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html" class="onebox" target="_blank" rel="nofollow noopener">http://www.brendangregg.com/blog/2017-05-09/cpu-utilization-is-wrong.html</a></p>
            <p><small>11 posts - 5 participants</small></p>
            <p><a href="https://0x00sec.org/t/why-cpu-is-a-misleading-metric/2002">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/why-cpu-is-a-misleading-metric/2002</link>
          <pubDate>Tue, 09 May 2017 23:22:37 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-2002</guid>
          <source url="https://0x00sec.org/t/why-cpu-is-a-misleading-metric/2002.rss">Why %CPU is a misleading metric</source>
        </item>
        <item>
          <title>About the Operations category</title>
          <dc:creator><![CDATA[IoTh1nkN0t]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>Category for Topics about Operations.</p>
<p>Edit (by <a class="mention" href="https://0x00sec.org/u/oaktree">@oaktree</a>) Operations being infra, system administration, etc.</p>
            <p><small>1 post - 1 participant</small></p>
            <p><a href="https://0x00sec.org/t/about-the-operations-category/1718">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/about-the-operations-category/1718</link>
          <pubDate>Tue, 28 Feb 2017 20:54:30 +0000</pubDate>
          <discourse:topicPinned>Yes</discourse:topicPinned>
          <discourse:topicClosed>No</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1718</guid>
          <source url="https://0x00sec.org/t/about-the-operations-category/1718.rss">About the Operations category</source>
        </item>
        <item>
          <title>Updating object timestamps in an s3 bucket with boto</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p>I’m going to keep putting these tutorials in here until <a class="mention" href="https://0x00sec.org/u/oaktree">@oaktree</a> makes an “ops” category just for me <img src="https://0x00sec.org/images/emoji/twitter/wink.png?v=9" title=":wink:" class="emoji" alt=":wink:"> And I realize pretty much all of us here are in infosec in some way or another and not really “ops” people, but bear with me. All these little things are going to come in useful someday somehow. I promise.</p>
<p>Now, onto the post…</p>
<p>So tonight because of some vendor’s stupidity, I had to update the timestamps on all the objects in an S3 bucket to something less than 24h old, ie, “now”. How do I do that? No idea. But I knew I had to start with my trusty Swiss Army Knife for AWS: python3 + <a href="https://github.com/boto/boto3" rel="nofollow noopener">boto3</a>.</p>
<p>Firing up boto, and python, I sketched out my short script. I knew I needed to do the following:</p>
<ol>
<li>Create a boto “client” object</li>
<li>Enumerate all the objects in the given bucket</li>
<li>For each of those objects, bump the timestamp to “now” somehow.</li>
</ol>
<p>Steps 1 and 2 were easy. Step 3 was less clear: boto has no method to modify metadata directly. At least, none that I could find. What to do? A bit of Googling turned up a Github <a href="https://github.com/boto/boto3/issues/389" rel="nofollow noopener">issue</a> describing the use of <code>copy_object()</code> pointing to the same source and dest key. It’s the boto version of <code>touch</code>, sorta. It’s not documented and it’s not really obvious.</p>
<p>So there you have it: If you want to <code>touch</code> an object in an S3 bucket, the best way to do it is to use <code>client.copy_object()</code> with the same source and destination.</p>
            <p><small>7 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/updating-object-timestamps-in-an-s3-bucket-with-boto/1713">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/updating-object-timestamps-in-an-s3-bucket-with-boto/1713</link>
          <pubDate>Tue, 28 Feb 2017 05:00:21 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1713</guid>
          <source url="https://0x00sec.org/t/updating-object-timestamps-in-an-s3-bucket-with-boto/1713.rss">Updating object timestamps in an s3 bucket with boto</source>
        </item>
        <item>
          <title>Intro to Microservices part 2</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><em>The second in a series on microservices.</em></p>
<h1>Microservices</h1>
<hr>
<h2>Part 2: The start of microservices</h2>
<h3>Out of the water, onto land…</h3>
<p>The motivation for and benefits of a microservices architecture extend far beyond simply breaking down the monolith as mentioned, but for most engineers and companies I’ve spoken with looking to make the switch, scaling and cost savings are the primary motivation. They realize that deployments are painful, that money is wasted on power or cloud compute resources, that choke points are killing performance. But they quickly realize additional benefits: the application can be extended more easily. Services and functions can be decoupled from one another and refactored without affecting other parts. Each segment can handle it own security. Each service can dynamically scale independently of others. Let your imaginations run wild, boys and girls.</p>
<p>To better understand the move from a monolith to a microservices architecture, consider your own applications and how they have evolved over time. Initially, they were likely simple scripts. Probably less than 100 lines. I know mine were, at least. Over time, as the needs grew more complex, so did the code that supported them. No longer would 100 lines of straight imperative code work, so you added some functions here, functions there. Sometimes they were reused, sometimes it was just a pipeline from one function to the next. As you matured and your problems grew more complex, your solutions became more sophisticated and elegant. You embraced the DRY principle and wrote highly compact and reusable pieces of code. Helpful libraries that you were able to recycle across projects. You took each job that your code did and broke it down until it did one thing and did it <em>very well</em>. That my friends, is the sprit of microservices. We take services–tasks–and break them out of the monolith and into their own tiny little app, apply an interface to it so it can communicate with other things, and bam, microservice.</p>
<p>Now, imagine how we might do that in practice?</p>
<h3>Killing the monolith, a little at a time</h3>
<p>As I mentioned earlier, one of the first services that gets split off from the main monolith is the database. This makes the most sense as it’s the most un-like service from the rest of the application and data has a higher demand for integrity so a safer option is to move it off the server hosting the application. Additionally, clustering databases can be a headache, so moving the database off the application server makes administration of both easier, as the app servers can come and go without affecting the database. Already you can probably see some themes emerging that will become quite prominent soon, namely the decoupling of services.</p>
<h3>Okay, I broke something off. What is the next thing?</h3>
<p>This is often entirely dependent upon the organization, but let me give you a scenario:</p>
<p>After splitting the DB off from the main application, you get a new feature request dropped into your lap: send users notifications on pending actions in their account. Do you add this to the monolith or do you create a new, tiny little application? Why, a microservice of course! So you imagine that this mircoservice serves the same role in the overall app architecture that a function might in a program: You try to make it reusable, you write a solid API, you document it, you isolate it away from lateral movement and practice good defensive coding. You have a lovely little service now. Just one catch: You have written it in such a way (no fault of your own really, the app architecture of the old ugly monolith forced you to) that you have to call the monolith and ask it for a piece of information on every transaction you perform. It’s a terrible, no good, very bad situation. In the process, you have actually identified the next great candidate for a microservice and a prime illustration of another benefit of the microservices architecture: reusability.</p>
<h3>DRY off</h3>
<p>Whether implicitly or explicitly, programmers understand the concept of DRY: Don’t Repeat Yourself. It’s why we have functions. Why write the same 10 lines every time I need to do something? Just write a function and pass data in and get data out. Easy. Mircoservices can serve the same purpose for us, and a well-written, reusable microservice is a lovely little gem that should be cherished.</p>
<p>In our situation, let’s take a look at how the notification service (let’s call him Mercury, since he’s dispatching messages) talks to Cronus (the big daddy Titan who ruled before Zeus and friends took over). Mercury needs information about the user it needs to dispatch a message to, so it has to call Cronos and ask it for some specific user info. Why? This sounds like bad design. Well, it is. That’s the nature of apps in the real world: they’re designed poorly. However, rather than giving Mercury direct access to the database, we can take something that Cronos is doing well, which is serving info about users and customers, and split it off. After all, this new service will instantly have two consumers as soon as it’s live and given what it’s serving, it will have many more.</p>
<p>So on your next sprint you decide to make this new service your top priority. Let’s call it Athena, after the goddess of wisdom known for her calm demeanor. Athena has one very narrow job: When asked about a user, it will authenticate and authorize the request. If the request is authorized, it will serve the requested information in a JSON object back to the requestor. Athena now has two customers: Cronos and Mercury, but more are coming. Therefore, Athena might end up being busy.</p>
<p>As it turns out, Athena’s job was a bit of a bottleneck. The developers were able to run it in a nice, compact server (512mb that usually ran at close to 80% capacity. She handles quite a few requests per second). However, once Athena was decoupled from Cronos and allowed to scale up to 4 instances, a total of 2gb of memory and nearly negligible cost, performance improved by 25%. Who knew! Previously, the entire app would have been scaled at enormous cost to get achieve what was possible by a surgical allocation of resources in a single service.</p>
<p><em>In terms of accuracy and precision, this is the difference between carpet bombing cities and a laser-guided JDAM flying through a window to blow up a room</em></p>
<p>Additionally, in off-peak hours, Athena easily scales back down to a single node until the traffic picks up again. We can already see the benefits of decoupling services from one another. Independent scaling is one, but what about refactor and replacement of large chunks of the application?</p>
<h3>Decoupling gone wild</h3>
<p>When Athena was first created, she was just cut and pasted right out of Cronos, monkeypatched a little to provide an interface, and largely left the way she originated. After a couple months, a developer who had been experimenting with Elixir in her free time had an idea. “Hey, based on what Athena is doing, we can get a performance gain and cut our codebase by half if we switch to elixir. Dropping the Node dependency will save install time and reduce RAM usage!” Excited, she codes up an MVP the next day and demos it to the team. They’re so impressed that they work on it and introduce Athena 2.0 the next week. Using the same exact API, they drop Athena 2.0 into place without any other app or service ever noticing while clawing back gains in memory utilization and request execution time.</p>
<hr>
<h2>Conclusion</h2>
<p>Most people get into microservices for the benefits of scaling. “If it was just easier to deploy my app, or just this piece of my app, life would be so much better.” Once they have dipped their toes in the waters of microservices, they quickly realize the flexibility this provides for the overall design of the system and how things like decoupling can lead to independent refactoring (or even wholesale rebuilding) of services to improve performance. In the next article, we will address new problems microservices introduce.</p>
            <p><small>6 posts - 4 participants</small></p>
            <p><a href="https://0x00sec.org/t/intro-to-microservices-part-2/1682">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/intro-to-microservices-part-2/1682</link>
          <pubDate>Tue, 21 Feb 2017 05:03:24 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1682</guid>
          <source url="https://0x00sec.org/t/intro-to-microservices-part-2/1682.rss">Intro to Microservices part 2</source>
        </item>
        <item>
          <title>Intro to Microservices part 1</title>
          <dc:creator><![CDATA[fraq]]></dc:creator>
          <category>Operations</category>
          <description><![CDATA[
            <p><em>NB: I have filed this under programming because it is in its purest essence a programming problem. However, this extends above and beyond the mere laying of code and into overall systems design</em></p>
<p><em>I have also decided to break these into shorter chunks of around 1,000-1,200 words each.</em></p>
<h1>Microservices</h1>
<hr>
<h2>Part 1: The Monolith</h2>
<p>Before diving straight into what a microservice is, we should probably step back a moment and examine what it is <em>not</em>. Specifically, we need to understand what the microservice architecture is an answer to and solution for. In large part, the microservice was a response to monolithic app architectures and the opportunity presented by ever increasing ease of provisioning new servers by technology such as virtualization, LXC containers (which came way before Docker), and eventually Docker itself.</p>
<p>For our use case, let’s examine one of the most classic and common application stacks: the humble LAMP stack.</p>
<p>For those who may not be familiar, LAMP stands for “Linux, Apache, Mysql, PHP”, and was and still is the stack that defines much of the internet’s web services today. This is a “full stack” design, meaning it encompasses everything from the kernel and OS up through database and runtime + webserver. Everything you need to run an app can be found in this stack.</p>
<p>In most instances of the LAMP stack you’ll encounter, it’s actually one full, self-contained app + database on a single server. Even in larger companies, you’ll actually see nearly the same architecture: the kernel, runtime + application, and webserver are all on the same box and heavily intertwined while the database tends to be on a separate server (or cluster if you care about HA). A load balancer will distribute requests across multiple instances of the app which are necessarily on separate boxes. Those instances of the app share state and session by storing all of that data in the database.</p>
<h3>The problem: up or out?</h3>
<p>The problem with monoliths is that they don’t scale well. Or, rather, they don’t scale out well. Often times they only scale up to a certain point and then the return on investment drops significantly. Consider a monolithic LAMP or MEAN (Mongo, Express, Angular, Node.js) stack that processes something like, oh I don’t know, insurance applications and HR data. Given that this is a highly seasonal task, you can see where you’d have a very regular, predictable need to scale as traffic increased. January through September, things would be rather quiet and business-as-usual for your quant little shop. Developers would be happily slinging PHP or Node while ops people hum along and hopefully patch the latest silly OpenSSL bug with branding and a logo that would make Uber jealous. Then as the end of September approaches, the head of engineering calls and all-hands meeting and reminds everyone: Winter is coming. Okay, not so much “winter” as “open enrollment”, an insanely busy season for anyone who handles insurance or benefits. October through December are a whirlwind of “patch it NOW!” and “just survive!”. Naturally, as the traffic increases literally five-fold starting on the first day of October, you need to be ready.</p>
<p>The head of the ops team is smart. He knows what’s coming and gathers his team to formulate a plan. You currently have two webservers + app and a three-node database cluster. The database cluster is more than capable of handling the requests, but the webapp is already operating at a consistent 50% CPU capacity even under this lighter traffic load. We want to save money, after all, so we deployed two single core 4 GB boxes during the slow season. Now that the season is coming to an end, you have a clear problem: you need more capacity. The solution is less clear: Deploy bigger servers or more servers? In other words, up or out?</p>
<h3>The problem with up and the problem with out</h3>
<p>Both up and out have their own problems. That’s not to say that a mircoservice architecture is free from problems, no. But it approaches them quite differently. See, the one of the main issues with monoliths is that they’re notoriously hard to deploy. As a codebase grows, it becomes more picky. Angry. Cantankerous. Solutions abound for solving this problem, but they are ultimately band-aids: Golden images, CodeDeploy, Packer (a subset of golden images). Most of the time in our perfect world, we think we have built this well-behaved app that installs well each time. Call me when that happens because I have some unicorns to sell you. So naturally, because the monolith is so hard to install once, we want to avoid installing it 10 times. Therefore, we choose to go up. We throw RAM and CPU at the problem and build the app 2-3 times instead of 10. We lose some redundancy, but we have our sanity, right?</p>
<p>So the problem with “out” is clear: Monoliths are a pain to deploy and build, so we want to do it as few times as possible. They’re often a pain to maintain too, so having more instances of the monolith means more server that can possibly drag me out of bed in the middle of the night with an alert from Nagios or PagerDuty. But what about up? What’s so bad about throwing more resources at the problem in a couple of boxes.</p>
<p>In a few short words:</p>
<ol>
<li>It’s expensive</li>
<li>It’s wasteful (see <span class="hashtag">#1</span>)</li>
<li>You sacrifice redundancy</li>
</ol>
<h4>Why “up” is wasteful</h4>
<p>To go ahead and get out in front of the objection, up is not <em>always</em> wasteful. Sometimes you just need a bigger ~boat~ box. However, most of the time when your reason for going bigger is “scaling”, you’re probably wasting resources and spending more than you need to. Typically you only get up to capacity at specific peak times and the rest of that time is idle. Larger boxes on cloud infrastructure such as AWS are incredibly expensive, and having them sit idle for hours a day is wasteful. Imagine a c4.xlarge box (which costs hundreds of dollars a month) sitting idle at 5% CPU for 22 hours a day. Wouldn’t it be amazing if you could have that server when demand is high and then terminate it for the rest of the day? Imagine the savings! Additionally, your application does not perform perfectly symmetrically. Generally the “performance” is actually a bottleneck in one or two places that force you to solve the problem by either multiplying instances (scale out) or adding more raw resources to the problem (scaling up). In order to compensate for one slow function, we are throwing resources at the whole problem.</p>
<h3>Conclusion</h3>
<p>This is not the sole problem with monoliths, nor is this the reason to move to a microservices architecture. Rather, this is just an illustration of the problems that ops teams face on a daily basis. Many are understaffed and face a lack of training. This compounds in decisions that were made to serve the “tyranny of the urgent” as opposed to strategic investment in infrastructure and systems design. Monoliths are the easy, short term answer for many dev teams, but unfortunately they reach the end of their scalability quickly. You can only scale up so many times and eventually scaling out faces problem of its own. What happens when you can reliably deploy the app, but now you are faced with the question of scaling out at a rate many times what you were doing before? Can you handle that? Can your team of two or three handle the linear increase to scaling of a hundred boxes or more?</p>
<p>In the next section, we will talk about how the microservice architecture addresses the problem of scaling, additional problems it solves, and new ones that it introduces.</p>
<aside class="quote quote-modified" data-post="1" data-topic="1682">
  <div class="title">
    <div class="quote-controls"></div>
    <img alt="" width="20" height="20" src="/user_avatar/0x00sec.org/fraq/40/1471_2.png" class="avatar">
    <a href="https://0x00sec.org/t/intro-to-microservices-part-2/1682">Intro to Microservices part 2</a> <a class="badge-wrapper  bullet" href="https://0x00sec.org/c/operations/86"><span class="badge-category-bg" style="background-color: #B3B5B4;"></span><span style="" data-drop-close="true" class="badge-category clear-badge" title="Category for Topics about Operations.">Operations</span></a>
  </div>
  <blockquote>
    The second in a series on microservices. 
Microservices

Part 2: The start of microservices
Out of the water, onto land…
The motivation for and benefits of a microservices architecture extend far beyond simply breaking down the monolith as mentioned, but for most engineers and companies I’ve spoken with looking to make the switch, scaling and cost savings are the primary motivation. They realize that deployments are painful, that money is wasted on power or cloud compute resources, that choke po…
  </blockquote>
</aside>

            <p><small>3 posts - 2 participants</small></p>
            <p><a href="https://0x00sec.org/t/intro-to-microservices-part-1/1681">Read full topic</a></p>
          ]]></description>
          <link>https://0x00sec.org/t/intro-to-microservices-part-1/1681</link>
          <pubDate>Tue, 21 Feb 2017 04:14:27 +0000</pubDate>
          <discourse:topicPinned>No</discourse:topicPinned>
          <discourse:topicClosed>Yes</discourse:topicClosed>
          <discourse:topicArchived>No</discourse:topicArchived>
          <guid isPermaLink="false">0x00sec.org-topic-1681</guid>
          <source url="https://0x00sec.org/t/intro-to-microservices-part-1/1681.rss">Intro to Microservices part 1</source>
        </item>
  </channel>
</rss>
